{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f29f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "# from pastamarkers import markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39761033",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c647a84",
   "metadata": {},
   "source": [
    "We begin by fetching the reduced data using the Python script `data_transfer.py` from the file `df_merged.parquet`, then importing it into Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../scripts/df_GP_1st_bug.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a6c02-6c62-4ba9-9558-e13a61171477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts(normalize=True) * 100\n",
    "# df.source = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94d88b",
   "metadata": {},
   "source": [
    "Here we extract all unique IDs from our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e814c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df['objectId'].unique().tolist()\n",
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df18f04",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4b38e",
   "metadata": {},
   "source": [
    "To calculate the weight values \\(w_i\\), we use the formula: `w_i` =\\begin{cases}\n",
    "\\frac{1}{{\\sigma_i^2}}, & \\text{if data is available for day } i \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_data = (df['source'] == 0) | (df['dc_sigflux'] == 0)\n",
    "# df['dc_weight'] = np.where(missing_data, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "#df['nr_weight'] = np.where(missing_data, 0, 1 / (df['nr_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe011e-eb7b-4e83-906a-b8f02eaec694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['dc_weight'] = 1 / (df['dc_sigflux'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ab189-58b7-4869-91be-1cc612883f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = (df['dc_sigflux'] == 0)\n",
    "df['dc_weight'] = np.where(missing_data, 0, 1 / (df['dc_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['source','dc_weight']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef1374",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf1c2f-68aa-427f-b465-1763e3721d09",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee9a7d-a1c7-404d-a835-3257262d0972",
   "metadata": {},
   "source": [
    "# Percentenge of classes (classification) for all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96fa16-9478-4db2-b779-b0c9e1f2f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to unique IDs\n",
    "ids_file_path = '../scripts/unique_ids.txt'\n",
    "\n",
    "# Read the file and store each line as an element in a list\n",
    "with open(ids_file_path, 'r') as file:\n",
    "    IDS = file.read().splitlines()\n",
    "\n",
    "# Initialize an empty list to store individual dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Folder name where the parquet files are located\n",
    "folder_name = 'test_EB'#'test2'  \n",
    "\n",
    "for Id in IDS:#[0:10]:\n",
    "    file_name = f'{Id}.parquet'\n",
    "    file_path = f'../scripts/{folder_name}/{file_name}'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the Parquet file into a DataFrame\n",
    "        data = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes[Id] = data\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb06795",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558a98",
   "metadata": {},
   "source": [
    "# With distance - factor test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576f19f",
   "metadata": {},
   "source": [
    "We group the data by shared ID and create `NumPy` arrays for flux, weighted flux, and the source test(if it's a missing day(data)). We also determine the length of each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('objectId')\n",
    "\n",
    "F = grouped['dc_flux'].apply(lambda x: x.values)#.values\n",
    "sig = grouped['dc_sigflux'].apply(lambda x: x.values)#.values\n",
    "W = grouped['dc_weight'].apply(lambda x: x.values)#.values\n",
    "source = grouped['source'].apply(lambda x: x.values)#.values\n",
    "lengths = grouped['source'].apply(lambda x: len(x))#.values\n",
    "mjd = grouped['mjd'].apply(lambda x: x.values)#.values\n",
    "# is_valid = grouped['is_valid'].apply(lambda x: x.values)#.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b64914",
   "metadata": {},
   "source": [
    "We define the length of our query,window or chunk, along with the limit factor and the size of each window or chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "chunk_size = 2 * (m + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae9b24",
   "metadata": {},
   "source": [
    "The `'no_match_test'` function evaluates whether there are any matches in the provided array, which contains the source test values for a window. If the sum of the array is less than or equal to 1, indicating that all values are missing or only one value is present, the function returns -99. Otherwise, it returns -1 to initialize the window's status as 'no match'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74191626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def no_match_test(array):\n",
    "#     if array.sum() <= 2 :#chunk_size-1 : \n",
    "#         return -99 ## all are missing, or all except one\n",
    "#     return -1 # initialise as no match  # can be modifieted ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98068a37-e0a0-4180-a6e7-cab0b5c5ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = 8\n",
    "# chunk_size = 2 * (m + 1)\n",
    "half_pts = int((m+1)/2)\n",
    "print(half_pts, int(chunk_size/2))\n",
    "def no_match_test(array):\n",
    "    # print(array, array[::2],array[1::2])\n",
    "    if (array[::2].sum() > half_pts) & (array[1::2].sum() > half_pts) :#chunk_size-1 : \n",
    "        return -1 \n",
    "    return -99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fecc96",
   "metadata": {},
   "source": [
    "\"`objects`\" list contains a subset of the objects we intend to work with.\n",
    "\n",
    "\"`L_max`\" is defined to facilitate partial iteration, serving as a debugging aid by allowing a limit to be set on the number of iterations performed.\n",
    "\n",
    "We initialize the NumPy arrays with `None` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f76cc4-508e-42d7-b72a-84e491b2deb7",
   "metadata": {},
   "source": [
    "#### Run this cell only once ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9f2ab-a6d1-436b-89a1-523423e70121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects = unique_ids[:]#[0:10]\n",
    "# num_objects = len(objects)\n",
    "# # Shuffle the list\n",
    "# random.shuffle(objects)\n",
    "# Save the shuffled list to a file\n",
    "# file_path = 'shuffled_objects.json'\n",
    "\n",
    "# with open(file_path, 'w') as file:\n",
    "#     json.dump(objects, file)\n",
    "\n",
    "# print(f\"Shuffled objects have been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574314e-ec75-4d62-811c-f23dc0fcf91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to the file\n",
    "file_path = 'shuffled_objects.json'\n",
    "\n",
    "# Read the shuffled list from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    objects = json.load(file)\n",
    "\n",
    "# print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbee235-7434-486c-b9b0-9d9fec1c8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects = objects[:10]\n",
    "num_objects = len(objects)\n",
    "\n",
    "list_L_max = [110,1424,7221,7572,5701,3401,1801,297,10591] \n",
    "L_max = 317#5611##10591 #10592# 8184#407#7221#list_L_max[m]\n",
    "\n",
    "print(\"L_max \", L_max)\n",
    "\n",
    "R = np.empty(num_objects, dtype=object)\n",
    "R_ref = np.empty(num_objects, dtype=object)\n",
    "# Matches = np.empty(num_objects, dtype=object)\n",
    "R_l = np.empty((num_objects, L_max), dtype=object)\n",
    "num_by_obj = np.zeros((L_max,num_objects), dtype=object)\n",
    "alp = np.empty((num_objects, L_max), dtype=object)\n",
    "d = np.empty((num_objects, L_max), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_objects = range(num_objects)\n",
    "Q = [None] * (L_max)\n",
    "min_d =  [float('inf'), -1, -1] * (L_max)\n",
    "num_left_by_Q = [0] * (L_max) ####### we don't need this one anymore <==> sum_i\n",
    "selected_Q_K_i = np.empty(L_max, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e82cf3",
   "metadata": {},
   "source": [
    "We initialize R using the '`no_match_test`' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "count_W = 0 \n",
    "n = lengths[objects[0]]\n",
    "num_chunks = int(n // 2)-m \n",
    "\n",
    "for k in indexes_objects:\n",
    "    \n",
    "    chunks = np.array([source[objects[k]][i*2 : (i*2+chunk_size)] for i in range(num_chunks)])\n",
    "    result = np.array(list(map(no_match_test, chunks)))\n",
    "    R[k] = result.copy()\n",
    "    R_ref[k] = result.copy()\n",
    "    \n",
    "    count_W += np.count_nonzero(result == -1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Num of feasible windows :\",count_W)\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2cac1-4da7-4bd5-b0d1-2e03beac745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "rangek0 = [i for i in range(len(objects)) if len(indexes_array[i]) > 0]\n",
    "len0 = len(rangek0)\n",
    "len0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042f5e9-4a42-4753-9f83-e82b949d57b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "classes0 = {}\n",
    "for k in rangek0:\n",
    "    df = dataframes[objects[k]]\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        if class_name in classes0:\n",
    "            classes0[class_name][0] += percentage\n",
    "            classes0[class_name][1] += error_bar**2\n",
    "        else:\n",
    "            classes0[class_name] = [percentage,error_bar**2]\n",
    "\n",
    "    # classes.append(get_classification3(objects[k]))\n",
    "for class_name, list1 in classes0.items():\n",
    "    classes0[class_name][0] = round(list1[0] / len0 , 2)\n",
    "sorted_classes0 = dict(sorted(classes0.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Elapsed time:\", (end_time - start_time)/60, \"minutes\")\n",
    "sorted_classes0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2346ac1-00f4-4c21-8793-8bc32aef3cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# List of all possible groups to merge\n",
    "groups_to_merge = {\n",
    "    'EB*': ['Candidate_EB*', 'EB*_Candidate'],\n",
    "    # 'LPV*': ['Candidate_LP*', 'LP*_Candidate'],\n",
    "    'RRLyr': ['Candidate_RRLyr', 'RRLyr_Candidate'],\n",
    "    'CV*': ['Candidate_CV*', 'CV*_Candidate'],\n",
    "    # 'WD*': ['Candidate_WD*', 'WD*_Candidate'],\n",
    "    # 'YSO': ['Candidate_YSO', 'YSO_Candidate'],\n",
    "    # 'C*': ['Candidate_C*', 'C*_Candidate'],\n",
    "    'RSG*': ['Candidate_RSG*', 'RSG*_Candidate'],\n",
    "    # 'TTau*': ['Candidate_TTau*', 'TTau*_Candidate'],\n",
    "    # 'RGB*': [ 'RGB*_Candidate'],\n",
    "}\n",
    "\n",
    "# Initialize the new dictionary with the original data, excluding the ones to be merged\n",
    "merged_data = {k: v for k, v in sorted_classes0.items() if k not in sum(groups_to_merge.values(), [])}\n",
    "\n",
    "# Function to combine values and propagate errors\n",
    "def combine_values_and_errors(keys):\n",
    "    combined_value = sum(sorted_classes0[key][0] for key in keys)\n",
    "    combined_error = np.sqrt(sum(sorted_classes0[key][1]**2 for key in keys))\n",
    "    return [combined_value, combined_error]\n",
    "\n",
    "# Merge the groups\n",
    "for new_key, old_keys in groups_to_merge.items():\n",
    "    if new_key in sorted_classes0:\n",
    "        all_keys = [new_key] + old_keys\n",
    "    else:\n",
    "        all_keys = old_keys\n",
    "    merged_data[new_key] = combine_values_and_errors(all_keys)\n",
    "\n",
    "# Sort the merged data\n",
    "sorted_classes0_m = dict(sorted(merged_data.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "# Output the result\n",
    "sorted_classes0_m \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96498701",
   "metadata": {},
   "source": [
    "### Loop to compute the distance of the subsequence in the time series to its nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891d484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rangek2 = list(range(len(objects)))\n",
    "\n",
    "l= 0\n",
    "while (l < L_max):\n",
    "    indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "    rangek2 = [i for i in range(len(objects)) if len(indexes_array[i]) > 0]\n",
    "\n",
    "    has_empty_list = len(rangek2) == 0\n",
    "    if has_empty_list:\n",
    "        print(\"break , l = \", l )\n",
    "        break\n",
    "        \n",
    "    num_left_by_Q[l] = len(rangek2)\n",
    "        \n",
    "    k = rangek2[0]\n",
    "        \n",
    "    f = F[objects[k]]\n",
    "    index_no_match = indexes_array[k][0]\n",
    "    k_Query_taked = k\n",
    "    selected_Q_K_i[l] = [k,index_no_match]\n",
    "    Q[l] = f[index_no_match*2 : index_no_match*2 +chunk_size]\n",
    "\n",
    "\n",
    "    \n",
    "    for k in rangek2:\n",
    "        f = F[objects[k]]\n",
    "        w = W[objects[k]]\n",
    "        n = lengths[objects[k]]\n",
    "        n_c = n - 2*m # (number of chunks x 2) ! it's (n/2 - m) but to optimize we mutiply by 2 directly !  \n",
    "        #print(n, n_c,len(R[k]))\n",
    "\n",
    "\n",
    "\n",
    "        s_1 = np.zeros(n_c, dtype=float)\n",
    "        s_2 = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:] += (f[j*2:j*2+ n_c]*h*w[j*2:j*2+ n_c])\n",
    "            s_2[:] += (h**2 * w[j*2:j*2+ n_c])\n",
    "\n",
    "\n",
    "        s_n = s_1[::2] + s_1[1::2]  \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "\n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "     \n",
    "    \n",
    "        dd = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            \n",
    "            dd[:] += ((f[j*2:j*2+ n_c] - alpha[:] * h)**2) * w[j*2:j*2+ n_c] \n",
    "            #alpha[:n-j*2] ==> alpha[:]\n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        factor_comparison =  d[k][l] <= factor\n",
    "                \n",
    "        R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l # explanation follows below!\n",
    "                \n",
    "        R_l[k][l] = R_ref[k].copy()\n",
    "\n",
    "        matches_k = float('inf')  # Start with a large number\n",
    "        min_index = None  # Variable to store the index of the minimum value\n",
    "\n",
    "        for i in range(len(factor_comparison)):\n",
    "            if  R_l[k][l][i] != -99:\n",
    "                if factor_comparison[i] :\n",
    "                    R_l[k][l][i] = l\n",
    "                    num_by_obj[l][k]+=1\n",
    "                if index_no_match != i and d[k][l][i] < matches_k:\n",
    "                        matches_k = d[k][l][i]  # Update the minimum value\n",
    "                        min_index = i  #\n",
    "\n",
    "        \n",
    "        if matches_k < min_d[l * 3] :\n",
    "            min_d[l * 3] = matches_k  # Instead of min_d[::3][l]\n",
    "            min_d[l * 3 + 2] = min_index      # Instead of min_d[2::3][l]\n",
    "            min_d[l * 3 + 1] = k            # Instead of min_d[1::3][l]\n",
    "\n",
    "    R_l[k_Query_taked][l][index_no_match] = -2\n",
    "\n",
    " \n",
    "    l += 1 \n",
    "    \n",
    "print(\"l = \",l)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time += end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d33b3",
   "metadata": {},
   "source": [
    "Let's break down the expression `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l` step by step:\n",
    "\n",
    "1. `indexes_array[k]`: This selects the array of indexes corresponding to the k-th element of `indexes_array`.\n",
    "2. `factor_comparison[indexes_array[k]]`: This applies boolean indexing to `factor_comparison` using the indexes from `indexes_array[k]`. It selects only the elements of `factor_comparison` corresponding to the indexes in `indexes_array[k]`.\n",
    "3. `indexes_array[k][factor_comparison[indexes_array[k]]]`: This gives the indices where the condition `factor_comparison` is true for the k-th element of `indexes_array`.\n",
    "4. `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]]`: This uses the indices obtained in the previous step to select elements from the k-th row of `R`.\n",
    "5. `= l`: Finally, it assigns the value `l` to the selected elements of `R[k]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_left_by_Q[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(L_max),num_left_by_Q)\n",
    "\n",
    "plt.xlabel('Queries')\n",
    "plt.ylabel('Nb objs left')\n",
    "plt.title('Number of objects left in function of queries.')\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "# data = {'Queries': range(L_max), 'Nb objs left': num_left_by_Q}\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Export to Excel\n",
    "# df.to_csv('num_left_by_Q.csv', index=False)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7a5da-1532-4af7-9c0c-744afd887ece",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fd2b6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398f367-aa9b-4e29-b1e0-91f9ff1ae619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming the variables d, Matrix_Matches, R_l, Q, length_no_missing, selected_Q_K_i are defined above\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Save each variable in a different file using numpy.save or numpy.savez_compressed\n",
    "# np.save('d.npy', d)  # For single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5e505-4cfe-4d1c-a0ea-85470dca1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Matrix_Matches.npy', Matrix_Matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76160c-871e-445e-a175-3fa5bac162c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('R_l.npy', R_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b9705-9ffa-42ff-a0a5-1c06b360368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Q.npy', Q)\n",
    "# np.save('length_no_missing.npy', length_no_missing)\n",
    "# np.save('selected_Q_K_i.npy', selected_Q_K_i)\n",
    "\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Compute the elapsed time\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(\"Elapsed time:\", elapsed_time / 60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e88794-d4d3-444e-a297-8cbafef93d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbb598-115f-47a9-98c6-fc32f14b679f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8790716f-91c9-4e20-ab5f-24561b5e2377",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3881c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe22e6",
   "metadata": {},
   "source": [
    "### Calculate the Matrix of Matches (with windows represented in rows and queries as columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e766e-82e6-4d7a-b9ca-1d0944e54ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangek = range(len(objects))\n",
    "\n",
    "# Initialize list to hold transposed arrays for each k\n",
    "Matrices_by_k = []\n",
    "\n",
    "no_missing = np.zeros(len(rangek), dtype= object)\n",
    "length_no_missing = np.zeros(len(rangek), dtype= int)\n",
    "\n",
    "Reference_Table_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0cf2c-a8fa-4ba7-8ed1-47764e4faad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for k in rangek:\n",
    "    no_missing[k] = np.where(R[k] != -99)[0]  \n",
    "    \n",
    "    length_no_missing[k] = len(no_missing[k])\n",
    "    \n",
    "    # Initialize transposed array\n",
    "    Matrix= np.empty((length_no_missing[k], len(R_l[k])), dtype=object)\n",
    "    \n",
    "    refrence_table_k = np.empty(length_no_missing[k], dtype=object)\n",
    "    \n",
    "    # Transpose and store the arrays\n",
    "    for i, idx in enumerate(no_missing[k]):\n",
    "        for j, arr in enumerate(R_l[k]):\n",
    "            if arr is not None:  # Check if arr is not None\n",
    "                if arr[idx] == -2 or arr[idx] >= 0:\n",
    "                    Matrix[i][j] = 1\n",
    "                else:\n",
    "                    Matrix[i][j] = 0\n",
    "            else:\n",
    "                Matrix[i][j] = 0\n",
    "                #print(f\"Error: arr is None at index {j} in R_l[{k}]\")\n",
    "            # if arr[idx] == -2 or arr[idx] >= 0:\n",
    "            #     Matrix[i][j] = 1\n",
    "            # else:\n",
    "            #     Matrix[i][j] = 0\n",
    "                \n",
    "        refrence_table_k [i] =  [k ,idx]\n",
    "\n",
    "                \n",
    "    # Append transposed array to the list\n",
    "    Matrices_by_k.append(Matrix)\n",
    "    Reference_Table_list.append(refrence_table_k)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time += end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")\n",
    "Matrices_by_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_Matches = np.concatenate(Matrices_by_k, axis=0)\n",
    "Reference_Table = np.concatenate(Reference_Table_list, axis=0)\n",
    "Matrix_Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636f0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_j_rows = np.sum(Matrix_Matches, axis=1)\n",
    "sum_j_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767a706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_i_columns = np.sum(Matrix_Matches, axis=0)\n",
    "sum_i_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6171",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a597b5-9c3c-44f3-a324-3dbc12625177",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_values_for_k(specific_k):\n",
    "    return no_missing[specific_k]\n",
    "get_i_values_for_k(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_i_for_row(global_idx):\n",
    "    return Reference_Table[global_idx]\n",
    "k,i = get_k_i_for_row(2)\n",
    "k,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_indexes_for_k(specific_k):\n",
    "    idx = 0 \n",
    "    for k in rangek:\n",
    "        if k == specific_k:\n",
    "            return list(range(idx, idx + length_no_missing[k]))\n",
    "        idx += length_no_missing[k]\n",
    "\n",
    "get_i_indexes_for_k(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e3e9a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5104ad6",
   "metadata": {},
   "source": [
    "# Matrix only for queries (len(Qs) x len(Qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34455e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_Queries = []\n",
    "\n",
    "for k,i in selected_Q_K_i:#[:5]:\n",
    "    #print(get_i_values_for_k(k),i)\n",
    "    i_k = np.where(get_i_values_for_k(k) == i)[0][0]\n",
    "    #print(get_i_indexes_for_k(k),i_k)\n",
    "    global_idx = get_i_indexes_for_k(k)[i_k]\n",
    "    Matrix_Queries.append(Matrix_Matches[global_idx])\n",
    "\n",
    "    #[0][0]\n",
    "Matrix_Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Matrix_Queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea3f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_j_rows_queries = np.sum(Matrix_Queries, axis=1)\n",
    "\n",
    "sum_i_columns_queries = np.sum(Matrix_Queries, axis=0)\n",
    "sum_i_columns_queries,sum_j_rows_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_i_columns_queries.argmax(),sum_i_columns_queries.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_j_rows_queries.argmax(), sum_j_rows_queries.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8913a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_j_rows_queries.sum(), sum_i_columns_queries.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8fbe7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955aea2",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_matches = sum(sum_i_columns) + sum(sum_j_rows)\n",
    "\n",
    "I_i_j = Matrix_Matches[:].copy() #*(sum_i[:])\n",
    "I_i_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, sj in enumerate(sum_j_rows):\n",
    "    for i, si in enumerate(sum_i_columns):\n",
    "        dn = (si*sj)\n",
    "        if dn == 0:\n",
    "            I_i_j[j][i] *= np.inf # we don't need this anymore , No, we do , if l_max != len(Q)\n",
    "        else:\n",
    "            I_i_j[j][i] *= total_matches/ dn\n",
    "I_i_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d604b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonzero_indices = np.nonzero(np.outer(sum_j, sum_i))\n",
    "\n",
    "# # Update only non-zero elements\n",
    "# I_i_j[nonzero_indices] = I_i_j[nonzero_indices] / (sum_i[nonzero_indices[1]] * sum_j[nonzero_indices[0]])\n",
    "\n",
    "# #I_i_j[I_i_j == 0] = np.inf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52920ca",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3b010",
   "metadata": {},
   "source": [
    "###### Compute the query with the highest number of matches and the one with the fewest matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef982c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(sum_i_columns),min(sum_i_columns), np.argmax(sum_i_columns), np.argmin(sum_i_columns), selected_Q_K_i[94], selected_Q_K_i[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225b1e2",
   "metadata": {},
   "source": [
    "###### Compute the window with the highest number of matches on queries and the one with the fewest matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a4e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#flattened_array = np.concatenate([arr.flatten() for arr in sum_j])\n",
    "maximum_value = np.max(sum_j_rows)\n",
    "maximum_value, np.argmax(sum_j_rows),sum_j_rows[155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of non-zero values\n",
    "non_zero_indices = np.argwhere(sum_j_rows != 0).flatten()\n",
    "\n",
    "# Retrieve non-zero values\n",
    "non_zero_values = sum_j_rows[non_zero_indices]\n",
    "\n",
    "# Find the index of the minimum non-zero value\n",
    "min_non_zero_index = non_zero_indices[np.argmin(non_zero_values)]\n",
    "\n",
    "min_non_zero_value = sum_j_rows[min_non_zero_index]\n",
    "\n",
    "min_non_zero_value, min_non_zero_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61491c0b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a9d9b",
   "metadata": {},
   "source": [
    "### Function to detect a specific window in a time series (specified by its object and index within this object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_a_query(k_TS, i_TS, selected_Q_K_i):\n",
    "    mask = selected_Q_K_i != None\n",
    "    for index_Q, (k, i) in enumerate(selected_Q_K_i[mask]):\n",
    "        if k_TS == k and i_TS == i:\n",
    "            return True, index_Q, f\"This window is used as the {index_Q}th query! \"\n",
    "    return False, 0 , \"This window is not used as a query ! \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(i,j):\n",
    "    return concatenated_array[j][i] ### I need to check this 2 j,i or i,j\n",
    "\n",
    "def get_i_by_sum(i):\n",
    "        return sum_i_columns[i]\n",
    "\n",
    "def get_j_by_sum(j):\n",
    "        return sum_i_columns[j]\n",
    "\n",
    "    \n",
    "def get_k_i_of_Q(l):\n",
    "    return selected_Q_K_i[l]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202add1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f608b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc673bbc",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e939f3",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5529e2f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97534fc3",
   "metadata": {},
   "source": [
    "## Functions to compute the numbers of matches and plot the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c7125",
   "metadata": {},
   "source": [
    "#### these functions should be in another file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c58d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_flux(k,l,open_Fink= False):\n",
    "    print(\"\\n______________________________________________________________________________________________\")\n",
    "    print(f\"{objects[k]}\")\n",
    "    #get_classification(objects[k])\n",
    "\n",
    "    for index, row in dataframes[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        print(f\"                        {classification} : {percentage:.1f}% \") \n",
    "   \n",
    "    \n",
    "#     for class_name, percentage in dict_classes.items():\n",
    "#         print(f\"                        {class_name} : {percentage:.1f}%\") \n",
    "    import ipywidgets as widgets\n",
    "          \n",
    "    button = widgets.Button(description=f\"open in FINK\")\n",
    "    # Capture current values of kk and l in lambda's default arguments\n",
    "    button.on_click(lambda _, k=k : on_button_clicked_plot(objects[k]))\n",
    "    display(button)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Plot for F[k]\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    for i in range(int(len(F[objects[k]])/2)):\n",
    "        if source.loc[objects[k]][2*i] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig[objects[k]][2*i]*0.4,\n",
    "                     c='C0', marker='x')\n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig.loc[objects[k]][2*i],\n",
    "                     c='C0', marker=marker)\n",
    "\n",
    "        if source.loc[objects[k]][2*i+1] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig[objects[k]][2*i+1]*0.4,\n",
    "                     c='C1', marker='x')\n",
    "            \n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig.loc[objects[k]][2*i+1],\n",
    "                     c='C1', marker=marker)\n",
    "            \n",
    "        a_query,l_1, string = if_a_query(k,i,selected_Q_K_i)\n",
    "            \n",
    "        if a_query and l_1 == l:\n",
    "            print(string)\n",
    "            \n",
    "            # Define the window of indices\n",
    "            window_start = mjd.loc[objects[k]][2*i]  # Index of the window start\n",
    "            window_end = mjd.loc[objects[k]][2*i] + int(len(Q[l])/2 - 1)  # Index of the window end\n",
    "            \n",
    "            \n",
    "            # Create an array of float indices\n",
    "            indices = np.arange(window_start, window_end + 1)\n",
    "            indices = np.concatenate(([indices[0] - 0.5], indices, [indices[-1] + 0.5]))\n",
    "\n",
    "            # Plot a shaded region for the window\n",
    "            plt.fill_between(indices, min(Q[l])/1.9, max(Q[l])*1.2, color='gray', alpha=0.2)\n",
    "            \n",
    "        \n",
    "    plt.plot([], [], color='C1', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C0', marker='o', label='origin')\n",
    "    plt.plot([], [], color='C0', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C1', marker='o', label='origin')\n",
    "    \n",
    "   \n",
    "    ################################### what about the seccond window !? \n",
    "    moy_alp = 1+0*alp[k][l].mean()\n",
    "    #moy_alp = np.median(F[k])/np.median(Q[l]) #Manu test\n",
    "\n",
    "    plt.plot(mjd.loc[objects[k]][::2], F.loc[objects[k]][::2], c='C0', linewidth = 1)\n",
    "    plt.plot(mjd.loc[objects[k]][1::2], F.loc[objects[k]][1::2], c='C1', linewidth = 1)\n",
    "\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][::2]*moy_alp, c='g', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][1::2]*moy_alp, c='r', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "\n",
    "    # Define the window of indices\n",
    "    window_start = -1-m + mjd.loc[objects[k]][0] # Index of the window start\n",
    "    window_end = int(len(Q[l])/2 - 1-1 -m)+ mjd.loc[objects[k]][0]  # Index of the window end\n",
    "\n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.4], indices, [indices[-1] + 0.4]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(Q[l])/1.2*moy_alp, max(Q[l])*1.2*moy_alp, color='gray', alpha=0.2)\n",
    "\n",
    "    # plt.xlabel('Index')\n",
    "    plt.ylabel('Flux')\n",
    "    # plt.title('Flux Plot')\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ###############                       Plot for d[k][0]                       ###############\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot([-1-m, -1-m], [0, 0], color='none')  # Plot an empty line with zero length\n",
    "    plt.plot(range(len(d[k][l])), d[k][l],color='C0', linestyle='-',linewidth=1)\n",
    "    \n",
    "#     matches = all_matches[k]#Matches[k]#\n",
    "#     for i, match_count in enumerate(matches):\n",
    "#         plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(match_count), fontsize=10, color='red', ha='left')\n",
    "    matches_idx = get_i_indexes_for_k(k)\n",
    "    matches2 = sum_j_rows[matches_idx]\n",
    "    #print(matches_idx, matches2)\n",
    "\n",
    "\n",
    "\n",
    "    # Plot dummy points with desired colors and markers\n",
    "    plt.plot([], [], color='black', marker='o', label='Query chosed')#markers.soli\n",
    "    plt.plot([], [], color='red', marker='x', label='missing cases !')\n",
    "    plt.plot([], [], color='blue', marker='s', label='Matched here')#markers.ravioli\n",
    "    plt.plot([], [], color='green', marker='*', label='Matches with a different `l` (Query)')#markers.stelline\n",
    "    plt.plot([], [], color='yellow', marker='^', label=f'Not matched with any of the {L_max} options we selected') #markers.tortellini\n",
    "    \n",
    "    c= 0\n",
    "    \n",
    "    for i, val in enumerate(R_l[k][l]):\n",
    "            if val == -99:\n",
    "                plt.scatter(i, d[k][l][i], color='red', marker='x', s=50)  # marker size 50\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, 0, fontsize=10, color='red', ha='left')\n",
    "                c+=1\n",
    "#                 plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, 0*str(matches2[i]), fontsize=10, color='red', ha='left')\n",
    "\n",
    "            elif val == l:\n",
    "                plt.scatter(i, d[k][l][i], color='blue', marker='s', s=50)\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, 'str(matches2[i-c])', fontsize=10, color='blue', ha='left')\n",
    "\n",
    "            elif val == -2:\n",
    "                plt.scatter(i, d[k][l][i], color='black', marker='o', s=50) \n",
    "                #print(matches2[i-c])\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='black', ha='left')\n",
    "\n",
    "            elif matches2[i-c]==0:\n",
    "                plt.scatter(i, d[k][l][i], color='yellow', marker='^', s=50) \n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='yellow', ha='left')\n",
    "\n",
    "            else:\n",
    "                plt.scatter(i, d[k][l][i], color='green', marker='*', s=75)\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='green', ha='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.legend(fontsize=8) \n",
    "    #plt.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "    plt.ylabel('distance')\n",
    "\n",
    "\n",
    "\n",
    "    ###############                       Plot for alpha[k][l]                       ###############\n",
    "\n",
    "#     plt.subplot(3, 1, 3)\n",
    "#     plt.plot(range(len(alp[k][l])), alp[k][l], marker='.', linestyle='-',color='black')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.title('alpha Plot')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(top=0.93)  # Adjust the top margin for the super title\n",
    "    plt.suptitle(f\"{objects[k]}, k = {k}, l = {l} \", fontname='Arial', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    if open_Fink:\n",
    "        open_website(objects[k])\n",
    "\n",
    "\n",
    "import webbrowser\n",
    "\n",
    "def open_website(k):\n",
    "    website_url = f'https://fink-portal.org/{k}'\n",
    "    webbrowser.open(website_url)\n",
    "\n",
    "def on_button_clicked_plot(Id):\n",
    "    print(\"URL opened\")\n",
    "    open_website(Id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce100169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_distance_flux(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ced90-aed9-4dca-8066-08450483d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for l in sorted_indices:\n",
    "#     k , i = selected_Q_K_i[l]\n",
    "#     # Nb_valid = np.sum(is_valid[objects[k]][i*2:i*2+chunk_size])\n",
    "\n",
    "#     # if Nb_valid < chunk_size -1:\n",
    "#     #     continue\n",
    "#     if sum_i_columns[l] >1 :\n",
    "#             break \n",
    "\n",
    "#     plot_distance_flux(k,l)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb3665-49a8-4678-bebc-9c72b7417a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_flux_min(k,l,min_d_i):\n",
    "    print(\"\\n______________________________________________________________________________________________\")\n",
    "    print(f\"{objects[k]}\")\n",
    "    \n",
    "    #get_classification(objects[k])\n",
    "\n",
    "    for index, row in dataframes[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        print(f\"                        {classification} : {percentage:.1f}% \") \n",
    "   \n",
    "    \n",
    "    import ipywidgets as widgets\n",
    "          \n",
    "    button = widgets.Button(description=f\"open in FINK\")\n",
    "    # Capture current values of kk and l in lambda's default arguments\n",
    "    button.on_click(lambda _, k=k : on_button_clicked_plot(objects[k]))\n",
    "    display(button)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Plot for F[k]\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    for i in range(int(len(F[objects[k]])/2)):\n",
    "        if source.loc[objects[k]][2*i] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     #sig[objects[k]][2*i]*0.4,\n",
    "                     c='C0', marker='x')\n",
    "        else:\n",
    "            if is_valid[objects[k]][2*i] == True:\n",
    "                marker = 'o'\n",
    "            elif is_valid[objects[k]][2*i] == False :\n",
    "                marker = '.'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig.loc[objects[k]][2*i],\n",
    "                     c='C0', marker=marker)\n",
    "\n",
    "        if source.loc[objects[k]][2*i+1] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     #sig[objects[k]][2*i+1]*0.4,\n",
    "                     c='C1', marker='x')\n",
    "            \n",
    "        else:\n",
    "            if is_valid[objects[k]][2*i+1] == True:\n",
    "                marker = 'o'\n",
    "            elif is_valid[objects[k]][2*i+1] == False :\n",
    "                marker = '.'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig.loc[objects[k]][2*i+1],\n",
    "                     c='C1', marker=marker)\n",
    "            \n",
    "        # a_query,l_1, string = if_a_query(k,i,selected_Q_K_i)\n",
    "            \n",
    "        # if a_query and l_1 == l:\n",
    "        #     print(string)\n",
    "            \n",
    "            # Define the window of indices\n",
    "    window_start = mjd.loc[objects[k]][2*min_d_i]  # Index of the window start\n",
    "    window_end = mjd.loc[objects[k]][2*min_d_i] + int(m)  # Index of the window end\n",
    "    \n",
    "    \n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.5], indices, [indices[-1] + 0.5]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(F[objects[k]])/1.9, max(F[objects[k]])*1.2, color='gray', alpha=0.2)\n",
    "        \n",
    "    \n",
    "    plt.plot([], [], color='C1', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C0', marker='o', label='origin')\n",
    "    plt.plot([], [], color='C0', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C1', marker='o', label='origin')\n",
    "    \n",
    "   \n",
    "    ################################### what about the seccond window !? \n",
    "    moy_alp = 1#+0*alp[k][l].mean()\n",
    "    #moy_alp = np.median(F[k])/np.median(Q[l]) #Manu test\n",
    "\n",
    "    plt.plot(mjd.loc[objects[k]][::2], F.loc[objects[k]][::2], c='C0', linewidth = 1)\n",
    "    plt.plot(mjd.loc[objects[k]][1::2], F.loc[objects[k]][1::2], c='C1', linewidth = 1)\n",
    "\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][::2]*moy_alp, c='g', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][1::2]*moy_alp, c='r', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "\n",
    "    # Define the window of indices\n",
    "    window_start = -1-m + mjd.loc[objects[k]][0] # Index of the window start\n",
    "    window_end = int(len(Q[l])/2 - 1-1 -m)+ mjd.loc[objects[k]][0]  # Index of the window end\n",
    "\n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.4], indices, [indices[-1] + 0.4]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(Q[l])/1.2*moy_alp, max(Q[l])*1.2*moy_alp, color='gray', alpha=0.2)\n",
    "\n",
    "    # plt.xlabel('Index')\n",
    "    plt.ylabel('Flux')\n",
    "    # plt.title('Flux Plot')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(top=0.93)  # Adjust the top margin for the super title\n",
    "    plt.suptitle(f\"{objects[k]}, k = {k}, l = {l} \", fontname='Arial', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def on_button_clicked_plot(Id):\n",
    "    print(\"URL opened\")\n",
    "    open_website(Id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bebc9",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4c747",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670655f-2e62-4f52-a2ab-f2e3c760a569",
   "metadata": {},
   "source": [
    "\n",
    "# Nearest query : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de3c18-f08f-4f18-b10b-f7e9c4b17edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_Q_K_i = selected_Q_K_i[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd10a74-19fc-45d0-9ce3-51c886877774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearst_query = {}\n",
    "dis = []\n",
    "for l, list_l in enumerate(selected_Q_K_i):\n",
    "    #print(l, list)\n",
    "    k,i = list_l\n",
    "    \n",
    "    nearst_query[l] = [-1,float('inf')]\n",
    "    for l_after, list_after in enumerate(selected_Q_K_i[l+1:]):\n",
    "        l_after += l+1\n",
    "        # print(l, list,l_after, list_after)\n",
    "        k_after, i_after = list_after\n",
    "        if k_after != k :\n",
    "            distance = d[k_after][l][i_after]\n",
    "            # print(distance)\n",
    "            if nearst_query[l][1] > distance :\n",
    "                nearst_query[l] = [l_after,distance]\n",
    "            \n",
    "    for l_before, list_before in enumerate(selected_Q_K_i[:l]):\n",
    "        # l_after += l+1\n",
    "        # print(l, list,l_after, list_after)\n",
    "        k_before, i_before = list_before\n",
    "        if k_before != k :\n",
    "    \n",
    "            distance = d[k][l_before][i]\n",
    "            # print(distance)\n",
    "            if nearst_query[l][1] > distance :\n",
    "                nearst_query[l] = [l_before,distance] \n",
    "    \n",
    "    dis.append(nearst_query[l][1])\n",
    "\n",
    "nearst_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5adb5-70f1-426a-8103-9bd658dabaff",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72574783-fd60-45b5-aec8-8f67debdb1a8",
   "metadata": {},
   "source": [
    "\n",
    "# Nearst window(with only one match) to each query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82d6e5-4957-4164-9c37-510889414954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearst_window_1 = {}\n",
    "dis = [0]*L_max\n",
    "for l, list_l in enumerate(selected_Q_K_i):\n",
    "    # print(l, list_l)\n",
    "    k,i = list_l\n",
    "    \n",
    "    nearst_window_1[l] = [-1,-1,float('inf')],[-1,-1,float('inf')],[-1,-1,float('inf')]\n",
    "    # wind_l = list_l #get_k_i_of_Q(l)\n",
    "    \n",
    "    index = Reference_Table.tolist().index(list_l)#Reference_Table_list.index(wind_l)\n",
    "\n",
    "    # print(l,\"\\n\")\n",
    "    \n",
    "    for row, list_w in enumerate(Reference_Table[index+1:]):\n",
    "        row += index +1\n",
    "        k_window, i_window = list_w\n",
    "        \n",
    "        if sum_j_rows[row] == 1 and R[k_window][i_window] > l : \n",
    "            # print(index, row+index)\n",
    "            # print(k_window, i_window)\n",
    "\n",
    "            distance = d[k_window][l][i_window]\n",
    "            # print(distance)\n",
    "\n",
    "            if nearst_window_1[l][0][2] > distance :\n",
    "                distance3 = nearst_window_1[l][1][2]\n",
    "                distance2 = nearst_window_1[l][0][2]\n",
    "                k_window3 = nearst_window_1[l][1][0]\n",
    "                k_window2 = nearst_window_1[l][0][0]\n",
    "                i_window3 = nearst_window_1[l][1][1]\n",
    "                i_window2 = nearst_window_1[l][0][1]\n",
    "                nearst_window_1[l] = ([k_window, i_window, distance],[k_window2, i_window2, distance2],[k_window3, i_window3, distance3])\n",
    "    dis[l] = nearst_window_1[l][0][2]\n",
    "\n",
    "  \n",
    "\n",
    "nearst_window_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cd149",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840ce47-c0d5-4467-8d8f-0723d7ca3349",
   "metadata": {},
   "source": [
    "\n",
    "# Nearst query for each window : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485352bb-0c7d-4c66-b93c-e91eb4296532",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearst_q_to_w = [[-1,float('inf')]]*len(Reference_Table)\n",
    "for j,row in enumerate(Reference_Table):#[0:10]:\n",
    "    # print(row,j)\n",
    "    k_window , i_window = row\n",
    "    for l in range(L_max):\n",
    "        k_l , i_l = selected_Q_K_i[l]\n",
    "        if k_l >= k_window : \n",
    "            break\n",
    "        # print(l,k_l , i_l)\n",
    "        distance = d[k_window][l][i_window]\n",
    "        if nearst_q_to_w[j][1] > distance:\n",
    "            nearst_q_to_w[j] = [l,distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6bf20-7bd5-4b51-b9a4-51a6a7ac4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearst_q_to_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178c947-6657-4586-bed5-25529b114aff",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a88baf-0fb5-463c-90be-c85384e0f5e9",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb496f08",
   "metadata": {},
   "source": [
    "# plot by multiple l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f223f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for l in [0,1]:\n",
    "#     for k in [0,1]:\n",
    "#         plot_distance_flux(k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be99b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# l_values = [100,0]#range(119)\n",
    "# k_values=range(len(objects))\n",
    "# k=1\n",
    "# for l in l_values:\n",
    "#     for k in k_values[:7]:\n",
    "#         plot_distance_flux(k,l) # True == open website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd1b2a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5716a",
   "metadata": {},
   "source": [
    "## plot histogram of numbers of matches for each Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b5761",
   "metadata": {},
   "source": [
    "We graph the number of matches for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = range(len(sum_i_columns))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(indexes, bins=len(sum_i_columns), weights=sum_i_columns, color='C1', edgecolor='white')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Indices')\n",
    "plt.ylabel('Numbers')\n",
    "plt.title('Histogram of numbers of matches for each Q ')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute the highest and lowest 10 values and their indexes\n",
    "sorted_indices = sorted(range(len(sum_i_columns)), key=lambda i: sum_i_columns[i])\n",
    "lowest_10_indices = sorted_indices[:20]\n",
    "highest_10_indices = sorted_indices[-10:][::-1]  # Reverse to get in descending order\n",
    "\n",
    "total_windows = len(Matrix_Matches)\n",
    "\n",
    "# Print the highest and lowest 10 values and their indexes with percentages\n",
    "print(\"Highest 10:\\n\")\n",
    "for i in highest_10_indices:\n",
    "    percentage = (sum_i_columns[i] / total_windows) * 100\n",
    "    print(f\"Index: {i}, Matches: {sum_i_columns[i]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\n\\nLowest 10:\\n\")\n",
    "for i in lowest_10_indices:\n",
    "    percentage = (sum_i_columns[i] / total_windows) * 100\n",
    "    print(f\"Index: {i}, Matches: {sum_i_columns[i]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b1f97-b3cc-40b5-8b60-7203cc6b5922",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0303a3-f603-4638-aa12-4a60a0e52e78",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc5c19-90f3-4686-8793-a12463a5adcd",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f1d29-3e27-4a15-b9fb-26a3bc79b8ef",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5283323-43eb-4588-a004-d2abfa58425b",
   "metadata": {},
   "source": [
    "\n",
    "# sort the queries(with one match) by the max nearst distance of each one \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb998356-43f3-47e8-b04b-caec0a5d941d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert sorted_indices and sum_i_columns to numpy arrays if they aren't already\n",
    "sorted_indices = np.array(sorted_indices)\n",
    "sum_i_columns = np.array(sum_i_columns)\n",
    "\n",
    "# Use a boolean mask to find indices where sum_i_columns is less than or equal to 1\n",
    "mask = sum_i_columns[sorted_indices] <= 1\n",
    "\n",
    "# Get the corresponding indices\n",
    "indices_1_match = sorted_indices[mask]\n",
    "\n",
    "# Assuming dis is already a numpy array or convert it if necessary\n",
    "dis = np.array(dis)\n",
    "\n",
    "# Use indices_1_match to index dis\n",
    "dis_1_match = dis[indices_1_match]\n",
    "\n",
    "# Sort dis_1_match and get the sorted indices\n",
    "sorted_dis_1_match_indices = np.argsort(dis_1_match)\n",
    "\n",
    "# Sort indices_1_match based on sorted_dis_1_match_indices\n",
    "sorted_indices_1_match = indices_1_match[sorted_dis_1_match_indices]\n",
    "\n",
    "# Result: sorted indices of sum_i_columns based on sorted dis_1_match values\n",
    "sorted_indices_1_match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fc6c3-c8fa-4404-9804-019e8fb721cc",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c573b-bd7c-4e16-a5d8-ef7730ee285b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "def on_button_clicked(k,l):\n",
    "    print(\"Button clicked:\")\n",
    "    plot_distance_flux(k,l)\n",
    "\n",
    "# Create the button widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"###################  m = \", m ,\"######################\")\n",
    "c= 0 \n",
    "for l in sorted_indices:#sorted_indices_1_match[::-1]:#sorted_indices:#[0:1549]:\n",
    "#for l in indexes_5:\n",
    "    #l = sorted_indices[r]\n",
    "    k , i = selected_Q_K_i[l]\n",
    "    # Nb_valid = np.sum(is_valid[objects[k]][i*2:i*2+chunk_size])\n",
    "\n",
    "    # if Nb_valid < chunk_size -1:\n",
    "    #     continue\n",
    "    if sum_i_columns[l] >1 :\n",
    "            break \n",
    "    c+=1\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------------------------------------------\",l,\"\\n\")\n",
    "    print(\"----------------------------------------NEW OBJECT --------------------------------------------------------\\n\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    print(f\"Q[{l}] , Matches on this Query: {sum_i_columns[l]}\")\n",
    "    \n",
    "    # print('Nb_valid', Nb_valid)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Ratio :\",Q[l][0]/Q[l][1])\n",
    "    \n",
    "    print(f\"Object of this Q : {objects[k]} : https://fink-portal.org/{objects[k]}\")\n",
    "\n",
    "    \n",
    "    non_zero_indexes = np.nonzero(num_by_obj[l])[0]\n",
    "    non_zero_indexes, len(non_zero_indexes)\n",
    "    print(\"\\nNumber of objects that have matches on this Q :\", len(non_zero_indexes))\n",
    "    print(\"Objects that have matches on this Q : \", non_zero_indexes,\"\\n\")\n",
    "    \n",
    "    for kk in non_zero_indexes:\n",
    "        print(f\"https://fink-portal.org/{objects[kk]}\" , \" : Nb of mathces : \",num_by_obj[l][kk])\n",
    "        button = widgets.Button(description=f\"plot {objects[kk]}\")\n",
    "        # Capture current values of kk and l in lambda's default arguments\n",
    "        button.on_click(lambda _, kk=kk, l=l: on_button_clicked(kk, l))\n",
    "        display(button)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    plot_distance_flux(k,l)\n",
    "\n",
    "    \"\"\"print(\"------------------------------- nearst query --------------------------------------------\")\n",
    "\n",
    "    l_nearst, d_nearst = nearst_query[l]\n",
    "    k_nearst , i_nearst = selected_Q_K_i[l_nearst]\n",
    "    \n",
    "    if l_nearst < l:\n",
    "        plot_distance_flux_min(k_nearst,l_nearst,i_nearst)\n",
    "    else:\n",
    "        plot_distance_flux_min(k_nearst,l,i_nearst)\"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"print(\"------------------------------- nearst window with one match --------------------------------------------\")\n",
    "\n",
    "    k_nearst , i_nearst, d_nearst = nearst_window_1[l][0]\n",
    "    # k_nearst , i_nearst = selected_Q_K_i[l_nearst]\n",
    "    print(i_nearst)\n",
    "    print(\"Distance = \",d_nearst)\n",
    "    \n",
    "    # plot_distance_flux(k_nearst,l)\n",
    "    plot_distance_flux_min(k_nearst,l,i_nearst)\n",
    "    \n",
    "\n",
    "    print(\"------------------------------- nearst window --------------------------------------------\")\n",
    "\n",
    "    min_d_d  = min_d[3*l]\n",
    "    min_d_k = min_d[3*l+1]\n",
    "    min_d_i = min_d[3*l+2]\n",
    "    \n",
    "    if min_d_d != float('inf') : \n",
    "        # print(min_d_d, min_d_k,min_d_i)\n",
    "        print(\"distance :\",min_d_d)\n",
    "        print(\"K :\", min_d_k)\n",
    "        print(\"mjd :\", mjd[objects[k]][min_d_i*2])\n",
    "        # plot_distance_flux(min_d_k,l)\n",
    "        plot_distance_flux_min(min_d_k,l,min_d_i)\n",
    "    else : \n",
    "        print(\"no min found\")\n",
    "        print(\"---------------------------------------------------------------------------\")\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b45c98-7595-4bb3-9a74-7564017d8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0531c-b2b9-471f-8018-261cea65af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a08dd-1b2a-4152-9aec-3b84c6f6734d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909343e-163b-432f-8466-78805222e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_indices = sorted_indices[:-2]\n",
    "l, len(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already imported numpy as np\n",
    "\n",
    "# Create a list to store dictionaries with the information\n",
    "data = []\n",
    "\n",
    "for l in sorted_indices:#[0:10]:\n",
    "    #print(l)\n",
    "    # if l not in range(0,len(Q)):\n",
    "    #     continue\n",
    "        \n",
    "    Q_ratio = (Q[l][::2]).sum()/(Q[l][1::2]).sum() / (m + 1)#Q[l][0] / Q[l][1]\n",
    "    k, i = selected_Q_K_i[l]\n",
    "    non_zero_indexes = np.nonzero(num_by_obj[l])[0]\n",
    "    #Nb_valid = np.sum(is_valid[objects[k]][i*2:i*2+chunk_size])\n",
    "    url_and_matches = []\n",
    "    for kk in non_zero_indexes:\n",
    "        url_and_matches.append(f\"https://fink-portal.org/{objects[kk]} : Nb of matches : {num_by_obj[l][kk]}\")\n",
    "    \n",
    "    str = \"\" \n",
    "    for index, row in dataframes[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        str += f\"  {classification} : {percentage:.1f}% \\n\"\n",
    "        \n",
    "    # Create a dictionary for each iteration\n",
    "    row = {\n",
    "        'Query': l,\n",
    "        'Matches on this Query': sum_i_columns[l],\n",
    "        'Ratio': Q_ratio,\n",
    "        'Object of this Q': objects[k],\n",
    "        'Link': f\"https://fink-portal.org/{objects[k]}\",\n",
    "        'class': str,\n",
    "        #'Nb_valid' : Nb_valid,\n",
    "        'mjd ': mjd.loc[objects[k]][2*i], \n",
    "        'Annotation': '',\n",
    "        'min d (nearst window 1 match)': nearst_window_1[l][0][2],\n",
    "        'Number of objects': len(non_zero_indexes),\n",
    "        'Objects with matches': non_zero_indexes.tolist(),\n",
    "        'URLs and Matches': '\\n'.join(url_and_matches)\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the data list\n",
    "    data.append(row)\n",
    "    \n",
    "    if sum_i_columns[l] >1 :\n",
    "        break \n",
    "    \n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Export DataFrame to Excel\n",
    "df.to_excel(f'lowest_Q_EM_GP_m{m}_o1-2_real_@.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265abe23-059d-4dae-9bea-8824fff07d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df#['min d (nearst window 1 match)'].iloc[0][0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d458b-ccfd-487a-bf73-64f6a273c0c4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89c22b-873e-4dea-aa97-210d55faf45b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706598f-c0fa-480a-9430-a278bd1a65fe",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d9534-cd2b-4a8d-a0ac-b9aa12a6e2aa",
   "metadata": {},
   "source": [
    "# Percentage of classes  without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a297a-f06d-414d-b4c5-50d91412ee0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rangek3 = [] # unique objects with 1 match (as query ) \n",
    "for l in sorted_indices:\n",
    "    if sum_i_columns[l] >1 :\n",
    "        break \n",
    "    k, i = selected_Q_K_i[l]\n",
    "    if k not in rangek3:\n",
    "        rangek3.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b4af2-7321-4429-9bdb-946f6ffaa0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes_wr = {}\n",
    "c= len(rangek3)\n",
    "\n",
    "for k in rangek3 :\n",
    "    df = dataframes[objects[k]]  # Example call, modify as necessary\n",
    "    \n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        \n",
    "        if class_name in classes_wr:\n",
    "            classes_wr[class_name][0] += percentage\n",
    "            classes_wr[class_name][1] += error_bar**2\n",
    "        else:\n",
    "            classes_wr[class_name] = [percentage,error_bar**2]\n",
    "\n",
    "    # classes.append(get_classification3(objects[k]))\n",
    "for class_name, list1 in classes_wr.items():\n",
    "    classes_wr[class_name][0] = round(list1[0] / c , 2)\n",
    "    classes_wr[class_name][1] = np.sqrt(list1[1]) / c\n",
    "sorted_classes_wr = dict(sorted(classes_wr.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_classes_wr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e19c2-68a6-4987-90bb-74e69b7b340c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of all possible groups to merge\n",
    "groups_to_merge = {\n",
    "    'EB*': ['Candidate_EB*', 'EB*_Candidate'],\n",
    "    #'LPV*': ['Candidate_LP*', 'LP*_Candidate'],\n",
    "    'RRLyr': ['Candidate_RRLyr', 'RRLyr_Candidate'],\n",
    "    'CV*': ['Candidate_CV*', 'CV*_Candidate'],\n",
    "    'WD*': [ 'WD*_Candidate'],\n",
    "    #'YSO': ['Candidate_YSO', 'YSO_Candidate'],\n",
    "    #'C*': ['Candidate_C*', 'C*_Candidate'],\n",
    "    #'RSG*': ['RSG*_Candidate'],\n",
    "    #'RGB*': [ 'RGB*_Candidate'],\n",
    "}\n",
    "\n",
    "# Initialize the new dictionary with the original data, excluding the ones to be merged\n",
    "merged_data = {k: v for k, v in sorted_classes_wr.items() if k not in sum(groups_to_merge.values(), [])}\n",
    "\n",
    "# Function to combine values and propagate errors\n",
    "def combine_values_and_errors(keys):\n",
    "    combined_value = sum(sorted_classes_wr[key][0] for key in keys)\n",
    "    combined_error = np.sqrt(sum(sorted_classes_wr[key][1]**2 for key in keys))\n",
    "    return [combined_value, combined_error]\n",
    "\n",
    "# Merge the groups\n",
    "for new_key, old_keys in groups_to_merge.items():\n",
    "    if new_key in sorted_classes_wr:\n",
    "        all_keys = [new_key] + old_keys\n",
    "    else:\n",
    "        all_keys = old_keys\n",
    "    merged_data[new_key] = combine_values_and_errors(all_keys)\n",
    "\n",
    "# Sort the merged data\n",
    "sorted_classes_wr_m = dict(sorted(merged_data.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "# Output the result\n",
    "sorted_classes_wr_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27058329-7700-4ed6-b475-e4cf83460478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_classes0_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef3af-a6f9-471f-8e82-75fd5522b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 \n",
    "all_objects = dict(list(sorted_classes0_m.items())[:nb_classes])\n",
    "anomalous_objects =  dict(list(sorted_classes_wr_m.items())[:nb_classes])\n",
    "# Extracting data for plotting\n",
    "classes = list(all_objects.keys())\n",
    "percentages_all = [all_objects[cls][0] for cls in classes]\n",
    "errors_all = [all_objects[cls][1] for cls in classes]\n",
    "\n",
    "percentages_anomalous = [anomalous_objects.get(cls, [0, 0])[0] for cls in classes]\n",
    "errors_anomalous = [anomalous_objects.get(cls, [0, 0])[1] for cls in classes]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(classes))\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot for all objects\n",
    "bars_all = ax.bar(x - width/2, percentages_all, width, yerr=errors_all, label='All Objects', capsize=5)\n",
    "\n",
    "# Plot for anomalous objects\n",
    "bars_anomalous = ax.bar(x + width/2, percentages_anomalous, width, yerr=errors_anomalous, label='Anomalous Objects', capsize=5)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Classes')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Class Distribution Comparison Without repetition')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Adding percentage labels on top of the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(bars_all)\n",
    "add_labels(bars_anomalous)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a53fab-1901-4e9c-8656-28f20ff2e639",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce496764-e949-4bb3-b9ec-dd13fef4b9aa",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d6f0d-5b43-4eb4-a724-2a62f64bdf5e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedd90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"Num_for_Qs_EXM.csv\"\n",
    "\n",
    "# Combine the data into a list of tuples\n",
    "data = list(zip(indexes, sum_i_columns))\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write a header if needed\n",
    "    csv_writer.writerow(['Queries', 'Nb of matches'])\n",
    "    \n",
    "    # Write the data\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(\"Data has been written to\", file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbf69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6986c3b4",
   "metadata": {},
   "source": [
    "We calculate the minimum and maximum number of matches, along with their corresponding indexes (where index represents the index of the query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(sum_i_columns),min(sum_i_columns),np.argmax(sum_i_columns), np.argmin(sum_i_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362f13c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c2107",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc95f9-0b69-4bfe-aa61-fc92797bf9b8",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20131ca1-9253-4ea8-aaaf-8ab20a9562a5",
   "metadata": {},
   "source": [
    "# Classes with repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a8d8a-251d-46a7-affc-1ac81a70268c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = {}\n",
    "c=0\n",
    "for l in sorted_indices:#[0:13]:\n",
    "    c+=1\n",
    "    if sum_i_columns[l] >1 :\n",
    "        break \n",
    "    k, i = selected_Q_K_i[l]\n",
    "\n",
    "    df = dataframes[objects[k]]  # Example call, modify as necessary\n",
    "    \n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        \n",
    "        if class_name in classes:\n",
    "            classes[class_name][0] += percentage\n",
    "            classes[class_name][1] += error_bar**2\n",
    "        else:\n",
    "            classes[class_name] = [percentage,error_bar**2]\n",
    "\n",
    "    # classes.append(get_classification3(objects[k]))\n",
    "for class_name, list1 in classes.items():\n",
    "    classes[class_name][0] = round(list1[0] / c , 2)\n",
    "    classes[class_name][1] = np.sqrt(list1[1]) / c\n",
    "sorted_classes = dict(sorted(classes.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb183c22-2557-4710-b2bc-cc34f855c5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# List of all possible groups to merge\n",
    "groups_to_merge = {\n",
    "    'EB*': ['Candidate_EB*', 'EB*_Candidate'],\n",
    "    # 'LPV*': ['Candidate_LP*', 'LP*_Candidate'],\n",
    "    # 'RRLyr': ['Candidate_RRLyr', 'RRLyr_Candidate'],\n",
    "    # 'CV*': ['Candidate_CV*', 'CV*_Candidate'],\n",
    "    # 'WD*': [ 'WD*_Candidate'],\n",
    "    # 'YSO': ['Candidate_YSO', 'YSO_Candidate'],\n",
    "    # 'C*': ['Candidate_C*', 'C*_Candidate'],\n",
    "    # 'RSG*': ['RSG*_Candidate'],\n",
    "    # 'RGB*': [ 'RGB*_Candidate'],\n",
    "}\n",
    "\n",
    "# Initialize the new dictionary with the original data, excluding the ones to be merged\n",
    "merged_data = {k: v for k, v in sorted_classes.items() if k not in sum(groups_to_merge.values(), [])}\n",
    "\n",
    "# Function to combine values and propagate errors\n",
    "def combine_values_and_errors(keys):\n",
    "    combined_value = sum(sorted_classes[key][0] for key in keys)\n",
    "    combined_error = np.sqrt(sum(sorted_classes[key][1]**2 for key in keys))\n",
    "    return [combined_value, combined_error]\n",
    "\n",
    "# Merge the groups\n",
    "for new_key, old_keys in groups_to_merge.items():\n",
    "    if new_key in sorted_classes:\n",
    "        all_keys = [new_key] + old_keys\n",
    "    else:\n",
    "        all_keys = old_keys\n",
    "    merged_data[new_key] = combine_values_and_errors(all_keys)\n",
    "\n",
    "# Sort the merged data\n",
    "sorted_classes_m = dict(sorted(merged_data.items(), key=lambda item: item[1][0], reverse=True))\n",
    "\n",
    "# Output the result\n",
    "sorted_classes_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b563462-867b-4073-a227-bfe08b4fbe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 \n",
    "all_objects = dict(list(sorted_classes0_m.items())[:nb_classes])\n",
    "anomalous_objects =  dict(list(sorted_classes_m.items())[:nb_classes])\n",
    "# Extracting data for plotting\n",
    "classes = list(all_objects.keys())\n",
    "percentages_all = [all_objects[cls][0] for cls in classes]\n",
    "errors_all = [all_objects[cls][1] for cls in classes]\n",
    "\n",
    "percentages_anomalous = [anomalous_objects.get(cls, [0, 0])[0] for cls in classes]\n",
    "errors_anomalous = [anomalous_objects.get(cls, [0, 0])[1] for cls in classes]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(classes))\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot for all objects\n",
    "bars_all = ax.bar(x - width/2, percentages_all, width, yerr=errors_all, label='All Objects', capsize=5)\n",
    "\n",
    "# Plot for anomalous objects\n",
    "bars_anomalous = ax.bar(x + width/2, percentages_anomalous, width, yerr=errors_anomalous, label='Anomalous Objects', capsize=5)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Classes')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Class Distribution Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Adding percentage labels on top of the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(bars_all)\n",
    "add_labels(bars_anomalous)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2276f35-c67a-4046-9c24-99fd9cabb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `all_objects` and `anomalous_objects` dictionaries are already defined\n",
    "\n",
    "# Extracting data\n",
    "classes = list(all_objects.keys())\n",
    "percentages_all = [all_objects[cls][0] for cls in classes]\n",
    "errors_all = [all_objects[cls][1] for cls in classes]\n",
    "\n",
    "percentages_anomalous = [anomalous_objects.get(cls, [0, 0])[0] for cls in classes]\n",
    "errors_anomalous = [anomalous_objects.get(cls, [0, 0])[1] for cls in classes]\n",
    "\n",
    "x = np.arange(len(classes))  # label locations\n",
    "width = 0.4  # width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(14, 10), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Stacked Bar Plot\n",
    "bars_all = ax[0].bar(x - width/2, percentages_all, width, label='All Objects', color='skyblue')\n",
    "bars_anomalous = ax[0].bar(x + width/2, percentages_anomalous, width, label='Anomalous Objects', color='salmon')\n",
    "\n",
    "# Adding percentage labels on top of the bars\n",
    "def add_labels(bars, ax):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(bars_all, ax[0])\n",
    "add_labels(bars_anomalous, ax[0])\n",
    "\n",
    "ax[0].set_xlabel('Classes')\n",
    "ax[0].set_ylabel('Percentage')\n",
    "ax[0].set_title('Class Distribution Comparison')\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax[0].legend()\n",
    "\n",
    "# Error Bars Plot\n",
    "ax[1].errorbar(x - width/2, percentages_all, yerr=errors_all, fmt='o', label='All Objects', color='blue', capsize=5)\n",
    "ax[1].errorbar(x + width/2, percentages_anomalous, yerr=errors_anomalous, fmt='o', label='Anomalous Objects', color='red', capsize=5)\n",
    "\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax[1].set_xlabel('Classes')\n",
    "ax[1].set_ylabel('Error Bars')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13179288-89e8-4d94-a19a-ba781e73adf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "def plot_distributions(data, title):\n",
    "    classes = list(data.keys())\n",
    "    counts = [data[cls][0] for cls in classes]\n",
    "    errors = [data[cls][1] for cls in classes]\n",
    "    \n",
    "    # Assuming percentages can be interpreted as probabilities (for large sample sizes)\n",
    "    total = 100  # Total count if percentages are based on 100\n",
    "    proportions = np.array(counts) / 100\n",
    "    \n",
    "    fig, axs = plt.subplots(len(classes), 2, figsize=(14, 2*len(classes)))\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        n = total\n",
    "        p = proportions[i]\n",
    "        mu = n * p\n",
    "        sigma = np.sqrt(n * p * (1 - p))\n",
    "        \n",
    "        x = np.arange(0, n + 1)\n",
    "        binom_pmf = stats.binom.pmf(x, n, p)\n",
    "        norm_pdf = stats.norm.pdf(x, mu, sigma)\n",
    "        \n",
    "        # Binomial PMF\n",
    "        axs[i, 0].stem(x, binom_pmf, basefmt=\" \")\n",
    "        axs[i, 0].set_title(f'Binomial PMF of {cls}')\n",
    "        axs[i, 0].set_xlabel('x')\n",
    "        axs[i, 0].set_ylabel('Probability')\n",
    "        \n",
    "        # Normal PDF approximation\n",
    "        axs[i, 1].plot(x, norm_pdf, 'r-', lw=2)\n",
    "        axs[i, 1].set_title(f'Normal PDF Approximation of {cls}')\n",
    "        axs[i, 1].set_xlabel('x')\n",
    "        axs[i, 1].set_ylabel('Density')\n",
    "        \n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()\n",
    "\n",
    "# Plotting distributions\n",
    "plot_distributions(all_objects, \"All Objects\")\n",
    "plot_distributions(anomalous_objects, \"Anomalous Objects\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa14d3-293b-4d39-ae2c-1fda5be62ed2",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0883c4-3ee5-4eb1-8e61-c0fcdf13cbd3",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98055f-f044-4f83-9ebc-00a38d552094",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_unique_ids_from_file(file_path):\n",
    "    # Read the file and store each line as an element in a list\n",
    "    with open(file_path, 'r') as file:\n",
    "        unique_ids = file.read().splitlines()\n",
    "    \n",
    "    return unique_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f46ee5-0572-4b1f-a3be-6196fb8575fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "folder_name = 'test2'\n",
    "IDS = read_unique_ids_from_file('../scripts/unique_ids.txt')\n",
    "classes = {}\n",
    "# for k in rangek3:\n",
    "#     Id = objects[k]\n",
    "c = 0\n",
    "for Id in IDS:\n",
    "    # print(Id)\n",
    "    file_name = f'{Id}.parquet'\n",
    "    #print(file_name)\n",
    "    \n",
    "    file_path = f'../scripts/{folder_name}/{file_name}'\n",
    "        # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        c+=1\n",
    "        # Read the Parquet file into a DataFrame\n",
    "        data = pd.read_parquet(file_path)\n",
    "        for index, row in data.iterrows():\n",
    "            classification = row['classification']\n",
    "            percentage = row['percentage']\n",
    "            if classification in classes:\n",
    "                classes[classification] += percentage\n",
    "            else:\n",
    "                classes[classification] = percentage\n",
    "\n",
    "        \n",
    "    else:\n",
    "        pass #print(f\"File not found: {file_path}\")\n",
    "for class_name, percentage in classes.items():\n",
    "    classes[class_name] = round(percentage / c , 1)\n",
    "sorted_classes = dict(sorted(classes.items(), key=lambda item: item[1], reverse=True))        \n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")\n",
    "\n",
    "sorted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c011a51-d013-49c7-a2c0-ed8b7bdc81b1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb24a58",
   "metadata": {},
   "source": [
    "### plot Qr/Qg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ea09f-d444-40c4-850e-847348c154ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Q),len(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4314fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_array = np.array(Q)\n",
    "ratios = Q_array[:, 0] / Q_array[:, 1]\n",
    "\n",
    "plt.plot(ratios)\n",
    "plt.title('Ratio of First Value to Second Value')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e29a4",
   "metadata": {},
   "source": [
    "### Here, we plot the number of matches as a function of the ratios (Qr/Qg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d36901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_array = np.array(Q)\n",
    "ratios = Q_array[:, 0] / Q_array[:, 1]\n",
    "\n",
    "plt.scatter(ratios[:-3],sum_i_columns[:-3]) ###################### -3 to exclude the 800 .. \n",
    "plt.title('num of matches for each Q in function of Ratio ')\n",
    "plt.xlabel('Ratio Qr/Qg')\n",
    "plt.ylabel('num(l)')\n",
    "plt.grid(True)\n",
    "# plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nHighest 10 Ratios, Matches, and Indices:\\n\")\n",
    "for i in range(10):\n",
    "    index = highest_10_indices[i]\n",
    "    ratio = ratios[index]\n",
    "    matches = sum_i_columns[index]\n",
    "    print(\"Index:\", index, \"Ratio:\", ratio, \"Matches:\", matches)\n",
    "    \n",
    "print(\"\\n\\nLowest 10 Ratios, Matches, and Indices:\\n\")\n",
    "for i in range(10):\n",
    "    index = lowest_10_indices[i]\n",
    "    ratio = ratios[index]\n",
    "    matches = sum_i_columns[index]\n",
    "    print(\"Index:\", index, \"Ratio:\", ratio, \"Matches:\", matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf037f3-1736-488b-aefe-f81b9f91ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, r in enumerate(ratios):\n",
    "    if r > 300:\n",
    "        print(index, ratios[index], Q[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b6e75-b0b8-4bc8-b903-712627079db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios[15], Q[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51060abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_Q_K_i[299], objects[854],plot_distance_flux(854, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"ratios_Q_119_EXM.csv\"\n",
    "\n",
    "# Combine the data into a list of tuples\n",
    "data = list(zip(ratios, sum_i_columns))\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(file_name, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write a header if needed\n",
    "    csv_writer.writerow(['Ratio', 'Sum of i Columns'])\n",
    "    \n",
    "    # Write the data\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(\"Data has been written to\", file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96434a5",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1e29e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3684c6",
   "metadata": {},
   "source": [
    "### Compute the highest and the lowest indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71165151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest_indices_array = []\n",
    "sorted_queries_list = []\n",
    "\n",
    "\n",
    "for l in range(len(num_by_obj)):\n",
    "\n",
    "    array = np.array(num_by_obj[l])\n",
    "\n",
    "    # Get indices of sorted array in ascending order\n",
    "    sorted_queries = np.argsort(array)\n",
    "    sorted_queries_list.append(sorted_queries)  # Append sorted indices list\n",
    "\n",
    "#     # Indices of 10 lowest values\n",
    "\n",
    "#     lowest_values = array[sorted_indices[0]]\n",
    "#     all_lowest_indices = np.where(array == lowest_values)[0]\n",
    "#     lowest_indices_array.append(all_lowest_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624740b1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce94c16",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23668aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_by_obj[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf12a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in rangek:\n",
    "#     print(np.sum(Matrices_by_k[k], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9f6be",
   "metadata": {},
   "source": [
    "## plot histogram of numbers of matches for all objects with a specific Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab74e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=108\n",
    "indexes = range(len(num_by_obj[l]))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(indexes, bins=len(num_by_obj[l]), weights=num_by_obj[l], color='C1', edgecolor='black')\n",
    "plt.xlabel('Objects')\n",
    "plt.ylabel('Numbers')\n",
    "plt.title('Histogram of numbers of matches for a specific Q for all objects')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "total_queries = len(Q)\n",
    "lowest_10_indices = sorted_queries_list[l][:10]\n",
    "\n",
    "\n",
    "array = np.array(num_by_obj[l])\n",
    "lowest_value = array[sorted_queries_list[l][0]]\n",
    "all_lowest_indices = np.where(array == lowest_value)[0]\n",
    "\n",
    "lowest_10_indices_1 = sorted_queries_list[l][len(all_lowest_indices):len(all_lowest_indices)+10]\n",
    "# These aren't simply the lowest 10 values; rather,\n",
    "#they represent the lowest 10 values with the condition that their number of matches exceeds\n",
    "#that of the lowest value. Suppose the lowest value of matches is 0, these objects are those with more than 0 matches.\n",
    "# (the lowest ones with Nb matches > 0  ).\n",
    "\n",
    "\n",
    "highest_10_indices = sorted_queries_list[l][-10:][::-1]  # Reverse to get in descending order\n",
    "\n",
    "# Print the highest and lowest 10 values and their indexes with percentages\n",
    "print(f\"Q[{l}]:\\n\")\n",
    "print(\"Highest 10:\\n\")\n",
    "for k in highest_10_indices:\n",
    "    percentage = (num_by_obj[l][k] / total_queries) * 100\n",
    "    print(f\"Index: {k}, Id : {objects[k]}, Matches: {num_by_obj[l][k]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\nLowest 10:\\n\")\n",
    "for k in lowest_10_indices:\n",
    "    percentage = (num_by_obj[l][k] / total_queries) * 100\n",
    "    print(f\"Index: {k}, Id : {objects[k]}, Matches: {num_by_obj[l][k]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\nLowest 10 with Nb matches > (lowest Nb):\\n\")\n",
    "for k in lowest_10_indices_1:\n",
    "    percentage = (num_by_obj[l][k] / total_queries) * 100\n",
    "    print(f\"Index: {k}, Id : {objects[k]}, Matches: {num_by_obj[l][k]}, Percentage: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indexes = np.nonzero(num_by_obj[108])[0]\n",
    "num_by_obj[108][non_zero_indexes], non_zero_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c66091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in highest_10_indices[8:9]:\n",
    "    plot_distance_flux(k, 108,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bd61d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31633296",
   "metadata": {},
   "outputs": [],
   "source": [
    "k= 100 \n",
    "for k in rangek:\n",
    "    print(k, num_by_obj[l][k]/length_no_missing[k]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f0e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_by_obj[l][136], count_missing_windows[136], len(R[136])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k= 864 \n",
    "num_by_obj[l][k],length_no_missing[k], count_missing_windows[k], len(R[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc436f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_distance_flux(k,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c67b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lensss = list(map(len, R))\n",
    "\n",
    "lensss  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea15411",
   "metadata": {},
   "source": [
    "### We restrict the selection of objects to those with a specific count of missing windows! \n",
    "Therefore, we prioritize objects with the highest number of intact windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_missing_windows = np.array([np.sum(subarr == -99) for subarr in R])\n",
    "\n",
    "result = np.where(count_missing_windows <=10, True, False)\n",
    "# The result array represents the condition for each object (i.e., objects with few missing windows).\n",
    "result,len(result),count_missing_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8297ea",
   "metadata": {},
   "source": [
    "We extract the indices where the condition is true, representing the objects with the highest numbers of normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914576e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = np.where(result)[0]\n",
    "l = 0\n",
    "selected_arrays = num_by_obj[l][indices]\n",
    "selected_arrays, indices, len(selected_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca54c8f",
   "metadata": {},
   "source": [
    "We indentify and plot the object with the highest number of matches for a query \"l\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb46bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = indices[np.argmax(selected_arrays)]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = selected_Q_K_i != None\n",
    "for index_Q, (k1, i) in enumerate(selected_Q_K_i[mask]):\n",
    "    if 17435 == k1 :\n",
    "        print(f\"This window is used as the {index_Q}th query! \")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff183596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_flux(1,l), print(objects[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6412d8b",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3caa113",
   "metadata": {},
   "source": [
    "### Generate a plot illustrating the match counts of the selected objects(Limited to missing window counts.) for a particular query, Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e010d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "indexes = range(len(num_by_obj[l][indices]))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(indexes, bins=len(num_by_obj[l][indices]), weights=num_by_obj[l][indices], color='skyblue', edgecolor='C0')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Indices')\n",
    "plt.ylabel('Numbers')\n",
    "plt.title('Histogram of numbers of matches for a specific Q for a limited nb of objects')\n",
    "\n",
    "# Display the histoazgram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5031b0",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a516e22",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69c58e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41abc0",
   "metadata": {},
   "source": [
    "### plot the highest and the lowest indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25c677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l=94\n",
    "count = 1\n",
    "for k in sorted_indices_list[l][len(lowest_indices_array[l]):len(lowest_indices_array[l])+10]:\n",
    "    print(count)\n",
    "    count += 1\n",
    "    print(objects[k],k,\"l =\",l,\".\")\n",
    "    print(\"Number of matches in this object of this Q\",num_by_obj[l][k])\n",
    "    plot_distance_flux(k,l,True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44927b",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146c91d",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e118c",
   "metadata": {},
   "source": [
    "# Negative Flux ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973582d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negatives = []\n",
    "k_negatives = []\n",
    "for k in rangek:\n",
    "    if np.any(F[objects[k]] <0):\n",
    "        k_negatives.append(k)\n",
    "        negative_mask = F[objects[k]] < 0 \n",
    "        negatives.append(F[objects[k]][negative_mask] / sig[objects[k]][negative_mask])\n",
    "\n",
    "negatives,k_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, list1 in enumerate(negatives):\n",
    "    #print(list1)\n",
    "    if np.any(np.array(list1) <-3):\n",
    "        print(F[objects[k_negatives[idx]]]/sig[objects[k_negatives[idx]]])\n",
    "        plot_distance_flux(k_negatives[idx],0,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e099d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "F[objects[5053]]/sig[objects[5053]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df2461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ravel = np.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5484471",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ravel,bins='fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8231cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in k_negatives[:3]:\n",
    "    plot_distance_flux(k,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f67e2a",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619cdc1",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed5d36",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac69fd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b3351",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339863a1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9af60",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f409654",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6d10d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d8b93",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5260a",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
