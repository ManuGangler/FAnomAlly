{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a049a-f8d6-4d0c-8d0b-7a64adba3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39761033",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c647a84",
   "metadata": {},
   "source": [
    "We begin by fetching the reduced data using the Python script `data_transfer.py` from the file `df_merged.parquet`, then importing it into Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../scripts/df_GP_2nd_bug.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a6c02-6c62-4ba9-9558-e13a61171477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.source.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94d88b",
   "metadata": {},
   "source": [
    "Here we extract all unique IDs from our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e814c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df['objectId'].unique().tolist()\n",
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df18f04",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4b38e",
   "metadata": {},
   "source": [
    "To calculate the weight values \\(w_i\\), we use the formula: `w_i` =\\begin{cases}\n",
    "\\frac{1}{{\\sigma_i^2}}, & \\text{if data is available for day } i \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ab189-58b7-4869-91be-1cc612883f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = (df['dc_sigflux'] == 0)\n",
    "df['dc_weight'] = np.where(missing_data, 0, 1 / (df['dc_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['source','dc_weight']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef1374",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf1c2f-68aa-427f-b465-1763e3721d09",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee9a7d-a1c7-404d-a835-3257262d0972",
   "metadata": {},
   "source": [
    "# Percentenge of classes (classification) for all data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18206e5-5d2e-4be0-af77-4e3fac9de9ae",
   "metadata": {},
   "source": [
    "The `Classifications_arch` folder stores the pre-computed classifications for each object in our datasets. These classifications are generated by the `Rn_jobs_th.py` script located in the `classification_functs` directory. Pre-computing the classifications saves time by storing the results for later analysis, making our workflow more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96fa16-9478-4db2-b779-b0c9e1f2f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to unique IDs\n",
    "ids_file_path = '../scripts/Classifications_arch/unique_ids.txt'\n",
    "\n",
    "# Read the file and store each line as an element in a list\n",
    "with open(ids_file_path, 'r') as file:\n",
    "    IDS = file.read().splitlines()\n",
    "\n",
    "# Initialize an empty list to store individual df_Classifications_arch\n",
    "df_Classifications_arch = {}\n",
    "\n",
    "# Folder name where the parquet files are located\n",
    "folder_name = 'Classifications_arch' \n",
    "\n",
    "for Id in IDS:\n",
    "    file_name = f'{Id}.parquet'\n",
    "    file_path = f'../scripts/classification_functs/{folder_name}/{file_name}'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Read the Parquet file into a DataFrame\n",
    "        data = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        df_Classifications_arch[Id] = data\n",
    "\n",
    "df_Classifications_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb06795",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558a98",
   "metadata": {},
   "source": [
    "# Initialization of variables, tables ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576f19f",
   "metadata": {},
   "source": [
    "We group the data by shared ID and create `NumPy` arrays for flux, weighted flux, and the source test(if it's a missing day(data)). We also determine the length of each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('objectId')\n",
    "\n",
    "F = grouped['dc_flux'].apply(lambda x: x.values)#.values\n",
    "sig = grouped['dc_sigflux'].apply(lambda x: x.values)#.values\n",
    "W = grouped['dc_weight'].apply(lambda x: x.values)#.values\n",
    "source = grouped['source'].apply(lambda x: x.values)#.values\n",
    "lengths = grouped['source'].apply(lambda x: len(x))#.values\n",
    "mjd = grouped['mjd'].apply(lambda x: x.values)#.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b64914",
   "metadata": {},
   "source": [
    "We define the length of our query,window or chunk, along with the limit factor and the size of each window or chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "chunk_size = 2 * (m + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae9b24",
   "metadata": {},
   "source": [
    "The `not_feasible_test` function determines the feasibility of each window. If the sum of values in each filter array exceeds half the total number of points in the filter, indicating all values are real, the function returns 1. Otherwise, it returns -1 to mark the window as 'not feasible'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677b81a-59c9-467f-8a8c-b5771dce4685",
   "metadata": {},
   "source": [
    "We set a rule to consider a window feasible if it has more than \\(m/2\\) for 'each' filter. This is just one way to do it; other conditions can be used depending on how much we trust the GPR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98068a37-e0a0-4180-a6e7-cab0b5c5ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_pts = int((m+1)/2)\n",
    "def not_feasible_test(array):\n",
    "    if (array[::2].sum() > half_pts) & (array[1::2].sum() > half_pts) :\n",
    "       return -1 \n",
    "    return -99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fecc96",
   "metadata": {},
   "source": [
    "\"`objects`\" list contains a subset of the objects we intend to work with.\n",
    "\n",
    "\"`L_max`\" is defined to facilitate partial iteration, serving as a debugging aid by allowing a limit to be set on the number of iterations performed.\n",
    "\n",
    "We initialize the NumPy arrays with `None` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f76cc4-508e-42d7-b72a-84e491b2deb7",
   "metadata": {},
   "source": [
    "#### Run this cell only once ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89616378-2a4f-4f2d-bba3-ee28a3ad5577",
   "metadata": {},
   "source": [
    "We shuffle our objects and save the shuffled data to ensure consistent results in subsequent analyses. For example, the value of `L_max` can vary slightly depending on the random shuffling of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9f2ab-a6d1-436b-89a1-523423e70121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects = unique_ids[:]#[0:10]\n",
    "# num_objects = len(objects)\n",
    "# # Shuffle the list\n",
    "# random.shuffle(objects)\n",
    "# # Save the shuffled list to a file\n",
    "# file_path = 'shuffled_objects2.json'\n",
    "\n",
    "# with open(file_path, 'w') as file:\n",
    "#     json.dump(objects, file)\n",
    "\n",
    "# print(f\"Shuffled objects have been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574314e-ec75-4d62-811c-f23dc0fcf91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Path to the file\n",
    "file_path = 'shuffled_objects.json'\n",
    "\n",
    "# Read the shuffled list from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    objects = json.load(file)\n",
    "\n",
    "# print(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc4c87-6a5d-4ff0-bcd9-0978045f1f36",
   "metadata": {},
   "source": [
    "`L_max` is the number of queries needed before every window gets at least one match. It depends on `m`, `num_objects`, and other factors. You can set the maximum number of windows to `L_max`. Initially, set `L_max` to 1 and compute the number of feasible windows below. After an initial trial, save `L_max` and return the code with the correct `L_max`. It's challenging, but here's the correct approach:\n",
    "\n",
    "1. Initialize `L_max` to 1.\n",
    "2. Compute the number of feasible windows :`count_W`. (before running the main algo)\n",
    "3. Perform an initial trial with `L_max`=`count_W`.\n",
    "4. Run the code and Save the value of `L_max`.\n",
    "5. Return the code with the correct `L_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbee235-7434-486c-b9b0-9d9fec1c8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects = objects[:10]\n",
    "num_objects = len(objects)\n",
    "\n",
    "list_L_max = [97,1424,7221,7572,5701,3401,1801,297,10591] \n",
    "L_max = 97#10416#5154#5317#\n",
    "\n",
    "print(\"L_max \", L_max)\n",
    "\n",
    "R = np.empty(num_objects, dtype=object)\n",
    "R_ref = np.empty(num_objects, dtype=object)\n",
    "R_l = np.empty((num_objects, L_max), dtype=object)\n",
    "num_by_obj = np.zeros((L_max,num_objects), dtype=object)\n",
    "alp = np.empty((num_objects, L_max), dtype=object)\n",
    "d = np.empty((num_objects, L_max), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_objects = range(num_objects)\n",
    "Q = [None] * (L_max)\n",
    "min_d =  [float('inf'), -1, -1] * (L_max)\n",
    "num_left_by_Q = [0] * (L_max) ####### we don't need this one anymore <==> sum_i\n",
    "selected_Q_K_i = np.empty(L_max, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e82cf3",
   "metadata": {},
   "source": [
    "We initialize R using the '`not_feasible_test`' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "count_W = 0 \n",
    "n = lengths[objects[0]]\n",
    "num_chunks = int(n // 2)-m \n",
    "\n",
    "for k in indexes_objects:\n",
    "    \n",
    "    chunks = np.array([source[objects[k]][i*2 : (i*2+chunk_size)] for i in range(num_chunks)])\n",
    "    result = np.array(list(map(not_feasible_test, chunks)))\n",
    "    R[k] = result.copy()\n",
    "    R_ref[k] = result.copy()\n",
    "    \n",
    "    count_W += np.count_nonzero(result == -1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Num of feasible windows :\",count_W)\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2cac1-4da7-4bd5-b0d1-2e03beac745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "rangek0 = [i for i in range(len(objects)) if len(indexes_array[i]) > 0]\n",
    "len0 = len(rangek0)\n",
    "len0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd949aa-6459-4d28-8e96-0252ea28cbaf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101fc3b-4886-4fd0-9943-0821230356f8",
   "metadata": {},
   "source": [
    "### We calculate the percentage of each class in the objects used prior to the first step (objects involved in the calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042f5e9-4a42-4753-9f83-e82b949d57b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "classes_All = {}\n",
    "for k in rangek0:\n",
    "    df = df_Classifications_arch[objects[k]]\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        if class_name in classes_All:\n",
    "            classes_All[class_name][0] += percentage\n",
    "            classes_All[class_name][1] += error_bar**2\n",
    "        else:\n",
    "            classes_All[class_name] = [percentage,error_bar**2]\n",
    "\n",
    "    # classes.append(get_classification3(objects[k]))\n",
    "for class_name, list1 in classes_All.items():\n",
    "    classes_All[class_name][0] = round(list1[0] / len0 , 2)\n",
    "sorted_classes_All = dict(sorted(classes_All.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Elapsed time:\", (end_time - start_time)/60, \"minutes\")\n",
    "sorted_classes_All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afe976-6790-4344-ad4a-835c6f9d9cad",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b52ee3-83a2-4317-b39b-5ba5f0b540ca",
   "metadata": {},
   "source": [
    "# Main algorithm : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96498701",
   "metadata": {},
   "source": [
    "### Loop to compute the distance of the subsequence in the time series to its nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891d484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rangek2 = list(range(len(objects)))\n",
    "\n",
    "l= 0\n",
    "while (l < L_max):\n",
    "    indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "    rangek2 = [i for i in range(len(objects)) if len(indexes_array[i]) > 0]\n",
    "\n",
    "    has_empty_list = len(rangek2) == 0\n",
    "    if has_empty_list:\n",
    "        print(\"break , l = \", l )\n",
    "        break\n",
    "        \n",
    "    num_left_by_Q[l] = len(rangek2)\n",
    "        \n",
    "    k = rangek2[0]\n",
    "        \n",
    "    f = F[objects[k]]\n",
    "    index_no_match = indexes_array[k][0]\n",
    "    k_Query_taked = k\n",
    "    selected_Q_K_i[l] = [k,index_no_match]\n",
    "    Q[l] = f[index_no_match*2 : index_no_match*2 +chunk_size]\n",
    "\n",
    "\n",
    "    \n",
    "    for k in rangek2:\n",
    "        f = F[objects[k]]\n",
    "        w = W[objects[k]]\n",
    "        n = lengths[objects[k]]\n",
    "        n_c = n - 2*m # (number of chunks x 2) ! it's (n/2 - m) but to optimize we mutiply by 2 directly !  \n",
    "\n",
    "\n",
    "\n",
    "        s_1 = np.zeros(n_c, dtype=float)\n",
    "        s_2 = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:] += (f[j*2:j*2+ n_c]*h*w[j*2:j*2+ n_c])\n",
    "            s_2[:] += (h**2 * w[j*2:j*2+ n_c])\n",
    "\n",
    "\n",
    "        s_n = s_1[::2] + s_1[1::2]  \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "\n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "     \n",
    "    \n",
    "        dd = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            \n",
    "            dd[:] += ((f[j*2:j*2+ n_c] - alpha[:] * h)**2) * w[j*2:j*2+ n_c] \n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        factor_comparison =  d[k][l] <= factor\n",
    "                \n",
    "        R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l # explanation follows below!\n",
    "                \n",
    "        R_l[k][l] = R_ref[k].copy()\n",
    "\n",
    "        matches_k = float('inf')  # Start with a large number\n",
    "        min_index = None  # Variable to store the index of the minimum value\n",
    "\n",
    "        for i in range(len(factor_comparison)):\n",
    "            if  R_l[k][l][i] != -99:\n",
    "                if factor_comparison[i] :\n",
    "                    R_l[k][l][i] = l\n",
    "                    num_by_obj[l][k]+=1\n",
    "                if index_no_match != i and d[k][l][i] < matches_k:\n",
    "                        matches_k = d[k][l][i]  # Update the minimum value\n",
    "                        min_index = i  #\n",
    "\n",
    "        \n",
    "        if matches_k < min_d[l * 3] :\n",
    "            min_d[l * 3] = matches_k  # Instead of min_d[::3][l]\n",
    "            min_d[l * 3 + 2] = min_index      # Instead of min_d[2::3][l]\n",
    "            min_d[l * 3 + 1] = k            # Instead of min_d[1::3][l]\n",
    "\n",
    "    R_l[k_Query_taked][l][index_no_match] = -2\n",
    "\n",
    " \n",
    "    l += 1 \n",
    "    \n",
    "print(\"l = \",l)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time += end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d33b3",
   "metadata": {},
   "source": [
    "Let's break down the expression `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l` step by step:\n",
    "\n",
    "1. `indexes_array[k]`: This selects the array of indexes corresponding to the k-th element of `indexes_array`.\n",
    "2. `factor_comparison[indexes_array[k]]`: This applies boolean indexing to `factor_comparison` using the indexes from `indexes_array[k]`. It selects only the elements of `factor_comparison` corresponding to the indexes in `indexes_array[k]`.\n",
    "3. `indexes_array[k][factor_comparison[indexes_array[k]]]`: This gives the indices where the condition `factor_comparison` is true for the k-th element of `indexes_array`.\n",
    "4. `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]]`: This uses the indices obtained in the previous step to select elements from the k-th row of `R`.\n",
    "5. `= l`: Finally, it assigns the value `l` to the selected elements of `R[k]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08a5c2-ed7d-4e94-bb31-e7039a4b6125",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b69f8b-e8f0-4cbd-bdaa-e899d4de9d82",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_left_by_Q[-1] # list of number of object for each step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(L_max),num_left_by_Q)\n",
    "\n",
    "plt.xlabel('Queries')\n",
    "plt.ylabel('Nb objs left')\n",
    "plt.title('Number of objects left in function of queries.')\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "# data = {'Queries': range(L_max), 'Nb objs left': num_left_by_Q}\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Export to Excel\n",
    "# df.to_csv('num_left_by_Q.csv', index=False)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d7a5da-1532-4af7-9c0c-744afd887ece",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fd2b6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3881c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe22e6",
   "metadata": {},
   "source": [
    "### Calculate the Matrix of Matches MM (with windows represented in rows and queries as columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e766e-82e6-4d7a-b9ca-1d0944e54ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangek = range(len(objects))\n",
    "\n",
    "# Initialize list to hold transposed arrays for each k\n",
    "Matrices_by_k = []\n",
    "\n",
    "no_missing = np.zeros(len(rangek), dtype= object)\n",
    "length_no_missing = np.zeros(len(rangek), dtype= int)\n",
    "\n",
    "Reference_Table_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0cf2c-a8fa-4ba7-8ed1-47764e4faad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for k in rangek:\n",
    "    no_missing[k] = np.where(R[k] != -99)[0]  \n",
    "    \n",
    "    length_no_missing[k] = len(no_missing[k])\n",
    "    \n",
    "    # Initialize transposed array\n",
    "    Matrix= np.empty((length_no_missing[k], len(R_l[k])), dtype=object)\n",
    "    \n",
    "    refrence_table_k = np.empty(length_no_missing[k], dtype=object)\n",
    "    \n",
    "    # Transpose and store the arrays\n",
    "    for i, idx in enumerate(no_missing[k]):\n",
    "        for j, arr in enumerate(R_l[k]):\n",
    "            if arr is not None:  # Check if arr is not None\n",
    "                if arr[idx] == -2 or arr[idx] >= 0:\n",
    "                    Matrix[i][j] = 1\n",
    "                else:\n",
    "                    Matrix[i][j] = 0\n",
    "            else:\n",
    "                Matrix[i][j] = 0\n",
    "                #print(f\"Error: arr is None at index {j} in R_l[{k}]\")\n",
    "            # if arr[idx] == -2 or arr[idx] >= 0:\n",
    "            #     Matrix[i][j] = 1\n",
    "            # else:\n",
    "            #     Matrix[i][j] = 0\n",
    "                \n",
    "        refrence_table_k [i] =  [k ,idx]\n",
    "\n",
    "                \n",
    "    # Append transposed array to the list\n",
    "    Matrices_by_k.append(Matrix)\n",
    "    Reference_Table_list.append(refrence_table_k)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time += end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time/60, \"minutes\")\n",
    "Matrices_by_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_Matches = np.concatenate(Matrices_by_k, axis=0)\n",
    "Reference_Table = np.concatenate(Reference_Table_list, axis=0)\n",
    "Matrix_Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636f0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_j_rows = np.sum(Matrix_Matches, axis=1)\n",
    "sum_j_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767a706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_i_columns = np.sum(Matrix_Matches, axis=0)\n",
    "sum_i_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6171",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a597b5-9c3c-44f3-a324-3dbc12625177",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45065dad-16b6-4b32-8adc-4ddaa159da0a",
   "metadata": {},
   "source": [
    "### Functions that return some important information  : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa7617-270a-4524-b897-b54217ec35f9",
   "metadata": {},
   "source": [
    "For a specific object k, this function returns the indexes of its feasible windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_values_for_k(specific_k):\n",
    "    return no_missing[specific_k]\n",
    "get_i_values_for_k(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dfcc8-b2bc-48ff-8b54-7e0b54938487",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f3fd2-7708-4813-955a-7e4126e472c0",
   "metadata": {},
   "source": [
    "For each row (window) in MM, this function returns the index information (the object number and the window index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_i_for_row(global_idx):\n",
    "    return Reference_Table[global_idx]\n",
    "k,i = get_k_i_for_row(2)\n",
    "k,i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aae45c-92a6-4715-9552-deeb6328e7aa",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34bf1-6152-4744-98ff-3dc65df2e1a3",
   "metadata": {},
   "source": [
    "For a specific object k, this function returns the indexes of its feasible windows in the MM (index of rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_indexes_for_k(specific_k):\n",
    "    idx = 0 \n",
    "    for k in rangek:\n",
    "        if k == specific_k:\n",
    "            return list(range(idx, idx + length_no_missing[k]))\n",
    "        idx += length_no_missing[k]\n",
    "\n",
    "get_i_indexes_for_k(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e3e9a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4920b-0886-4121-a0ca-088048a7d81e",
   "metadata": {},
   "source": [
    "This function checks whether the window (in object `k_TSâ€‹` with index `i_TS`) has been marked as a query or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_a_query(k_TS, i_TS, selected_Q_K_i): \n",
    "    mask = selected_Q_K_i != None\n",
    "    for index_Q, (k, i) in enumerate(selected_Q_K_i[mask]):\n",
    "        if k_TS == k and i_TS == i:\n",
    "            return True, index_Q, f\"This window is used as the {index_Q}th query! \"\n",
    "    return False, 0 , \"This window is not used as a query ! \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e65751-1519-4ebc-93d5-ee61ac064bee",
   "metadata": {},
   "source": [
    "get the number of match for a query i or a window j (they must be reversed ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807c9ed-cd4a-4c8c-bb23-f63c91899e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_i_by_sum(i):\n",
    "        return sum_i_columns[i]\n",
    "\n",
    "def get_j_by_sum(j):\n",
    "        return sum_i_columns[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3d2a2-63c5-429e-99ba-5aafbfb73828",
   "metadata": {},
   "source": [
    "This function returns the object and the window (the origin) of the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8a25c-cb2f-41ba-bf6e-eeab71574733",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_k_i_of_Q(l):\n",
    "    return selected_Q_K_i[l]\n",
    "get_k_i_of_Q(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202add1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f608b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5529e2f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97534fc3",
   "metadata": {},
   "source": [
    "## Plotting functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c58d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_flux(k,l,open_Fink= False):\n",
    "    print(\"\\n______________________________________________________________________________________________\")\n",
    "    print(f\"{objects[k]}\")\n",
    "    #get_classification(objects[k])\n",
    "\n",
    "    for index, row in df_Classifications_arch[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        print(f\"                        {classification} : {percentage:.1f}% \") \n",
    "   \n",
    "\n",
    "    import ipywidgets as widgets\n",
    "          \n",
    "    button = widgets.Button(description=f\"open in FINK\")\n",
    "    # Capture current values of kk and l in lambda's default arguments\n",
    "    button.on_click(lambda _, k=k : on_button_clicked_plot(objects[k]))\n",
    "    display(button)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Plot for F[k]\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    for i in range(int(len(F[objects[k]])/2)):\n",
    "        if source.loc[objects[k]][2*i] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig[objects[k]][2*i]*0.4,\n",
    "                     c='C0', marker='x')\n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig.loc[objects[k]][2*i],\n",
    "                     c='C0', marker=marker)\n",
    "\n",
    "        if source.loc[objects[k]][2*i+1] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig[objects[k]][2*i+1]*0.4,\n",
    "                     c='C1', marker='x')\n",
    "            \n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig.loc[objects[k]][2*i+1],\n",
    "                     c='C1', marker=marker)\n",
    "            \n",
    "        a_query,l_1, string = if_a_query(k,i,selected_Q_K_i)\n",
    "            \n",
    "        if a_query and l_1 == l:\n",
    "            print(string)\n",
    "            \n",
    "            # Define the window of indices\n",
    "            window_start = mjd.loc[objects[k]][2*i]  # Index of the window start\n",
    "            window_end = mjd.loc[objects[k]][2*i] + int(len(Q[l])/2 - 1)  # Index of the window end\n",
    "            \n",
    "            \n",
    "            # Create an array of float indices\n",
    "            indices = np.arange(window_start, window_end + 1)\n",
    "            indices = np.concatenate(([indices[0] - 0.5], indices, [indices[-1] + 0.5]))\n",
    "\n",
    "            # Plot a shaded region for the window\n",
    "            plt.fill_between(indices, min(Q[l])/1.9, max(Q[l])*1.2, color='gray', alpha=0.2)\n",
    "            \n",
    "        \n",
    "    plt.plot([], [], color='C1', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C0', marker='o', label='origin')\n",
    "    plt.plot([], [], color='C0', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C1', marker='o', label='origin')\n",
    "    \n",
    "   \n",
    "    ################################### what about the seccond window !? \n",
    "    moy_alp = 1\n",
    "\n",
    "    plt.plot(mjd.loc[objects[k]][::2], F.loc[objects[k]][::2], c='C0', linewidth = 1)\n",
    "    plt.plot(mjd.loc[objects[k]][1::2], F.loc[objects[k]][1::2], c='C1', linewidth = 1)\n",
    "\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][::2]*moy_alp, c='g', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][1::2]*moy_alp, c='r', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "\n",
    "    # Define the window of indices\n",
    "    window_start = -1-m + mjd.loc[objects[k]][0] # Index of the window start\n",
    "    window_end = int(len(Q[l])/2 - 1-1 -m)+ mjd.loc[objects[k]][0]  # Index of the window end\n",
    "\n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.4], indices, [indices[-1] + 0.4]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(Q[l])/1.2*moy_alp, max(Q[l])*1.2*moy_alp, color='gray', alpha=0.2)\n",
    "\n",
    "    # plt.xlabel('Index')\n",
    "    plt.ylabel('Flux')\n",
    "    # plt.title('Flux Plot')\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     ###############                       Plot for d[k][0]                       ###############\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot([-1-m, -1-m], [0, 0], color='none')  # Plot an empty line with zero length\n",
    "    plt.plot(range(len(d[k][l])), d[k][l],color='C0', linestyle='-',linewidth=1)\n",
    "\n",
    "\n",
    "    \n",
    "    matches_idx = get_i_indexes_for_k(k)\n",
    "    matches2 = sum_j_rows[matches_idx]\n",
    "\n",
    "\n",
    "    # Plot dummy points with desired colors and markers\n",
    "    plt.plot([], [], color='black', marker='o', label='Query chosed')#markers.soli\n",
    "    plt.plot([], [], color='red', marker='x', label='missing cases !')\n",
    "    plt.plot([], [], color='blue', marker='s', label='Matched here')#markers.ravioli\n",
    "    plt.plot([], [], color='green', marker='*', label='Matches with a different `l` (Query)')#markers.stelline\n",
    "    plt.plot([], [], color='yellow', marker='^', label=f'Not matched with any of the {L_max} options we selected') #markers.tortellini\n",
    "    \n",
    "    c= 0\n",
    "    \n",
    "    for i, val in enumerate(R_l[k][l]):\n",
    "            if val == -99:\n",
    "                plt.scatter(i, d[k][l][i], color='red', marker='x', s=50)  # marker size 50\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, 0, fontsize=10, color='red', ha='left')\n",
    "                c+=1\n",
    "#                 plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, 0*str(matches2[i]), fontsize=10, color='red', ha='left')\n",
    "\n",
    "            elif val == l:\n",
    "                plt.scatter(i, d[k][l][i], color='blue', marker='s', s=50)\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='blue', ha='left')\n",
    "\n",
    "            elif val == -2:\n",
    "                plt.scatter(i, d[k][l][i], color='black', marker='o', s=50) \n",
    "                #print(matches2[i-c])\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='black', ha='left')\n",
    "\n",
    "            elif matches2[i-c]==0:\n",
    "                plt.scatter(i, d[k][l][i], color='yellow', marker='^', s=50) \n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='yellow', ha='left')\n",
    "\n",
    "            else:\n",
    "                plt.scatter(i, d[k][l][i], color='green', marker='*', s=75)\n",
    "                plt.text(i+0.2, d[k][l][i]+d[k][l][i]*5/100, str(matches2[i-c]), fontsize=10, color='green', ha='left')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.legend(fontsize=8) \n",
    "    #plt.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "    plt.ylabel('distance')\n",
    "\n",
    "\n",
    "\n",
    "    ###############                       Plot for alpha[k][l]                       ###############\n",
    "\n",
    "#     plt.subplot(3, 1, 3)\n",
    "#     plt.plot(range(len(alp[k][l])), alp[k][l], marker='.', linestyle='-',color='black')\n",
    "#     plt.xlabel('Index')\n",
    "#     plt.ylabel('Value')\n",
    "#     plt.title('alpha Plot')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(top=0.93)  # Adjust the top margin for the super title\n",
    "    plt.suptitle(f\"{objects[k]}, k = {k}, l = {l} \", fontname='Arial', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    if open_Fink:\n",
    "        open_website(objects[k])\n",
    "\n",
    "\n",
    "import webbrowser\n",
    "\n",
    "def open_website(k):\n",
    "    website_url = f'https://fink-portal.org/{k}'\n",
    "    webbrowser.open(website_url)\n",
    "\n",
    "def on_button_clicked_plot(Id):\n",
    "    print(\"URL opened\")\n",
    "    open_website(Id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb22ca7-ca87-43a5-8f3a-6d17cd339ae3",
   "metadata": {},
   "source": [
    "#### This applies only to the closest distance for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb3665-49a8-4678-bebc-9c72b7417a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_flux_min(k,l,min_d_i):\n",
    "    print(\"\\n______________________________________________________________________________________________\")\n",
    "    print(f\"{objects[k]}\")\n",
    "    \n",
    "    #get_classification(objects[k])\n",
    "\n",
    "    for index, row in df_Classifications_arch[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        print(f\"                        {classification} : {percentage:.1f}% \") \n",
    "   \n",
    "    \n",
    "    import ipywidgets as widgets\n",
    "          \n",
    "    button = widgets.Button(description=f\"open in FINK\")\n",
    "    # Capture current values of kk and l in lambda's default arguments\n",
    "    button.on_click(lambda _, k=k : on_button_clicked_plot(objects[k]))\n",
    "    display(button)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Plot for F[k]\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i in range(int(len(F[objects[k]])/2)):\n",
    "        if source.loc[objects[k]][2*i] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig[objects[k]][2*i]*0.4,\n",
    "                     c='C0', marker='x')\n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i], F.loc[objects[k]][2*i], \n",
    "                     sig.loc[objects[k]][2*i],\n",
    "                     c='C0', marker=marker)\n",
    "\n",
    "        if source.loc[objects[k]][2*i+1] == 0:\n",
    "            marker = 'x'\n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig[objects[k]][2*i+1]*0.4,\n",
    "                     c='C1', marker='x')\n",
    "            \n",
    "        else:\n",
    "            marker = 'o'\n",
    "                \n",
    "            plt.errorbar(mjd.loc[objects[k]][2*i+1], F.loc[objects[k]][2*i+1],\n",
    "                     sig.loc[objects[k]][2*i+1],\n",
    "                     c='C1', marker=marker)\n",
    "            \n",
    "        # a_query,l_1, string = if_a_query(k,i,selected_Q_K_i)\n",
    "            \n",
    "        # if a_query and l_1 == l:\n",
    "        #     print(string)\n",
    "            \n",
    "            # Define the window of indices\n",
    "    window_start = mjd.loc[objects[k]][2*min_d_i]  # Index of the window start\n",
    "    window_end = mjd.loc[objects[k]][2*min_d_i] + int(m)  # Index of the window end\n",
    "    \n",
    "    \n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.5], indices, [indices[-1] + 0.5]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(F[objects[k]])/1.9, max(F[objects[k]])*1.2, color='gray', alpha=0.2)\n",
    "        \n",
    "    \n",
    "    plt.plot([], [], color='C1', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C0', marker='o', label='origin')\n",
    "    plt.plot([], [], color='C0', marker='x', label='missing points !')\n",
    "    plt.plot([], [], color='C1', marker='o', label='origin')\n",
    "    \n",
    "   \n",
    "    ################################### what about the seccond window !? \n",
    "    moy_alp = 1#+0*alp[k][l].mean()\n",
    "    #moy_alp = np.median(F[k])/np.median(Q[l]) #Manu test\n",
    "\n",
    "    plt.plot(mjd.loc[objects[k]][::2], F.loc[objects[k]][::2], c='C0', linewidth = 1)\n",
    "    plt.plot(mjd.loc[objects[k]][1::2], F.loc[objects[k]][1::2], c='C1', linewidth = 1)\n",
    "\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][::2]*moy_alp, c='g', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "    plt.plot(np.arange(len(Q[l]) // 2) - 1-m + mjd.loc[objects[k]][0], Q[l][1::2]*moy_alp, c='r', label='Q[l]',marker='.', linewidth=3, zorder=3)\n",
    "\n",
    "    # Define the window of indices\n",
    "    window_start = -1-m + mjd.loc[objects[k]][0] # Index of the window start\n",
    "    window_end = int(len(Q[l])/2 - 1-1 -m)+ mjd.loc[objects[k]][0]  # Index of the window end\n",
    "\n",
    "    # Create an array of float indices\n",
    "    indices = np.arange(window_start, window_end + 1)\n",
    "    indices = np.concatenate(([indices[0] - 0.4], indices, [indices[-1] + 0.4]))\n",
    "\n",
    "    # Plot a shaded region for the window\n",
    "    plt.fill_between(indices, min(Q[l])/1.2*moy_alp, max(Q[l])*1.2*moy_alp, color='gray', alpha=0.2)\n",
    "\n",
    "    # plt.xlabel('Index')\n",
    "    plt.ylabel('Flux')\n",
    "    # plt.title('Flux Plot')\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.subplots_adjust(top=0.93)  # Adjust the top margin for the super title\n",
    "    plt.suptitle(f\"{objects[k]}, k = {k}, l = {l} \", fontname='Arial', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def on_button_clicked_plot(Id):\n",
    "    print(\"URL opened\")\n",
    "    open_website(Id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180bebc9",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4c747",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670655f-2e62-4f52-a2ab-f2e3c760a569",
   "metadata": {},
   "source": [
    "\n",
    "# Nearest query for each query : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd10a74-19fc-45d0-9ce3-51c886877774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearst_query = {}\n",
    "dis_to_nearst_query = []\n",
    "for l, list_l in enumerate(selected_Q_K_i):\n",
    "    #print(l, list)\n",
    "    k,i = list_l\n",
    "    \n",
    "    nearst_query[l] = [-1,float('inf')]\n",
    "    for l_after, list_after in enumerate(selected_Q_K_i[l+1:]):\n",
    "        l_after += l+1\n",
    "        # print(l, list,l_after, list_after)\n",
    "        k_after, i_after = list_after\n",
    "        if k_after != k :\n",
    "            distance = d[k_after][l][i_after]\n",
    "            # print(distance)\n",
    "            if nearst_query[l][1] > distance :\n",
    "                nearst_query[l] = [l_after,distance]\n",
    "            \n",
    "    for l_before, list_before in enumerate(selected_Q_K_i[:l]):\n",
    "        # l_after += l+1\n",
    "        # print(l, list,l_after, list_after)\n",
    "        k_before, i_before = list_before\n",
    "        if k_before != k :\n",
    "    \n",
    "            distance = d[k][l_before][i]\n",
    "            # print(distance)\n",
    "            if nearst_query[l][1] > distance :\n",
    "                nearst_query[l] = [l_before,distance] \n",
    "    \n",
    "    dis_to_nearst_query.append(nearst_query[l][1])\n",
    "\n",
    "nearst_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5adb5-70f1-426a-8103-9bd658dabaff",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72574783-fd60-45b5-aec8-8f67debdb1a8",
   "metadata": {},
   "source": [
    "\n",
    "# Nearst window(with only one match) to each query \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82d6e5-4957-4164-9c37-510889414954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearst_window_1 = {}\n",
    "dis_to_nearst_window_1 = [0]*L_max\n",
    "for l, list_l in enumerate(selected_Q_K_i):\n",
    "    # print(l, list_l)\n",
    "    k,i = list_l\n",
    "    \n",
    "    nearst_window_1[l] = [-1,-1,float('inf')],[-1,-1,float('inf')],[-1,-1,float('inf')]\n",
    "    # wind_l = list_l #get_k_i_of_Q(l)\n",
    "    \n",
    "    index = Reference_Table.tolist().index(list_l)#Reference_Table_list.index(wind_l)\n",
    "\n",
    "    # print(l,\"\\n\")\n",
    "    \n",
    "    for row, list_w in enumerate(Reference_Table[index+1:]):\n",
    "        row += index +1\n",
    "        k_window, i_window = list_w\n",
    "        \n",
    "        if sum_j_rows[row] == 1 and R[k_window][i_window] > l : \n",
    "            # print(index, row+index)\n",
    "            # print(k_window, i_window)\n",
    "\n",
    "            distance = d[k_window][l][i_window]\n",
    "            # print(distance)\n",
    "\n",
    "            if nearst_window_1[l][0][2] > distance :\n",
    "                distance3 = nearst_window_1[l][1][2]\n",
    "                distance2 = nearst_window_1[l][0][2]\n",
    "                k_window3 = nearst_window_1[l][1][0]\n",
    "                k_window2 = nearst_window_1[l][0][0]\n",
    "                i_window3 = nearst_window_1[l][1][1]\n",
    "                i_window2 = nearst_window_1[l][0][1]\n",
    "                nearst_window_1[l] = ([k_window, i_window, distance],[k_window2, i_window2, distance2],[k_window3, i_window3, distance3])\n",
    "    dis_to_nearst_window_1[l] = nearst_window_1[l][0][2]\n",
    "\n",
    "  \n",
    "\n",
    "nearst_window_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cd149",
   "metadata": {},
   "source": [
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd1b2a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5716a",
   "metadata": {},
   "source": [
    "## plot histogram of numbers of matches for each Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b5761",
   "metadata": {},
   "source": [
    "We graph the number of matches for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = range(len(sum_i_columns))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(indexes, bins=len(sum_i_columns), weights=sum_i_columns, color='C1', edgecolor='white')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Indices')\n",
    "plt.ylabel('Numbers')\n",
    "plt.title('Histogram of numbers of matches for each Q ')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute the highest and lowest 10 values and their indexes\n",
    "sorted_indices = sorted(range(len(sum_i_columns)), key=lambda i: sum_i_columns[i])\n",
    "lowest_10_indices = sorted_indices[:20]\n",
    "highest_10_indices = sorted_indices[-10:][::-1]  # Reverse to get in descending order\n",
    "\n",
    "total_windows = len(Matrix_Matches)\n",
    "\n",
    "# Print the highest and lowest 10 values and their indexes with percentages\n",
    "print(\"Highest 10:\\n\")\n",
    "for i in highest_10_indices:\n",
    "    percentage = (sum_i_columns[i] / total_windows) * 100\n",
    "    print(f\"Index: {i}, Matches: {sum_i_columns[i]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\n\\nLowest 10:\\n\")\n",
    "for i in lowest_10_indices:\n",
    "    percentage = (sum_i_columns[i] / total_windows) * 100\n",
    "    print(f\"Index: {i}, Matches: {sum_i_columns[i]}, Percentage: {percentage:.2f}%\")\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b1f97-b3cc-40b5-8b60-7203cc6b5922",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0303a3-f603-4638-aa12-4a60a0e52e78",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc5c19-90f3-4686-8793-a12463a5adcd",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f1d29-3e27-4a15-b9fb-26a3bc79b8ef",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5283323-43eb-4588-a004-d2abfa58425b",
   "metadata": {},
   "source": [
    "\n",
    "# sort the queries(with one match) by the max nearst distance of each one \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e55c24-6de6-4604-a585-5c335ee2aa44",
   "metadata": {},
   "source": [
    "First, we take the queries with only one match. Then, we sort these queries based on the distance to their nearest query, starting with the query that has the minimum distance to its nearest neighbor and ending with the query that has the maximum distance to its nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb998356-43f3-47e8-b04b-caec0a5d941d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert sorted_indices and sum_i_columns to numpy arrays if they aren't already\n",
    "sorted_indices = np.array(sorted_indices)\n",
    "sum_i_columns = np.array(sum_i_columns)\n",
    "\n",
    "# Use a boolean mask to find indices where sum_i_columns is less than or equal to 1\n",
    "mask = sum_i_columns[sorted_indices] <= 1\n",
    "\n",
    "# Get the corresponding indices\n",
    "indices_1_match = sorted_indices[mask]\n",
    "\n",
    "\n",
    "dis = np.array(dis_to_nearst_query) \n",
    "\n",
    "# Use indices_1_match to index dis\n",
    "dis_1_match = dis[indices_1_match]\n",
    "\n",
    "# Sort dis_1_match and get the sorted indices\n",
    "sorted_dis_1_match_indices = np.argsort(dis_1_match)\n",
    "\n",
    "# Sort indices_1_match based on sorted_dis_1_match_indices\n",
    "sorted_indices_1_match = indices_1_match[sorted_dis_1_match_indices]#[::-1]\n",
    "\n",
    "# Result: sorted indices of sum_i_columns based on sorted dis_1_match values\n",
    "sorted_indices_1_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd2095-eb28-45c6-912d-b67dea7c768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted_indices_1_match:\n",
    "    print(i, nearst_query[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a08dd-1b2a-4152-9aec-3b84c6f6734d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725a95e-32d8-42c8-95b6-adc260fdd5c7",
   "metadata": {},
   "source": [
    "# Save information to an Excel file for archiving and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056aec82-c317-4714-8fba-ff7527e4976a",
   "metadata": {},
   "source": [
    "In fact, this can help reduce the number of queries with only one match by transforming Excel data into a table format, then selecting specific interesting classes for analysis (and put them in the list `specific_classes`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for l in sorted_indices:\n",
    "\n",
    "    Q_ratio = (Q[l][::2]).sum()/(Q[l][1::2]).sum() / (m + 1)\n",
    "    k, i = selected_Q_K_i[l]\n",
    "    non_zero_indexes = np.nonzero(num_by_obj[l])[0]\n",
    "    #Nb_valid = np.sum(is_valid[objects[k]][i*2:i*2+chunk_size])\n",
    "    url_and_matches = []\n",
    "    for kk in non_zero_indexes:\n",
    "        url_and_matches.append(f\"https://fink-portal.org/{objects[kk]} : Nb of matches : {num_by_obj[l][kk]}\")\n",
    "    \n",
    "    string = \"\" \n",
    "    for index, row in df_Classifications_arch[objects[k]].iterrows():\n",
    "        classification = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        string += f\"  {classification} : {percentage:.1f}% \\n\"\n",
    "        \n",
    "    # Create a dictionary for each iteration\n",
    "    row = {\n",
    "        'Query': l,\n",
    "        'Matches on this Query': sum_i_columns[l],\n",
    "        'Ratio': Q_ratio,\n",
    "        'Object of this Q': objects[k],\n",
    "        'Link': f\"https://fink-portal.org/{objects[k]}\",\n",
    "        'class': string,\n",
    "        #'Nb_valid' : Nb_valid,\n",
    "        'mjd ': mjd.loc[objects[k]][2*i], \n",
    "        'Annotation': '',\n",
    "        #'min d (nearst window 1 match)': nearst_window_1[l][0][2],\n",
    "        'Number of objects': len(non_zero_indexes),\n",
    "        'Objects with matches': non_zero_indexes.tolist(),\n",
    "        'URLs and Matches': '\\n'.join(url_and_matches)\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the data list\n",
    "    data.append(row)\n",
    "    \n",
    "    if sum_i_columns[l] >1 : # we only choose queries with one match\n",
    "        break \n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Export DataFrame to Excel\n",
    "df.to_excel(f'lowest_Q_EM_GP_m{m}_o1-2_real_@.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265abe23-059d-4dae-9bea-8824fff07d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d458b-ccfd-487a-bf73-64f6a273c0c4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c573b-bd7c-4e16-a5d8-ef7730ee285b",
   "metadata": {},
   "source": [
    "# Visual Analysis for Results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7959aa-17fc-4c5a-9bf4-a4614108494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_classes = [7715,7716,7987,9113,9114,9520,9566,9567,9568,9569,4845]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094daeb-8e2c-45ce-b74e-96f584a2fad9",
   "metadata": {},
   "source": [
    "`sorted_indices_1_match[::-1]:` It sorts the queries from the most unusual (compared to the others) to the most typical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3a507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"###################  m = \", m ,\"######################\")\n",
    "count= 0 \n",
    "for l in sorted_indices_1_match[::-1]:#sorted_indices:#sorted_indices_1_match[::-1]:#sorted_indices:#[0:1549]:\n",
    "    k , i = selected_Q_K_i[l]\n",
    "    Nb_valid = np.sum(source[objects[k]][i*2:i*2+chunk_size])\n",
    "\n",
    "    #if Nb_valid < 8: # We can select queries where all the data is either real or has few missing values.\n",
    "    #    continue\n",
    "    if sum_i_columns[l] >1 :\n",
    "            break\n",
    "\n",
    "    count+=1\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------------------------------------------\",l,\"\\n\")\n",
    "    print(\"----------------------------------------NEW OBJECT --------------------------------------------------------\\n\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    print(f\"Q[{l}] , Matches on this Query: {sum_i_columns[l]}\")\n",
    "    \n",
    "    # print('Nb_valid', Nb_valid)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"Ratio :\",Q[l][0]/Q[l][1])\n",
    "    \n",
    "    print(f\"Object of this Q : {objects[k]} : https://fink-portal.org/{objects[k]}\")\n",
    "\n",
    "    \n",
    "    non_zero_indexes = np.nonzero(num_by_obj[l])[0]\n",
    "    non_zero_indexes, len(non_zero_indexes)\n",
    "    print(\"\\nNumber of objects that have matches on this Q :\", len(non_zero_indexes))\n",
    "    print(\"Objects that have matches on this Q : \", non_zero_indexes,\"\\n\")\n",
    "    \n",
    "    for kk in non_zero_indexes:\n",
    "        print(f\"https://fink-portal.org/{objects[kk]}\" , \" : Nb of mathces : \",num_by_obj[l][kk])\n",
    "        button = widgets.Button(description=f\"plot {objects[kk]}\")\n",
    "        # Capture current values of kk and l in lambda's default arguments\n",
    "        button.on_click(lambda _, kk=kk, l=l: on_button_clicked(kk, l))\n",
    "        display(button)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    plot_distance_flux(k,l)\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------\\n\")\n",
    "    #nearst_w_k, nearst_w_i, nearst_w_d = nearst_window_1[l][0]\n",
    "\n",
    "    #print(nearst_w_i, nearst_w_d)\n",
    "    \n",
    "    #plot_distance_flux(nearst_w_k,l)\n",
    "\n",
    "    \"\"\"print(\"------------------------------- nearst query --------------------------------------------\")\n",
    "\n",
    "    l_nearst, d_nearst = nearst_query[l]\n",
    "    k_nearst , i_nearst = selected_Q_K_i[l_nearst]\n",
    "    \n",
    "    if l_nearst < l:\n",
    "        plot_distance_flux_min(k_nearst,l_nearst,i_nearst)\n",
    "    else:\n",
    "        plot_distance_flux_min(k_nearst,l,i_nearst)\"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"print(\"------------------------------- nearst window with one match --------------------------------------------\")\n",
    "\n",
    "    k_nearst , i_nearst, d_nearst = nearst_window_1[l][0]\n",
    "    # k_nearst , i_nearst = selected_Q_K_i[l_nearst]\n",
    "    print(i_nearst)\n",
    "    print(\"Distance = \",d_nearst)\n",
    "    \n",
    "    # plot_distance_flux(k_nearst,l)\n",
    "    plot_distance_flux_min(k_nearst,l,i_nearst)\n",
    "    \n",
    "\n",
    "    print(\"------------------------------- nearst window --------------------------------------------\")\n",
    "\n",
    "    min_d_d  = min_d[3*l]\n",
    "    min_d_k = min_d[3*l+1]\n",
    "    min_d_i = min_d[3*l+2]\n",
    "    \n",
    "    if min_d_d != float('inf') : \n",
    "        # print(min_d_d, min_d_k,min_d_i)\n",
    "        print(\"distance :\",min_d_d)\n",
    "        print(\"K :\", min_d_k)\n",
    "        print(\"mjd :\", mjd[objects[k]][min_d_i*2])\n",
    "        # plot_distance_flux(min_d_k,l)\n",
    "        plot_distance_flux_min(min_d_k,l,min_d_i)\n",
    "    else : \n",
    "        print(\"no min found\")\n",
    "        print(\"---------------------------------------------------------------------------\")\"\"\"\n",
    "\n",
    "    \n",
    "    if count == 50 :\n",
    "     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09d8f2-4423-4119-b312-885f35920bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count,m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89c22b-873e-4dea-aa97-210d55faf45b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706598f-c0fa-480a-9430-a278bd1a65fe",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d9534-cd2b-4a8d-a0ac-b9aa12a6e2aa",
   "metadata": {},
   "source": [
    "# Percentage of classes  without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a297a-f06d-414d-b4c5-50d91412ee0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rangek3 = [] # unique objects with 1 match (as query ) \n",
    "for l in sorted_indices:\n",
    "    if sum_i_columns[l] >1 : ################ i only choose queries with one match ( for m=0 we only have 4 !!!)\n",
    "        break \n",
    "    k, i = selected_Q_K_i[l]\n",
    "    if k not in rangek3:\n",
    "        rangek3.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b4af2-7321-4429-9bdb-946f6ffaa0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes_wr = {}\n",
    "c= len(rangek3)\n",
    "\n",
    "for k in rangek3 :\n",
    "    df = df_Classifications_arch[objects[k]]  # Example call, modify as necessary\n",
    "    \n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        class_name = row['classification']\n",
    "        percentage = row['percentage']\n",
    "        error_bar = row['error_bar']\n",
    "        \n",
    "        if class_name in classes_wr:\n",
    "            classes_wr[class_name][0] += percentage\n",
    "            classes_wr[class_name][1] += error_bar**2\n",
    "        else:\n",
    "            classes_wr[class_name] = [percentage,error_bar**2]\n",
    "\n",
    "    # classes.append(get_classification3(objects[k]))\n",
    "for class_name, list1 in classes_wr.items():\n",
    "    classes_wr[class_name][0] = round(list1[0] / c , 2)\n",
    "    classes_wr[class_name][1] = np.sqrt(list1[1]) / c\n",
    "sorted_classes_Anm = dict(sorted(classes_wr.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "sorted_classes_Anm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef3af-a6f9-471f-8e82-75fd5522b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 \n",
    "all_objects = dict(list(sorted_classes_All.items())[:nb_classes])\n",
    "anomalous_objects =  dict(list(sorted_classes_Anm.items())[:nb_classes])\n",
    "# Extracting data for plotting\n",
    "classes = list(all_objects.keys())\n",
    "percentages_all = [all_objects[cls][0] for cls in classes]\n",
    "errors_all = [all_objects[cls][1] for cls in classes]\n",
    "\n",
    "percentages_anomalous = [anomalous_objects.get(cls, [0, 0])[0] for cls in classes]\n",
    "errors_anomalous = [anomalous_objects.get(cls, [0, 0])[1] for cls in classes]\n",
    "\n",
    "# Plotting\n",
    "x = np.arange(len(classes))\n",
    "width = 0.35  # Width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot for all objects\n",
    "bars_all = ax.bar(x - width/2, percentages_all, width, yerr=errors_all, label='All Objects', capsize=5)\n",
    "\n",
    "# Plot for anomalous objects\n",
    "bars_anomalous = ax.bar(x + width/2, percentages_anomalous, width, yerr=errors_anomalous, label='Anomalous Objects', capsize=5)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Classes')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Class Distribution Comparison Without repetition')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Adding percentage labels on top of the bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(bars_all)\n",
    "add_labels(bars_anomalous)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a53fab-1901-4e9c-8656-28f20ff2e639",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce496764-e949-4bb3-b9ec-dd13fef4b9aa",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d6f0d-5b43-4eb4-a724-2a62f64bdf5e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362f13c",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
