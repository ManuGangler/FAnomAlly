{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f29f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "df = pd.read_parquet('../scripts/df_merged.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e814c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df['objectId'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df['source'] == 0) | (df['dc_sigflux'] == 0)\n",
    "df['dc_weight'] = np.where(condition, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "df['nr_weight'] = np.where(condition, 0, 1 / (df['nr_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['source'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['source','dc_weight']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca04880",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c328bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=0\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "l=1\n",
    "Q = df[['dc_flux']].iloc[:2*(m+1)]#.values # j:j+m ?\n",
    "\n",
    "d = {k: 0 for k in unique_ids}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn\n",
    "        n = len(T)\n",
    "        zeros = np.zeros(n, dtype=float)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        f = T['dc_flux'].values\n",
    "        w = T['dc_weight'].values\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            #f = T['dc_flux'].values[j*2:] # * 2 !!! for r and g right ? \n",
    "            #w = T['dc_sigflux_weight'].values[j*2:]\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            \n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        s = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        #print(len(s), len(s_n1))\n",
    "        s[mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "            \n",
    "        #alpha = s[::2] + s[1::2] \n",
    "        #print(s)\n",
    "        alpha = np.repeat(s, 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] # :-j*2 it works but not for 0 \n",
    "\n",
    "        d[k] = dd[::2] + dd[1::2]\n",
    "            \n",
    "            \n",
    "    if (d[k] <= factor).all():\n",
    "        print(k, \": \", d[k],\"\\n\")\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(d['ZTF17aaaeclk']<= factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['ZTF17aaaeclk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ddea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe541b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['objectId']=='ZTF17aaaeclk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af74fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3793896",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.32646186*np.array((0.000286,0.000636))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac69fd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f40530",
   "metadata": {},
   "source": [
    "# with l>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1ecb7",
   "metadata": {},
   "source": [
    "this part takes a lot of time ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7654ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2 * (m + 1)\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df[['dc_flux']]) // chunk_size\n",
    "# Split the DataFrame into chunks and store them in an array\n",
    "Q = [df[['dc_flux']].iloc[i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if m>0: #for j in range(1, max(1, m+1)): this isn't faster\n",
    "    for j in range(1, m+1):\n",
    "        Q.extend([df[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "\n",
    "Q = pd.concat(Q) # here we transform Q from list of dataframes to a single data frame  \n",
    "# we will be able to distinct the values by using l variable s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_l = (len(Q)) // chunk_size \n",
    "\n",
    "d   = {k: [0] * Number_l for k in unique_ids[0:10]}\n",
    "alp = {k: [0] * Number_l for k in unique_ids[0:10]}\n",
    "a = {k: [0] * Number_l for k in unique_ids[0:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54318ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:10]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['dc_flux', 'dc_weight']]\n",
    "    n = len(T)\n",
    "    f = T['dc_flux'].values\n",
    "    w = T['dc_weight'].values\n",
    "    \n",
    "    zeros = np.zeros(n, dtype=float)\n",
    "\n",
    "    for l in range(Number_l): # I think we will changee it to while \n",
    "        #print(l)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        d[k][l]=0\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[2*l*(m+1) +j*2: 2*l*(m+1) + j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "        #alp[k][l] = s\n",
    "        \n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[2*l*(m+1) + j*2: 2*l*(m+1) +j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            # 2*l*(m+1) this part is to take from Q by l \n",
    "            \n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] \n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        a[k][l] =  d[k][l] <= factor   \n",
    "            \n",
    "        if (d[k][l] <= factor).all():\n",
    "            print(k, \": \", d[k][l],\"\\n\")\n",
    "            count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_l, len(Q), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19320532",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d[k][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd86d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "alp[k][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f967e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c521f41",
   "metadata": {},
   "source": [
    " j'ai complété l'implémentation `(partie with l>0)`, mais pour 'Q', j'ai actuellement toutes les valeurs possibles pour 'Q' (c'est-à-dire toutes les combinaisons possibles de valeurs de flux)\n",
    " dans ce cas le code fait tous les calculs des distances en stockant les valeurs True ou False si d<= factor (variable 'a') . \n",
    " \n",
    "Cependant, cela rend le calcul trop complexe(avec les donnees completes il ne marche pas (kernel interrepted )). Donc j'essaie de passer à l'approche sélective, mais je rencontre des difficultés avec la logique de sélection, surtout lorsque 'm' est supérieur à zéro.\n",
    "\n",
    " ma compréhension du logique de sélection :\n",
    "\n",
    "- Lorsque 'm' = 0, si la valeur de 'd(i)'  > facteur, je considère 'f(i)' comme la nouvelle valeur de 'Q' (en faites, je prend tous les valeurs f(i) ou d(i)> facteur ce qui réduit 'Q' à ces valeurs)\n",
    "    \n",
    "- Mais lorsque 'm' >0 alors que 'Q' contient deux valeurs ou plus (supposons 'i' et 'i+1'), la condition est : si à la fois 'd(i)' et 'd(i+1)' sont supérieurs au facteur, alors 'Q_next' est composé de 'f(i)' et 'f(i+1)' n'est ce pas ?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e812f26",
   "metadata": {},
   "source": [
    "#### Mr.  : \n",
    "m étant donné. (possiblement m>0)\n",
    "initialiser R(i) à « no match »\n",
    "Pour tout i:\n",
    "\tSi Sum (missing(i) .. missing (i+m) ) <=1    # Tout est missing, ou tout sauf 1 est missing\n",
    "\t\tR_i :=  « missing »\n",
    "Pour tout l < l_max :    # l_max permet de ne fait qu'une partie de l'itération, utile pour débugguer\n",
    "\tInitialiser Q(l) :\n",
    "\t\tSoit un i(l) / R(i(l)) = « no match »    # / pour \"tel que\" \n",
    "\t\t\tsi pas possible : fin\n",
    "\t\tQ(l) := f(i(l)) … f(i(l)+m)\n",
    "\tPour tout i / R(i) = « no match »  :    \n",
    "\t\tcalculer d(i)\n",
    "\t\tsi d(i) < Limit(m):\n",
    "\t\t\tR(i) := l \n",
    "Valeurs de retour : Q(l), R(i), et aussi d(i) à titre d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682a590",
   "metadata": {},
   "source": [
    "###### just to organize my ideas,  we now have all necessary implementations:\n",
    "\n",
    "- 'd' is a function of 'l', 'i', and 'k'. However, I think it's impractical in its current form and requires modification.\n",
    "- 'Q' is a function of 'l' and utilizes vectorized versions of 'hr' and 'hg'. It contains all possible 'l' values.\n",
    "\n",
    "- 'T' of course depends on 'k'. While it might be possible to vectorize it, but it seems it will be too much and inusual)\n",
    "\n",
    "###### \n",
    " 'Alpha' ? |X| , I think it should be defined similarly to 'd'. (- done)\n",
    "\n",
    "the problem is in the time taken by the code.\n",
    "we can reduce the complexity by reduction the 'Q' for each step (I still need to understand the step after the test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe73e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec4a45a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236bfb2",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dd87f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e725f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76658af",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558a98",
   "metadata": {},
   "source": [
    "# With distance - factoor test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1b600",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = unique_ids[0:10]\n",
    "\n",
    "L_max = int(len(objects)/2)  \n",
    "print(\"L_max \", L_max)\n",
    "\n",
    "d = {k: [0] * L_max for k in objects}\n",
    "alp = {k: [0] * L_max for k in objects}\n",
    "a = {k: [0] * L_max for k in objects}\n",
    "R = {k: ['no_match'] * 1 for k in objects}\n",
    "F = {k: [0] for k in objects}\n",
    "W = {k: [0] for k in objects}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "chunk_size =2 * (m + 1)\n",
    "\n",
    "for k in objects:\n",
    "\n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_weight', 'source']]\n",
    "    n = len(T)\n",
    "    F[k] = T['dc_flux'].values\n",
    "    W[k] = T['dc_weight'].values\n",
    "    for i in range(int(n/2)):\n",
    "        box_status = (T['source'][i*chunk_size : (i+1)*chunk_size] == 0)\n",
    "\n",
    "        if box_status.sum() <= 1:\n",
    "            R[k][i*chunk_size : (i+1)*chunk_size] = ['missing']\n",
    "        else:\n",
    "            R[k][i*chunk_size : (i+1)*chunk_size] = ['no_match']#] *  chunk_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "# R = ['no_match']*len(objects)\n",
    "Q = [None] * (L_max+1)\n",
    "l= 0\n",
    "while (l < L_max):\n",
    "    indexes_dict = {key: [i for i, value in enumerate(values) if value == 'no_match'] for key, values in R.items()}\n",
    "    \n",
    "    has_non_empty_list = any(value for value in indexes_dict.values() if value)\n",
    "    if not has_non_empty_list:\n",
    "        break\n",
    "    #print(indexes_dict)\n",
    "    \n",
    "    for k in R: # we can remove the loop for here ! \n",
    "        #print(l , k)\n",
    "        count_match = R[k].count('no_match')\n",
    "        indexes = [index for index, value in enumerate(R[k]) if value == 'no_match']\n",
    "        print(indexes)\n",
    "\n",
    "        if indexes:\n",
    "            f = F[k]\n",
    "#           if count_match > 0:\n",
    "#             index_missing = R[k].index('no_match')\n",
    "#             print(index_missing)\n",
    "\n",
    "            index_no_match = indexes[0]\n",
    "#             print(f)\n",
    "            Q[l] = f[index_no_match*chunk_size : (index_no_match+1)*chunk_size]\n",
    "            break\n",
    "     \n",
    "    \n",
    "    print(\"HELLOOOOO\",Q[l])\n",
    "    \n",
    "    \n",
    "    for k in unique_ids[0:10]:\n",
    "        f = F[k]\n",
    "        w = W[k]\n",
    "        n = len(f)\n",
    "\n",
    "        zeros = np.zeros(n, dtype=float)\n",
    "\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        d[k][l]=0\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[l], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "                 \n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[l], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            # 2*l*(m+1) this part is to take from Q by l \n",
    "            \n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] \n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        a[k][l] =  d[k][l] <= factor \n",
    "        \n",
    "        for b in indexes_dict[k]:\n",
    "            if d[k][l][b] <= factor : \n",
    "                R[k][b] = l\n",
    "#         test = d[k][l][indexes_dict[k]]\n",
    "#         if (test <= factor).any():\n",
    "#             #print(k, \": \", d[k][l],\"\\n\")\n",
    "#             count +=1\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    print(\"print LLLLLLLLL\",l)\n",
    "    l += 1\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77da7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d33b3",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04abf7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d1ca4",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "for j in range(1, max(1, m+1)):\n",
    "    print(j*2)\n",
    "\n",
    "if m>0: \n",
    "    for j in range(1, m+1):\n",
    "        print(j*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a056e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "m = 100\n",
    "\n",
    "code_snippet_1 = \"\"\"\n",
    "for j in range(1, max(1, m+1)):\n",
    "    j*2\n",
    "\"\"\"\n",
    "\n",
    "code_snippet_2 = \"\"\"\n",
    "if m > 0:\n",
    "    for j in range(1, m+1):\n",
    "        j*2\n",
    "\"\"\"\n",
    "\n",
    "time_taken_1 = timeit.timeit(stmt=code_snippet_1, number=1000000, globals=globals())\n",
    "time_taken_2 = timeit.timeit(stmt=code_snippet_2, number=1000000, globals=globals())\n",
    "\n",
    "print(\"Time snippet 1:\", time_taken_1)\n",
    "print(\"Time snippet 2:\", time_taken_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d2a8e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33360431",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72635c7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67470869",
   "metadata": {},
   "source": [
    "# Test for Q all possible values ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values = list(range(10))  \n",
    "\n",
    "# Duplicate each value\n",
    "duplicated_values = [val for val in values for _ in range(2)]\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'dc_flux': duplicated_values})\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc35ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of each chunk\n",
    "m=1\n",
    "chunk_size = 2 * (m + 1)\n",
    "\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df2[['dc_flux']]) // chunk_size\n",
    "\n",
    "# Split the DataFrame into chunks and store them in an array\n",
    "Q = [df2[['dc_flux']].iloc[i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, m+1):\n",
    "    Q.extend([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "    #print([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "############################### importante !!! \n",
    "Q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f63d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "O = pd.concat(Q)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161710eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "(len(O)) // (2*(m+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "j=2\n",
    "l=0\n",
    "#np.tile(Q[(j*2):(j*2+2)], (4 // 2, 1)).ravel()\n",
    "O[2*l*(m+1) +(j*2) : 2*l*(m+1) +(j*2+2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba48ab08",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16500ca4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970a094",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf652e9",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2107d7",
   "metadata": {},
   "source": [
    "# distance dict to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974dcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "\n",
    "# Iterate through the data dictionary and create dictionaries for each object ID\n",
    "for object_id, distances in d.items():\n",
    "    for distance in distances:\n",
    "        list_of_dicts.append({'objectId': object_id, 'distance': distance})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "pdf = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)/2898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['is_distance_gt_factor'] = pdf['distance'] <= factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650230b",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f44885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['objectId'] =='ZTF18acevrat' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "def approach1():\n",
    "    condition = df['source'] == 0\n",
    "    df['dc_sigflux_weight'] = np.where(condition, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "    df['nr_sigflux_weight'] = np.where(condition, 0, 1 / (df['nr_sigflux'] ** 2))\n",
    "\n",
    "def approach2():\n",
    "    df['dc_sigflux_weight'] = 1 / (df['dc_sigflux'] ** 2)\n",
    "    df['nr_sigflux_weight'] = 1 / (df['nr_sigflux'] ** 2)\n",
    "    df['dc_sigflux_weight'] = df['dc_sigflux_weight'] * (df['source'] != 0)\n",
    "    df['nr_sigflux_weight'] = df['nr_sigflux_weight'] * (df['source'] != 0)\n",
    "\n",
    "time_approach2 = timeit.timeit(approach2, number=10)\n",
    "time_approach1 = timeit.timeit(approach1, number=10)\n",
    "\n",
    "print(\"1 execution time:\", time_approach1)\n",
    "print(\"2 execution time:\", time_approach2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "\n",
    "T = {unique_ids.index(k): df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:1]}\n",
    "d = {unique_ids.index(k): np.zeros(int(len(T[k])/2), dtype=np.float64) for k in unique_ids[0:1]}\n",
    "\n",
    "for j in range(1,m+1): \n",
    "    #h = Q.values     \n",
    "    \n",
    "    \n",
    "            for filt in np.unique(T[k]['fid']):\n",
    "                mask = T[k]['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[k][mask]['dc_flux'].values\n",
    "                w = T[k][mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[-1+j:]*h[j-1] * w[-1+j:])\n",
    "                s_d = (h[j-1]**2 * w[-1+j:])\n",
    "\n",
    "                alpha = s_n / s_d\n",
    "                #print(\"alpha\", alpha)\n",
    "                \n",
    "                d[k] += ((f[-1+j:] - alpha * h[j-1])**2) * w[-1+j:]\n",
    "\n",
    "                #break\n",
    "            \n",
    "if (d[k] <= factor).any():\n",
    "        #print(d)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f66bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "#print(Q)\n",
    "\n",
    "#T = {k: df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:100]}\n",
    "d0 = {k: 0 for k in unique_ids[0:10]}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:10]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_sigflux_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn \n",
    "        for j in range(0,m): \n",
    "            \n",
    "            alpha = 0\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[j:]*h[j] * w[j:])\n",
    "                s_d = (h[j]**2 * w[j:])\n",
    "                s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "\n",
    "                alpha += s\n",
    "                #print(\"alpha\", alpha)\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                d0[k] += ((f[j:] - alpha * h[j])**2) * w[j:]\n",
    "               #print()\n",
    "               #print(d)\n",
    "\n",
    "            #break\n",
    "            \n",
    "    if (d0[k] <= factor).all():\n",
    "        print(d0[k],k)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
