{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f29f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.read_parquet('../scripts/df_merged1.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e814c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df['objectId'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df['source'] == 0) | (df['dc_sigflux'] == 0)\n",
    "df['dc_weight'] = np.where(condition, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "df['nr_weight'] = np.where(condition, 0, 1 / (df['nr_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['source'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['source','dc_weight']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca04880",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c328bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=0\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "l=1\n",
    "Q = df[['dc_flux']].iloc[:2*(m+1)]#.values # j:j+m ?\n",
    "\n",
    "d = {k: 0 for k in unique_ids}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn\n",
    "        n = len(T)\n",
    "        zeros = np.zeros(n, dtype=float)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        f = T['dc_flux'].values\n",
    "        w = T['dc_weight'].values\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            #f = T['dc_flux'].values[j*2:] # * 2 !!! for r and g right ? \n",
    "            #w = T['dc_sigflux_weight'].values[j*2:]\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            \n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        s = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        #print(len(s), len(s_n1))\n",
    "        s[mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "            \n",
    "        #alpha = s[::2] + s[1::2] \n",
    "        #print(s)\n",
    "        alpha = np.repeat(s, 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] # :-j*2 it works but not for 0 \n",
    "\n",
    "        d[k] = dd[::2] + dd[1::2]\n",
    "            \n",
    "            \n",
    "    if (d[k] <= factor).all():\n",
    "        print(k, \": \", d[k],\"\\n\")\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(d['ZTF17aaaeclk']<= factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['ZTF17aaaeclk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ddea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe541b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['objectId']=='ZTF17aaaeclk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af74fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3793896",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.32646186*np.array((0.000286,0.000636))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac69fd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f40530",
   "metadata": {},
   "source": [
    "# with l>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdbc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7654ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54318ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=1\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "l=1\n",
    "\n",
    "chunk_size = 2 * (m + 1)\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df[['dc_flux']]) // chunk_size\n",
    "# Split the DataFrame into chunks and store them in an array\n",
    "Q = [df[['dc_flux']].iloc[i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "if m>0: \n",
    "    for j in range(1, m+1):\n",
    "        Q.extend([df[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "\n",
    "Q = pd.concat(Q) # here we transform Q from list of dataframes to a single data frame  \n",
    "# we will be able to distinct the values by using l variable s\n",
    "\n",
    "Number_l = (len(Q)) // (2*(m+1)) \n",
    "\n",
    "d = {k: 0 for k in unique_ids[0:10]}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:10]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['dc_flux', 'dc_weight']]\n",
    "    n = len(T)\n",
    "    f = T['dc_flux'].values\n",
    "    w = T['dc_weight'].values\n",
    "    \n",
    "    zeros = np.zeros(n, dtype=float)\n",
    "\n",
    "    for l in range(Number_l):\n",
    "        #print(l)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        d[k]=0\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[2*l*(m+1) +j*2: 2*l*(m+1) + j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            \n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        s = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        s[mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "\n",
    "        alpha = np.repeat(s, 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[2*l*(m+1) + j*2: 2*l*(m+1) +j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            # 2*l*(m+1) this part is to take from Q by l \n",
    "            \n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] # :-j*2 it works but not for 0 \n",
    "\n",
    "        d[k] = dd[::2] + dd[1::2]\n",
    "            \n",
    "            \n",
    "        if (d[k] <= factor).all():\n",
    "            print(k, \": \", d[k],\"\\n\")\n",
    "            count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88cc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_l, len(Q), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe88960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4071dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae8161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c3b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e26779",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566948b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a450a99",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6671c4c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18983229",
   "metadata": {},
   "source": [
    "# Test for Q all possible values ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values = list(range(10))  \n",
    "\n",
    "# Duplicate each value\n",
    "duplicated_values = [val for val in values for _ in range(2)]\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'dc_flux': duplicated_values})\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc35ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of each chunk\n",
    "m=1\n",
    "chunk_size = 2 * (m + 1)\n",
    "\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df2[['dc_flux']]) // chunk_size\n",
    "\n",
    "# Split the DataFrame into chunks and store them in an array\n",
    "Q = [df2[['dc_flux']].iloc[i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, m+1):\n",
    "    Q.extend([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "    #print([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "############################### importante !!! \n",
    "Q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "O = pd.concat(Q)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6782c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "(len(O)) // (2*(m+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "j=2\n",
    "l=0\n",
    "#np.tile(Q[(j*2):(j*2+2)], (4 // 2, 1)).ravel()\n",
    "O[2*l*(m+1) +(j*2) : 2*l*(m+1) +(j*2+2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c5218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba48ab08",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16500ca4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970a094",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf652e9",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7abbb",
   "metadata": {},
   "source": [
    "# distance dict to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974dcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "\n",
    "# Iterate through the data dictionary and create dictionaries for each object ID\n",
    "for object_id, distances in d.items():\n",
    "    for distance in distances:\n",
    "        list_of_dicts.append({'objectId': object_id, 'distance': distance})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "pdf = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)/2898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['is_distance_gt_factor'] = pdf['distance'] <= factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650230b",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f44885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['objectId'] =='ZTF18acevrat' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "def approach1():\n",
    "    condition = df['source'] == 0\n",
    "    df['dc_sigflux_weight'] = np.where(condition, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "    df['nr_sigflux_weight'] = np.where(condition, 0, 1 / (df['nr_sigflux'] ** 2))\n",
    "\n",
    "def approach2():\n",
    "    df['dc_sigflux_weight'] = 1 / (df['dc_sigflux'] ** 2)\n",
    "    df['nr_sigflux_weight'] = 1 / (df['nr_sigflux'] ** 2)\n",
    "    df['dc_sigflux_weight'] = df['dc_sigflux_weight'] * (df['source'] != 0)\n",
    "    df['nr_sigflux_weight'] = df['nr_sigflux_weight'] * (df['source'] != 0)\n",
    "\n",
    "time_approach2 = timeit.timeit(approach2, number=10)\n",
    "time_approach1 = timeit.timeit(approach1, number=10)\n",
    "\n",
    "print(\"1 execution time:\", time_approach1)\n",
    "print(\"2 execution time:\", time_approach2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "\n",
    "T = {unique_ids.index(k): df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:1]}\n",
    "d = {unique_ids.index(k): np.zeros(int(len(T[k])/2), dtype=np.float64) for k in unique_ids[0:1]}\n",
    "\n",
    "for j in range(1,m+1): \n",
    "    #h = Q.values     \n",
    "    \n",
    "    \n",
    "            for filt in np.unique(T[k]['fid']):\n",
    "                mask = T[k]['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[k][mask]['dc_flux'].values\n",
    "                w = T[k][mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[-1+j:]*h[j-1] * w[-1+j:])\n",
    "                s_d = (h[j-1]**2 * w[-1+j:])\n",
    "\n",
    "                alpha = s_n / s_d\n",
    "                #print(\"alpha\", alpha)\n",
    "                \n",
    "                d[k] += ((f[-1+j:] - alpha * h[j-1])**2) * w[-1+j:]\n",
    "\n",
    "                #break\n",
    "            \n",
    "if (d[k] <= factor).any():\n",
    "        #print(d)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f66bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "#print(Q)\n",
    "\n",
    "#T = {k: df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:100]}\n",
    "d0 = {k: 0 for k in unique_ids[0:10]}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:10]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_sigflux_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn \n",
    "        for j in range(0,m): \n",
    "            \n",
    "            alpha = 0\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[j:]*h[j] * w[j:])\n",
    "                s_d = (h[j]**2 * w[j:])\n",
    "                s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "\n",
    "                alpha += s\n",
    "                #print(\"alpha\", alpha)\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                d0[k] += ((f[j:] - alpha * h[j])**2) * w[j:]\n",
    "               #print()\n",
    "               #print(d)\n",
    "\n",
    "            #break\n",
    "            \n",
    "    if (d0[k] <= factor).all():\n",
    "        print(d0[k],k)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
