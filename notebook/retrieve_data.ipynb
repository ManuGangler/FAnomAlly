{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f29f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39761033",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c647a84",
   "metadata": {},
   "source": [
    "We begin by fetching the reduced data using the Python script `data_transfer.py` from the file `df_merged.parquet`, then importing it into Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../scripts/df_merged.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94d88b",
   "metadata": {},
   "source": [
    "Here we extract all unique IDs from our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e814c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ids = df['objectId'].unique().tolist()\n",
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df18f04",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4b38e",
   "metadata": {},
   "source": [
    "To calculate the weight values \\(w_i\\), we use the formula: `w_i` =\\begin{cases}\n",
    "\\frac{1}{{\\sigma_i^2}}, & \\text{if data is available for day } i \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = (df['source'] == 0) | (df['dc_sigflux'] == 0)\n",
    "df['dc_weight'] = np.where(missing_data, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "df['nr_weight'] = np.where(missing_data, 0, 1 / (df['nr_sigflux'] ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27587801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['source','dc_weight']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef1374",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb06795",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558a98",
   "metadata": {},
   "source": [
    "# With distance - factor test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576f19f",
   "metadata": {},
   "source": [
    "We group the data by shared ID and create `NumPy` arrays for flux, weighted flux, and the source test(if it's a missing day(data)). We also determine the length of each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('objectId')\n",
    "\n",
    "F = grouped['dc_flux'].apply(lambda x: x.values).values\n",
    "W = grouped['dc_weight'].apply(lambda x: x.values).values\n",
    "source = grouped['source'].apply(lambda x: x.values).values\n",
    "lengths = grouped['source'].apply(lambda x: len(x)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b64914",
   "metadata": {},
   "source": [
    "We define the length of our query,window or chunk, along with the limit factor and the size of each window or chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "chunk_size = 2 * (m + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae9b24",
   "metadata": {},
   "source": [
    "The `'no_match_test'` function evaluates whether there are any matches in the provided array, which contains the source test values for a window. If the sum of the array is less than or equal to 1, indicating that all values are missing or only one value is present, the function returns -99. Otherwise, it returns -1 to initialize the window's status as 'no match'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74191626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_match_test(array):\n",
    "    if array.sum() <= 1 : \n",
    "        return -99 ## all are missing, or only one is\n",
    "    return -1 # initialise as no match  # can be modifieted ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fecc96",
   "metadata": {},
   "source": [
    "\"`objects`\" list contains a subset of the objects we intend to work with.\n",
    "\n",
    "\"`L_max`\" is defined to facilitate partial iteration, serving as a debugging aid by allowing a limit to be set on the number of iterations performed.\n",
    "\n",
    "We initialize the NumPy arrays with `None` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = unique_ids[0:1000]\n",
    "num_objects = len(objects)\n",
    "L_max = int(num_objects/2)\n",
    "\n",
    "print(\"L_max \", L_max)\n",
    "\n",
    "\n",
    "R = np.empty(num_objects, dtype=object)\n",
    "alp = np.empty((num_objects, L_max), dtype=object)\n",
    "d = np.empty((num_objects, L_max), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_objects = range(num_objects)\n",
    "Q = [None] * (L_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e82cf3",
   "metadata": {},
   "source": [
    "We initialize R using the '`no_match_test`' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in indexes_objects:\n",
    "\n",
    "    n = lengths[k]\n",
    "    num_chunks = int(n // 2)-m \n",
    "\n",
    "    #print(n,num_chunks)\n",
    "\n",
    "    chunks = np.array([source[k][i*2 : (i*2+chunk_size)] for i in range(num_chunks)])\n",
    "    result = np.array(list(map(no_match_test, chunks)))\n",
    "    R[k] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96498701",
   "metadata": {},
   "source": [
    "### Loop to compute the distance of the subsequence in the time series to its nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "l= 0\n",
    "while (l < L_max):\n",
    "    indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "    \n",
    "    has_non_empty_list = np.any([value.size > 0 for value in indexes_array])\n",
    "    if not has_non_empty_list:\n",
    "        print(\"break , l = \", l )\n",
    "        break\n",
    "        \n",
    "    for k in range(len(R)): # we can remove the loop for here ! ???\n",
    "          if np.any(indexes_array[k]):\n",
    "            f = F[k]\n",
    "            \n",
    "            index_no_match = indexes_array[k][0]\n",
    "            #print(f[index_no_match*2 : index_no_match*2 +chunk_size])\n",
    "            \n",
    "            Q[l] = f[index_no_match*2 : index_no_match*2 +chunk_size]\n",
    "            break\n",
    "            \n",
    "    for k in range(len(objects)):\n",
    "        f = F[k]\n",
    "        w = W[k]\n",
    "        n = lengths[k]\n",
    "        n_c = n - 2*m # (number of chunks x 2) ! it's (n/2 - m) but to optimize we mutiply by 2 directly !  \n",
    "        #print(n, n_c,len(R[k]))\n",
    "\n",
    "\n",
    "\n",
    "        s_1 = np.zeros(n_c, dtype=float)\n",
    "        s_2 = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:] += (f[j*2:j*2+ n_c]*h*w[j*2:j*2+ n_c])\n",
    "            s_2[:] += (h**2 * w[j*2:j*2+ n_c])\n",
    "\n",
    "\n",
    "        s_n = s_1[::2] + s_1[1::2]  \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "\n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "     \n",
    "    \n",
    "        dd = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            \n",
    "            dd[:] += ((f[j*2:j*2+ n_c] - alpha[:] * h)**2) * w[j*2:j*2+ n_c] \n",
    "            #alpha[:n-j*2] ==> alpha[:]\n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        factor_comparison =  d[k][l] <= factor\n",
    "                \n",
    "        R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l # explanation follows below!\n",
    "        \n",
    "#         print(\"indexes_array\",indexes_array[k])\n",
    "#         print(\"factor_comparison\",factor_comparison)\n",
    "#         print(\"factor_comparison[indexes_array]\",factor_comparison[indexes_array[k]])\n",
    "#         print(\"indexes_array[factor_comparison[indexes_array]]\",indexes_array[k][factor_comparison[indexes_array[k]]])\n",
    "#         print(\"R[k]\",R[k])\n",
    "#         print(\"indexes_array[factor_comparison[indexes_array]]\",R[k][indexes_array[k][factor_comparison[indexes_array[k]]]])\n",
    "#         print()\n",
    "#         print()\n",
    "        \n",
    "        \"\"\"for i in indexes_array[k]:\n",
    "            #print(i)\n",
    "            if d[k][l][i] <= factor : \n",
    "                R[k][i] = l\"\"\"\n",
    "     \n",
    "    #print(\"l = \",l)\n",
    "    \n",
    "    l += 1 \n",
    "    \n",
    "print(\"l = \",l)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877d33b3",
   "metadata": {},
   "source": [
    "Let's break down the expression `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l` step by step:\n",
    "\n",
    "1. `indexes_array[k]`: This selects the array of indexes corresponding to the k-th element of `indexes_array`.\n",
    "2. `factor_comparison[indexes_array[k]]`: This applies boolean indexing to `factor_comparison` using the indexes from `indexes_array[k]`. It selects only the elements of `factor_comparison` corresponding to the indexes in `indexes_array[k]`.\n",
    "3. `indexes_array[k][factor_comparison[indexes_array[k]]]`: This gives the indices where the condition `factor_comparison` is true for the k-th element of `indexes_array`.\n",
    "4. `R[k][indexes_array[k][factor_comparison[indexes_array[k]]]]`: This uses the indices obtained in the previous step to select elements from the k-th row of `R`.\n",
    "5. `= l`: Finally, it assigns the value `l` to the selected elements of `R[k]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd26284",
   "metadata": {},
   "outputs": [],
   "source": [
    "F[0],d[0][0],R[0],Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('nested_arrays.npz', array1=d, array2=R, array3=Q)\n",
    "\n",
    "# Load the arrays from the .npz file\n",
    "data = np.load('nested_arrays.npz')\n",
    "\n",
    "# # Retrieve the arrays from the loaded data\n",
    "# d = data['array1']\n",
    "# R = data['array2']\n",
    "# Q = data['array3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e939f3",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac69fd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809db1a0",
   "metadata": {},
   "source": [
    "# Distinguishing the two cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d581437",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "chunk_size = 2 * (m + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = unique_ids[0:1000]\n",
    "num_objects = len(objects)\n",
    "L_max = int(num_objects/2)\n",
    "\n",
    "print(\"L_max \", L_max)\n",
    "\n",
    "\n",
    "R_r = np.empty(num_objects, dtype=object)\n",
    "R_g = np.empty(num_objects, dtype=object)\n",
    "alp = np.empty((num_objects, L_max), dtype=object)\n",
    "d = np.empty((num_objects, L_max), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59113c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in indexes_objects:\n",
    "\n",
    "    n = lengths[k]\n",
    "    num_chunks = int(n // 2)-m \n",
    "\n",
    "    #print(n,num_chunks)\n",
    "\n",
    "    chunks_r = np.array([source[k][i*2 : (i*2+chunk_size):2] for i in range(num_chunks)])\n",
    "    chunks_g = np.array([source[k][1+i*2 : (i*2+chunk_size):2] for i in range(num_chunks)])\n",
    "    result_r = np.array(list(map(no_match_test, chunks)))\n",
    "    result_g = np.array(list(map(no_match_test, chunks)))\n",
    "    R[k] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0064c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "l= 0\n",
    "while (l < L_max):\n",
    "    indexes_array = np.array([np.where(array == -1)[0] for array in R], dtype=object)\n",
    "    \n",
    "    has_non_empty_list = np.any([value.size > 0 for value in indexes_array])\n",
    "    if not has_non_empty_list:\n",
    "        print(\"break , l = \", l )\n",
    "        break\n",
    "        \n",
    "    for k in range(len(R)): # we can remove the loop for here ! ???\n",
    "          if np.any(indexes_array[k]):\n",
    "            f = F[k]\n",
    "            \n",
    "            index_no_match = indexes_array[k][0]\n",
    "            #print(f[index_no_match*2 : index_no_match*2 +chunk_size])\n",
    "            \n",
    "            Q[l] = f[index_no_match*2 : index_no_match*2 +chunk_size]\n",
    "            break\n",
    "            \n",
    "    for k in range(len(objects)):\n",
    "        f = F[k]\n",
    "        w = W[k]\n",
    "        n = lengths[k]\n",
    "        n_c = n - 2*m # (number of chunks x 2) ! it's (n/2 - m) but to optimize we mutiply by 2 directly !  \n",
    "        #print(n, n_c,len(R[k]))\n",
    "\n",
    "\n",
    "\n",
    "        s_1 = np.zeros(n_c, dtype=float)\n",
    "        s_2 = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:] += (f[j*2:j*2+ n_c]*h*w[j*2:j*2+ n_c])\n",
    "            s_2[:] += (h**2 * w[j*2:j*2+ n_c])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1#[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2#[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "\n",
    "        alpha = alp[k][l]#np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "     \n",
    "    \n",
    "        dd = np.zeros(n_c, dtype=float)\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[l][j*2: j*2+2], (len(f[j*2:j*2+ n_c]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            \n",
    "            dd[:] += ((f[j*2:j*2+ n_c] - alpha[:] * h)**2) * w[j*2:j*2+ n_c] \n",
    "            #alpha[:n-j*2] ==> alpha[:]\n",
    "\n",
    "        d[k][l] = dd#[::2] + dd[1::2]\n",
    "        \n",
    "        factor_comparison =  d[k][l] <= factor\n",
    "                \n",
    "        R[k][indexes_array[k][factor_comparison[indexes_array[k]]]] = l # explanation follows below!\n",
    "        \n",
    "#         print(\"indexes_array\",indexes_array[k])\n",
    "#         print(\"factor_comparison\",factor_comparison)\n",
    "#         print(\"factor_comparison[indexes_array]\",factor_comparison[indexes_array[k]])\n",
    "#         print(\"indexes_array[factor_comparison[indexes_array]]\",indexes_array[k][factor_comparison[indexes_array[k]]])\n",
    "#         print(\"R[k]\",R[k])\n",
    "#         print(\"indexes_array[factor_comparison[indexes_array]]\",R[k][indexes_array[k][factor_comparison[indexes_array[k]]]])\n",
    "#         print()\n",
    "#         print()\n",
    "        \n",
    "        \"\"\"for i in indexes_array[k]:\n",
    "            #print(i)\n",
    "            if d[k][l][i] <= factor : \n",
    "                R[k][i] = l\"\"\"\n",
    "     \n",
    "    #print(\"l = \",l)\n",
    "    \n",
    "    l += 1 \n",
    "    \n",
    "print(\"l = \",l)\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1aadf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395df9c7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ff33c",
   "metadata": {},
   "source": [
    "# basic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c328bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=0\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n",
    "l=1\n",
    "Q = df[['dc_flux']].iloc[:2*(m+1)]#.values # j:j+m ?\n",
    "\n",
    "d = {k: 0 for k in unique_ids}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn\n",
    "        n = len(T)\n",
    "        zeros = np.zeros(n, dtype=float)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        f = T['dc_flux'].values\n",
    "        w = T['dc_weight'].values\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            #f = T['dc_flux'].values[j*2:] # * 2 !!! for r and g right ? \n",
    "            #w = T['dc_sigflux_weight'].values[j*2:]\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            \n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        s = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        s[mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "            \n",
    "        alpha = np.repeat(s, 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[j*2:j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] # :-j*2 it works but not for 0 \n",
    "\n",
    "        d[k] = dd[::2] + dd[1::2]\n",
    "            \n",
    "            \n",
    "    if (d[k] <= factor).all():\n",
    "        print(k, \": \", d[k],\"\\n\")\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb1744",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1eaa46",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7109d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f40530",
   "metadata": {},
   "source": [
    "# with l>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdbc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "factor = 2*m+1 + 3*np.sqrt(2*(2*m+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1ecb7",
   "metadata": {},
   "source": [
    "this part takes a lot of time ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7654ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2 * (m + 1)\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(df[['dc_flux']]) // chunk_size\n",
    "# Split the DataFrame into chunks and store them in an array\n",
    "Q = [df[['dc_flux']].iloc[i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if m>0: #for j in range(1, max(1, m+1)): this isn't faster\n",
    "    for j in range(1, m+1):\n",
    "        Q.extend([df[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "\n",
    "Q = pd.concat(Q) # here we transform Q from list of dataframes to a single data frame  \n",
    "# we will be able to distinct the values by using l variable s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_l = 1#(len(Q)) // chunk_size \n",
    "\n",
    "d   = {k: [0] * Number_l for k in unique_ids[0:1]}\n",
    "alp = {k: [0] * Number_l for k in unique_ids[0:1]}\n",
    "a = {k: [0] * Number_l for k in unique_ids[0:1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54318ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:1]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['dc_flux', 'dc_weight']]\n",
    "    n = len(T)\n",
    "    f = T['dc_flux'].values\n",
    "    w = T['dc_weight'].values\n",
    "    \n",
    "    zeros = np.zeros(n, dtype=float)\n",
    "\n",
    "    for l in range(Number_l): # I think we will changee it to while \n",
    "        #print(l)\n",
    "        s_1 = zeros.copy()\n",
    "        s_2 = zeros.copy()\n",
    "        d[k][l]=0\n",
    "        \n",
    "        for j in range(0,m+1): \n",
    "            h = np.tile(Q[2*l*(m+1) +j*2: 2*l*(m+1) + j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "\n",
    "            s_1[:n-j*2] += (f[j*2:]*h*w[j*2:])\n",
    "            s_2[:n-j*2] += (h**2 * w[j*2:])\n",
    "\n",
    "\n",
    "            #s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "        s_n = s_1[::2] + s_1[1::2]  # this needs to optimizate with new variables ! \n",
    "        s_d = s_2[::2] + s_2[1::2] \n",
    "        \n",
    "        mask_no_0 = (s_d != 0)\n",
    "        alp[k][l] = np.zeros_like(s_d, dtype=float)\n",
    "\n",
    "        alp[k][l][mask_no_0] = s_n[mask_no_0] / s_d[mask_no_0] # # Perform division only where s_d(i) is not zero\n",
    "         \n",
    "        #alp[k][l] = s\n",
    "        \n",
    "        alpha = np.repeat(alp[k][l], 2) # duplicate alpha for each value (one for r and second for g)\n",
    "        \n",
    "        dd = zeros.copy()\n",
    "        \n",
    "        for j in range(0,m+1):\n",
    "            h = np.tile(Q[2*l*(m+1) + j*2: 2*l*(m+1) +j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            # 2*l*(m+1) this part is to take from Q by l \n",
    "            print(Q[2*l*(m+1) + j*2: 2*l*(m+1) +j*2+2])\n",
    "            dd[:n-j*2] += ((f[j*2:] - alpha[:n-j*2] * h)**2) * w[j*2:] \n",
    "\n",
    "        d[k][l] = dd[::2] + dd[1::2]\n",
    "        \n",
    "        a[k][l] =  d[k][l] <= factor   \n",
    "            \n",
    "        if (d[k][l] <= factor).all():\n",
    "            print(k, \": \", d[k][l],\"\\n\")\n",
    "            count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_l, len(Q), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19320532",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f967e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c521f41",
   "metadata": {},
   "source": [
    " j'ai complété l'implémentation `(partie with l>0)`, mais pour 'Q', j'ai actuellement toutes les valeurs possibles pour 'Q' (c'est-à-dire toutes les combinaisons possibles de valeurs de flux)\n",
    " dans ce cas le code fait tous les calculs des distances en stockant les valeurs True ou False si d<= factor (variable 'a') . \n",
    " \n",
    "Cependant, cela rend le calcul trop complexe(avec les donnees completes il ne marche pas (kernel interrepted )). Donc j'essaie de passer à l'approche sélective, mais je rencontre des difficultés avec la logique de sélection, surtout lorsque 'm' est supérieur à zéro.\n",
    "\n",
    " ma compréhension du logique de sélection :\n",
    "\n",
    "- Lorsque 'm' = 0, si la valeur de 'd(i)'  > facteur, je considère 'f(i)' comme la nouvelle valeur de 'Q' (en faites, je prend tous les valeurs f(i) ou d(i)> facteur ce qui réduit 'Q' à ces valeurs)\n",
    "    \n",
    "- Mais lorsque 'm' >0 alors que 'Q' contient deux valeurs ou plus (supposons 'i' et 'i+1'), la condition est : si à la fois 'd(i)' et 'd(i+1)' sont supérieurs au facteur, alors 'Q_next' est composé de 'f(i)' et 'f(i+1)' n'est ce pas ?\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e812f26",
   "metadata": {},
   "source": [
    "#### Mr.  : \n",
    "m étant donné. (possiblement m>0)\n",
    "initialiser R(i) à « no match »\n",
    "Pour tout i:\n",
    "\tSi Sum (missing(i) .. missing (i+m) ) <=1    # Tout est missing, ou tout sauf 1 est missing\n",
    "\t\tR_i :=  « missing »\n",
    "Pour tout l < l_max :    # l_max permet de ne fait qu'une partie de l'itération, utile pour débugguer\n",
    "\tInitialiser Q(l) :\n",
    "\t\tSoit un i(l) / R(i(l)) = « no match »    # / pour \"tel que\" \n",
    "\t\t\tsi pas possible : fin\n",
    "\t\tQ(l) := f(i(l)) … f(i(l)+m)\n",
    "\tPour tout i / R(i) = « no match »  :    \n",
    "\t\tcalculer d(i)\n",
    "\t\tsi d(i) < Limit(m):\n",
    "\t\t\tR(i) := l \n",
    "Valeurs de retour : Q(l), R(i), et aussi d(i) à titre d'information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4a45a",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76658af",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77da7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04abf7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d1ca4",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9]\n",
    "list2 = [[0,0,1,1],[1,1,2,2],[2,2,3,3],[3,3,4,4],[4,4,5,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8dbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "idx =3\n",
    "chunk_size = 2 * (m + 1)\n",
    "list1[idx*2:idx*2+chunk_size:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "idx =3\n",
    "chunk_size = 2 * (m + 1)\n",
    "list1[idx*2:idx*2+chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafa347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R = np.empty(len(objects), dtype=object)\n",
    "\n",
    "m=1\n",
    "chunk_size =2 * (m + 1)\n",
    "\n",
    "for k in range(len(objects)):\n",
    "\n",
    "    n = len(source[k])\n",
    "    #num_chunks = n // chunk_size\n",
    "\n",
    "    #chunks = [source[k][i*chunk_size : (i+1)*chunk_size] for i in range(num_chunks)]\n",
    "    num_chunks = int(n // 2)-m \n",
    "\n",
    "    print(n,num_chunks)\n",
    "\n",
    "\n",
    "    chunks = np.array([source[k][i*2 : (i*2+chunk_size)] for i in range(num_chunks)])\n",
    "#     if m>0: \n",
    "#         for j in range(1, m+1):\n",
    "#             chunks.extend([source[k][i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "#     if m > 0:\n",
    "#         for j in range(1, m + 1):\n",
    "#             for i in range(num_chunks - 1):\n",
    "#                 chunks.append(source[k][i * chunk_size + j * 2: (i + 1) * chunk_size + j * 2])\n",
    "\n",
    "    #result = np.concatenate(np.array([no_match_test(chunk) for chunk in chunks]))  # Apply no_match_test directly\n",
    "    result = np.array(list(map(no_match_test, chunks)))\n",
    "    R[k] = result\n",
    "\n",
    "    ### le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c675867",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "for j in range(1, max(1, m+1)):\n",
    "    print(j*2)\n",
    "\n",
    "if m>0: \n",
    "    for j in range(1, m+1):\n",
    "        print(j*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a056e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "m = 100\n",
    "\n",
    "code_snippet_1 = \"\"\"\n",
    "s_1 = np.zeros(n, dtype=float)\n",
    "s_2 = np.zeros(n, dtype=float)\n",
    "s_3 = np.zeros(n, dtype=float)\n",
    "s_4 = np.zeros(n, dtype=float)\n",
    "s_5 = np.zeros(n, dtype=float)\n",
    "s_6 = np.zeros(n, dtype=float)\n",
    "\"\"\"\n",
    "\n",
    "code_snippet_2 = \"\"\"\n",
    "zeros = np.zeros(n, dtype=float)\n",
    "\n",
    "s_1 = zeros.copy()\n",
    "s_2 = zeros.copy()\n",
    "s_3 = zeros.copy()\n",
    "s_4 = zeros.copy()\n",
    "s_5 = zeros.copy()\n",
    "s_6 = zeros.copy()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "time_taken_1 = timeit.timeit(stmt=code_snippet_1, number=10000000, globals=globals())\n",
    "time_taken_2 = timeit.timeit(stmt=code_snippet_2, number=10000000, globals=globals())\n",
    "\n",
    "print(\"Time snippet 1:\", time_taken_1)\n",
    "print(\"Time snippet 2:\", time_taken_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d2a8e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33360431",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72635c7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67470869",
   "metadata": {},
   "source": [
    "# Test for Q all possible values ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "values = list(range(12))  \n",
    "\n",
    "# Duplicate each value\n",
    "duplicated_values = [val for val in values for _ in range(2)]\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'dc_flux': duplicated_values})\n",
    "\n",
    "#print(df2)\n",
    "print(duplicated_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb27875",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,m+1):\n",
    "            h = np.tile(Q[0][j*2: j*2+2], (len(f[j*2:]) // 2, 1)).ravel() # array of h for r and g successive for the vectorisation\n",
    "            print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc35ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the size of each chunk\n",
    "m=1\n",
    "chunk_size = 2 * (m + 1)\n",
    "\n",
    "# Calculate the number of chunks\n",
    "num_chunks = int(len(duplicated_values) // 2) -m \n",
    "print(num_chunks,chunk_size)\n",
    "\n",
    "values =duplicated_values\n",
    "Q = [duplicated_values[i*2 : (i*2+chunk_size)] for i in range(num_chunks)]\n",
    "Q,len(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(list(map(no_match_test, np.array(Q))))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d391abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q =[]\n",
    "# Q =[]\n",
    "# for i in range(0,num_chunks):\n",
    "#     Q.append(values[i*2 : (i*2+chunk_size)])\n",
    "# Q\n",
    "# for i in range(0,num_chunks):\n",
    "#     print(i*2)\n",
    "#     print(values[i*2 : (i*2+chunk_size)])\n",
    "#     Q.append(values[i : (i*2+chunk_size)])\n",
    "# Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49556c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "chunk_size = 2 * (m + 1)\n",
    "\n",
    "# Calculate the number of chunks\n",
    "num_chunks = len(duplicated_values) - chunk_size + 1\n",
    "print(num_chunks)\n",
    "# Split the DataFrame into overlapping chunks and store them in an array\n",
    "Q = [values[i : i + chunk_size] for i in range(num_chunks)]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1973ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1, m+1):\n",
    "    Q.extend([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "    #print([df2[['dc_flux']].iloc[i*chunk_size +j*2 : (i+1)*chunk_size+j*2] for i in range(num_chunks-1)])\n",
    "############################### importante !!! \n",
    "Q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f63d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "O = pd.concat(Q)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1187cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "j=2\n",
    "l=0\n",
    "#np.tile(Q[(j*2):(j*2+2)], (4 // 2, 1)).ravel()\n",
    "O[2*l*(m+1) +(j*2) : 2*l*(m+1) +(j*2+2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16500ca4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970a094",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf652e9",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2107d7",
   "metadata": {},
   "source": [
    "# distance dict to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974dcef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "\n",
    "# Iterate through the data dictionary and create dictionaries for each object ID\n",
    "for object_id, distances in d.items():\n",
    "    for distance in distances:\n",
    "        list_of_dicts.append({'objectId': object_id, 'distance': distance})\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "pdf = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)/2898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['is_distance_gt_factor'] = pdf['distance'] <= factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650230b",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f44885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['objectId'] =='ZTF18acevrat' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "def approach1():\n",
    "    condition = df['source'] == 0\n",
    "    df['dc_sigflux_weight'] = np.where(condition, 0, 1 / (df['dc_sigflux'] ** 2))\n",
    "    df['nr_sigflux_weight'] = np.where(condition, 0, 1 / (df['nr_sigflux'] ** 2))\n",
    "\n",
    "def approach2():\n",
    "    df['dc_sigflux_weight'] = 1 / (df['dc_sigflux'] ** 2)\n",
    "    df['nr_sigflux_weight'] = 1 / (df['nr_sigflux'] ** 2)\n",
    "    df['dc_sigflux_weight'] = df['dc_sigflux_weight'] * (df['source'] != 0)\n",
    "    df['nr_sigflux_weight'] = df['nr_sigflux_weight'] * (df['source'] != 0)\n",
    "\n",
    "time_approach2 = timeit.timeit(approach2, number=10)\n",
    "time_approach1 = timeit.timeit(approach1, number=10)\n",
    "\n",
    "print(\"1 execution time:\", time_approach1)\n",
    "print(\"2 execution time:\", time_approach2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "\n",
    "T = {unique_ids.index(k): df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:1]}\n",
    "d = {unique_ids.index(k): np.zeros(int(len(T[k])/2), dtype=np.float64) for k in unique_ids[0:1]}\n",
    "\n",
    "for j in range(1,m+1): \n",
    "    #h = Q.values     \n",
    "    \n",
    "    \n",
    "            for filt in np.unique(T[k]['fid']):\n",
    "                mask = T[k]['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[k][mask]['dc_flux'].values\n",
    "                w = T[k][mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[-1+j:]*h[j-1] * w[-1+j:])\n",
    "                s_d = (h[j-1]**2 * w[-1+j:])\n",
    "\n",
    "                alpha = s_n / s_d\n",
    "                #print(\"alpha\", alpha)\n",
    "                \n",
    "                d[k] += ((f[-1+j:] - alpha * h[j-1])**2) * w[-1+j:]\n",
    "\n",
    "                #break\n",
    "            \n",
    "if (d[k] <= factor).any():\n",
    "        #print(d)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f66bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "m=1\n",
    "factor = 2*m -1 + 3*np.sqrt(2*(2*m -1))\n",
    "l=1\n",
    "Q = df[['fid', 'dc_flux']].iloc[:2*m]#.values # j:j+m ?\n",
    "#print(Q)\n",
    "\n",
    "#T = {k: df[df['objectId'] == k][['fid', 'dc_flux', 'dc_sigflux_weight']] for k in unique_ids[0:100]}\n",
    "d0 = {k: 0 for k in unique_ids[0:10]}\n",
    "#print(d)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in unique_ids[0:10]:\n",
    "    \n",
    "    T = df[df['objectId'] == k][['fid','dc_flux', 'dc_sigflux_weight']]\n",
    "    for l in [0]:\n",
    "        #d[k]=0\n",
    "        # we don't use it rn \n",
    "        for j in range(0,m): \n",
    "            \n",
    "            alpha = 0\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                s_n = (f[j:]*h[j] * w[j:])\n",
    "                s_d = (h[j]**2 * w[j:])\n",
    "                s = np.where(s_d == 0, 0, s_n / s_d)\n",
    "\n",
    "                alpha += s\n",
    "                #print(\"alpha\", alpha)\n",
    "            for filt in np.unique(T['fid']):\n",
    "                mask = T['fid'] == filt\n",
    "                h = Q[Q['fid'] == filt ]['dc_flux'].values     \n",
    "                f = T[mask]['dc_flux'].values\n",
    "                w = T[mask]['dc_sigflux_weight'].values\n",
    "\n",
    "                d0[k] += ((f[j:] - alpha * h[j])**2) * w[j:]\n",
    "               #print()\n",
    "               #print(d)\n",
    "\n",
    "            #break\n",
    "            \n",
    "    if (d0[k] <= factor).all():\n",
    "        print(d0[k],k)\n",
    "        count +=1\n",
    "        #print(count, k)\n",
    "        \n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #print(d[k],k)\n",
    "        \n",
    "print(count)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
