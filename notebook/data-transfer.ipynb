{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f8385",
   "metadata": {},
   "source": [
    "# 1) Upload data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68831f6",
   "metadata": {},
   "source": [
    "Initially, we acquired the data from FINK using the link provided: https://fink-portal.org/download.\n",
    "\n",
    "#### Now, let's import the data into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6810444",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_parquet('../../ftransfer_ztf_2024-02-01_689626')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0005021",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b78ae0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228083e5",
   "metadata": {},
   "source": [
    "# 2) Select alert and bluid the data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207add8",
   "metadata": {},
   "source": [
    "### We select alerts (data) based on their shared ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = pdf['objectId'][4771]\n",
    "\n",
    "id_plus_repete = pdf['objectId'].value_counts().idxmax()\n",
    "Id = \"ZTF17aaaaoqd\"\n",
    "#Id = \"ZTF20abvtozi\"\n",
    "# here opting for the most frequently occurring alert.\n",
    "pdf_selectionne = pdf.loc[pdf['objectId'] == Id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c0c24",
   "metadata": {},
   "source": [
    "### Choose the last alert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be404",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pdf_selectionne['candidate'].apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pdf_selectionne['candidate'].apply(pd.Series)\n",
    "\n",
    "# index of the candidate with the biggest 'jd'\n",
    "index_max_jd = candidate_df['jd'].idxmax()\n",
    "\n",
    "# select this candidate\n",
    "pdf_selectionne = pdf_selectionne.loc[index_max_jd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374623a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c878ac",
   "metadata": {},
   "source": [
    "### Transform the data of all candidates (including `prv_candidates` and the last one) into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_selectionne_cand = pdf_selectionne['prv_candidates'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd041afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add 'candidate' the actual value \n",
    "keys = pdf_selectionne_cand[0].keys()\n",
    "actual_cand = {key: pdf_selectionne['candidate'][key] for key in keys if key in pdf_selectionne['candidate']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2516f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dicts = list(pdf_selectionne_cand)\n",
    "liste_dicts.append(actual_cand)\n",
    "df = pd.DataFrame(liste_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb6079",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4c784",
   "metadata": {},
   "source": [
    "# 3) plot Difference Magnitude in Modified Julian Date [UTC]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd102bb",
   "metadata": {},
   "source": [
    "_Circles (●) with error bars show valid alerts that pass the Fink quality cuts.\n",
    "In addition, the Difference magnitude view shows:\n",
    "\n",
    "_upper triangles with errors (▲), representing alert measurements that do not satisfy Fink quality cuts, but are nevetheless contained in the history of valid alerts and used by classifiers.\n",
    "\n",
    "_lower triangles (▽), representing 5-sigma magnitude limit in difference image based on PSF-fit photometry contained in the history of valid alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mjd = df['jd'].apply(lambda x: x - 2400000.5)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "# valid values \n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "# Upper limit values\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "#bad quality values \n",
    "maskBadquality = ~maskValid & ~maskUpper\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt]['magpsf'],\n",
    "        df[maskValid & maskFilt]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} band'.format(filtdic[filt])\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        df[maskUpper & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskUpper & maskFilt]['diffmaglim'],\n",
    "        ls='', marker='v', color=colordic[filt], markerfacecolor='none'\n",
    "    )\n",
    "    \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskBadquality & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskBadquality & maskFilt]['magpsf'],\n",
    "        df[maskBadquality & maskFilt]['sigmapsf'],\n",
    "        ls='', marker='^', color=colordic[filt]\n",
    "    )\n",
    "\n",
    "#plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35bf46",
   "metadata": {},
   "source": [
    "# Plot the magnitude difference for valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34ecf0",
   "metadata": {},
   "source": [
    "Distinguishing between positive differences represented by circles and negative differences represented by triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "    \n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "\n",
    "    \n",
    "#t or 1 => candidate is from positive (sci minus ref) subtraction;\n",
    "#f or 0 => candidate is from negative (ref minus sci) subtraction\"\n",
    "maskpos = (df['isdiffpos'] == 't') | (df['isdiffpos'] == 1)\n",
    "maskneg = (df['isdiffpos'] == 'f') | (df['isdiffpos'] == 0)\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    # candidates from negative \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt & maskneg ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt & maskneg ]['magpsf'],\n",
    "        df[maskValid & maskFilt & maskneg ]['sigmapsf'],\n",
    "        ls = '', marker='^', color=colordic[filt], label='{} (-)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "    # candidates from positive \n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt &  maskpos ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt &  maskpos ]['magpsf'],\n",
    "        df[maskValid & maskFilt &  maskpos ]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} (+)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "\n",
    "#plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf6121",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7320a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146da65d",
   "metadata": {},
   "source": [
    "# 4) Verify whether there is a source behind the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7f388",
   "metadata": {},
   "source": [
    "If so, we compute the magnitude DC using the `dc_mag` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17e03a",
   "metadata": {},
   "source": [
    " And we extract a subset of validated data into a dataframe for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fink_science.conversion import dc_mag\n",
    "from fink_utils.photometry.conversion import dc_mag\n",
    "from fink_utils.photometry.utils import is_source_behind\n",
    "\n",
    "# Take only valid measurements\n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "df_valid = df[maskValid].sort_values('jd')\n",
    "\n",
    "isSource = is_source_behind(\n",
    "    df_valid['distnr'].values[0]\n",
    ")\n",
    "\n",
    "if isSource:\n",
    "    print('It looks like there is a source behind. Lets compute the DC magnitude instead.')\n",
    "    \n",
    "    # Use DC magnitude instead of difference mag\n",
    "    mag_dc, err_dc = np.transpose(\n",
    "        [\n",
    "            dc_mag(*args) for args in zip(\n",
    "                df_valid['magpsf'].astype(float).values,\n",
    "                df_valid['sigmapsf'].astype(float).values,\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values,\n",
    "                df_valid['isdiffpos'].values\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df_valid['mag_dc'] = mag_dc\n",
    "    df_valid['err_dc'] = err_dc\n",
    "else:\n",
    "    print('No source found -- keeping PSF fit magnitude')\n",
    "    df_valid['mag_dc'] = df_valid['magpsf']\n",
    "    df_valid['err_dc'] = df_valid['sigmapsf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb64c6",
   "metadata": {},
   "source": [
    "### Next, we plot the comparison between PSF-fit magnitudes and DC magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f96483",
   "metadata": {},
   "source": [
    "We calculate the reference value as the average magnitude of the nearest source in the reference image PSF catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "for filt in np.unique(df_valid['fid']):\n",
    "    maskFilt = df_valid['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['magpsf'],\n",
    "        df_valid[maskFilt]['sigmapsf'],\n",
    "        ls = '', marker='x', \n",
    "        color=colordic[filt], \n",
    "        label='{} band (PSF-fit)'.format(filtdic[filt]),\n",
    "    )\n",
    "    \n",
    "    \n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['mag_dc'],\n",
    "        df_valid[maskFilt]['err_dc'],\n",
    "        ls = '', marker='o', \n",
    "        color=colordic[filt], \n",
    "        label='{} band (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    #To show if there is a variance in the reference( magnitude of the nearest source in the reference image PSF)\n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['magnr'],\n",
    "        ls = '--', \n",
    "        color=colordic[filt], \n",
    "        label='{} ref (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    \n",
    "\n",
    "ref_r = np.sqrt((df_valid[df_valid['fid'] == 2]['magnr'] ** 2).mean())# Quadratic Mean\n",
    "ref_g = np.sqrt((df_valid[df_valid['fid'] == 1]['magnr'] ** 2).mean())\n",
    "\n",
    "\n",
    "#  Average Values (Used in Fink)\n",
    "#plt.axhline(y=ref_r, color=colordic[2], linestyle='--')\n",
    "#plt.axhline(y=ref_g, color=colordic[1], linestyle='--')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Comparison of PSF-fit and DC magnitudes')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Magnitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b07b1b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbec51a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9302975",
   "metadata": {},
   "source": [
    "# 5) Calculate and plot Apparent DC flux  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c69e3",
   "metadata": {},
   "source": [
    "We utilize a function(`apparent_flux`) located within the `fink_utils` package to compute the apparent flux for the valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "from fink_utils.photometry.conversion import apparent_flux\n",
    "\n",
    "\n",
    "dc_flux, dc_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux(*args, jansky=True) for args in zip(\n",
    "                df_valid['magpsf'].astype(float).values,\n",
    "                df_valid['sigmapsf'].astype(float).values,\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values,\n",
    "                df_valid['isdiffpos'].values\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['dc_flux'] = dc_flux\n",
    "df_valid['dc_sigflux'] = dc_sigflux\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3,\n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        label=filt\n",
    "    )\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d75848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid[['jd', 'fid', 'dc_flux']]#,'mjd'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe5d71",
   "metadata": {},
   "source": [
    "## Apparent flux for the nearest source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45ab7e",
   "metadata": {},
   "source": [
    "We create a function `apparent_flux` to determine the apparent flux for the nearest source in the reference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51e48f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from FAnomAly_utils.flux import flux_nr\n",
    "#from FAnomAlly.FAnomAly_utils.flux import flux_nr\n",
    "nr_flux, nr_sigflux = np.transpose(\n",
    "        [\n",
    "            flux_nr(*args, jansky=True) for args in zip(\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['nr_flux'] = nr_flux\n",
    "df_valid['nr_sigflux'] = nr_sigflux\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76716d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372399a2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765880f1",
   "metadata": {},
   "source": [
    "# 6) Data missing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0759eda",
   "metadata": {},
   "source": [
    "Our objective here is to retrieve the missing data values, particularly for cases where they represent upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only Upper limits data\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "\n",
    "df_Upper = df[maskUpper].sort_values('jd')#, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a5ed4",
   "metadata": {},
   "source": [
    "Compute the average of the sigma magnitude values for the nearest sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmnr_r = np.sqrt((df_valid[df_valid['fid'] == 2]['sigmagnr'] ** 2).mean())\n",
    "sigmnr_g = np.sqrt((df_valid[df_valid['fid'] == 1]['sigmagnr'] ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926d3fb",
   "metadata": {},
   "source": [
    "We define a function named `apparent_flux_Upper` to calculate the apparent flux, along with its associated sigma (error), for both the DC flux and NR flux, specifically for data representing upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAnomAly_utils.flux import apparent_flux_Upper\n",
    "\n",
    "dc_flux, dc_sigflux,nr_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux_Upper(*args, ref_r, ref_g, sigmnr_r, sigmnr_g, jansky=True) for args in zip(\n",
    "                df_Upper['diffmaglim'].astype(float).values,\n",
    "                df_Upper['fid'].astype(int).values,\n",
    "\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_Upper['dc_flux'] = dc_flux\n",
    "df_Upper['dc_sigflux'] = dc_sigflux\n",
    "df_Upper['nr_sigflux'] = nr_sigflux\n",
    "df_Upper['nr_flux'] = dc_flux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a918d",
   "metadata": {},
   "source": [
    "### Plot the apparent DC flux (in millijansky) for both valid and upper limits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db693860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} valid\"\n",
    "    )\n",
    "    \n",
    "    mask2 = df_Upper['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df_Upper[mask2]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_Upper[mask2]['dc_flux']*1e3,\n",
    "        df_Upper[mask2]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Upperlim\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7453ea6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf0776",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae0fe5",
   "metadata": {},
   "source": [
    "# 7) Combine Upper with valid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616249f2",
   "metadata": {},
   "source": [
    "We merge the data from the upper limit and valid datasets based on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83977c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['jd', 'fid','dc_flux', 'dc_sigflux', 'nr_flux', 'nr_sigflux']\n",
    "combined_df = pd.concat([df_Upper[columns_to_keep], df_valid[columns_to_keep]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf479ce",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbd07c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b941e8",
   "metadata": {},
   "source": [
    "# 8) Data by days "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade442e",
   "metadata": {},
   "source": [
    "Here, we group the data by modified Julian date on a daily basis and by filter ID (1 for g, 2 for R, 3 for i), computing the average values of flux and sigma flux(for both DC and NR) using the `Weighted_Mean` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['mjd'] = combined_df['jd'].apply(lambda x: x - 2400000.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54621832",
   "metadata": {},
   "source": [
    "#### Convert 'mjd' to integer to remove fractional part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc85e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['mjd'] = combined_df['mjd'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560339d1",
   "metadata": {},
   "source": [
    "#### group the data by mjd and by filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70711f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = combined_df.groupby(['mjd','fid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94fb10",
   "metadata": {},
   "source": [
    "#### calculate the average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from FAnomAly_utils.Weighted_Mean import Weighted_Mean_general\n",
    "\n",
    "df_mod = pd.DataFrame()\n",
    "df_mod = df2.apply(Weighted_Mean_general, flux_col='dc_flux', sigflux_col='dc_sigflux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf35e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod[['nr_flux', 'nr_sigflux']] = df2.apply(Weighted_Mean_general, flux_col='nr_flux',sigflux_col='nr_sigflux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74da68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only once !...\n",
    "df_mod.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b932d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428ad40",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6faa8",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40124d6",
   "metadata": {},
   "source": [
    "# 9) Fill the missing days ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53876f8",
   "metadata": {},
   "source": [
    "If there are missing days without alerts in the data, we can fill these gaps by inserting average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33983e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAnomAly_utils.Weighted_Mean import Weighted_Mean_all\n",
    "\n",
    "min_mjd = df_mod['mjd'].min()\n",
    "max_mjd = df_mod['mjd'].max()\n",
    "# Create a DataFrame all_days containing a range of MJD values from the minimum to the maximum MJD found in df_mod.\n",
    "all_days = pd.DataFrame({'mjd': range(min_mjd, max_mjd + 1)})\n",
    "\n",
    "df_extended = df_mod\n",
    "df_extended['source'] = 'Original'\n",
    "\n",
    "\n",
    "#If this condition is true, it indicates that there is missing data.\n",
    "if (df_mod.shape[0] < (max_mjd -min_mjd + 1)*2):        \n",
    "     for filt in np.unique(df_extended['fid']):\n",
    "        print(filt)\n",
    "        mask = df_extended['fid'] == filt\n",
    "        sub = df_extended[mask]\n",
    "        data_days = df_extended[mask]['mjd']\n",
    "\n",
    "        missing_days = all_days[~all_days['mjd'].isin(data_days)]\n",
    "    \n",
    "    \n",
    "        df_new = pd.DataFrame(index=missing_days['mjd'])\n",
    "    \n",
    "        dc_flux ,nr_flux = Weighted_Mean_all(sub)\n",
    "        \n",
    "        dc_sigflux = sub['dc_flux'].std()\n",
    "        nr_sigflux = sub['nr_flux'].std()\n",
    "        \n",
    "        #print(dc_flux*1e3, dc_sigflux*1e3 ,nr_flux*1e3 ,nr_sigflux*1e3)\n",
    "\n",
    "        \n",
    "        df_new[['fid','dc_flux', 'dc_sigflux' ,'nr_flux' ,'nr_sigflux']] = [filt,dc_flux, dc_sigflux ,nr_flux ,nr_sigflux]\n",
    "        df_new['source'] = 'Missing'\n",
    "\n",
    "        # Add a new column 'source' to df_extended\n",
    "\n",
    "        df_extended = pd.concat([df_extended, df_new.reset_index()], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c40a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.sort_values(by='mjd',   inplace=True)\n",
    "df_extended.reset_index(drop= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4d55b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_extended.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4a387",
   "metadata": {},
   "source": [
    "### plot apparent  DC and nr flux in millijanksy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "\n",
    "for filt in np.unique(df_extended['fid']):\n",
    "    mask = df_extended['fid'] == filt\n",
    "    mask_missing =  df_extended['source'] == \"Missing\"\n",
    "    mask_original = df_extended['source'] == \"Original\"\n",
    "    sub2 = df_extended[mask & mask_missing]\n",
    "    sub = df_extended[mask & mask_original]\n",
    "    \n",
    "    plt.errorbar(\n",
    "        sub['mjd'],\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} original flux dc\"\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        sub2['mjd'],\n",
    "        sub2['dc_flux']*1e3, \n",
    "        #sub2['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='x',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Missing flux dc\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    \"\"\"plt.errorbar(\n",
    "        df[mask]['mjd'],\n",
    "        df[mask]['nr_flux']*1e3,\n",
    "        df[mask]['nr_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all nr\"\n",
    "    )\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent  DC and nr flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe88c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df_mod['fid']):\n",
    "    mask = df_mod['fid'] == filt\n",
    "    sub = df_mod\n",
    "    plt.errorbar(\n",
    "        sub[mask]['mjd'],\n",
    "        sub[mask]['dc_flux']*1e3, \n",
    "        sub[mask]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all flux dc\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    \"\"\"plt.errorbar(\n",
    "        df[mask]['mjd'],\n",
    "        df[mask]['nr_flux']*1e3,\n",
    "        df[mask]['nr_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all nr\"\n",
    "    )\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent  DC and nr flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mjd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdaf6f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff4db1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503bea0",
   "metadata": {},
   "source": [
    "# 10) Create a final dataframe to consolidate the values of this alert into a single row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7954a",
   "metadata": {},
   "source": [
    "In this dataframe, include another dataframe as a dictionary containing the values of mjd,flux, sigma, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly = pd.DataFrame()\n",
    "df_anomaly['objectId'] = [pdf_selectionne.objectId]\n",
    "df_anomaly['candid'] = [pdf_selectionne.candid]\n",
    "df_anomaly['jd'] = [pdf_selectionne.candidate['jd']]\n",
    "df_anomaly['df'] = [df_extended.to_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ddc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's an example of how we can utilize the dataframe of the first row:\n",
    "df = pd.DataFrame.from_dict(df_anomaly['df'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23333851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adb25b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf81c9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56786483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a76f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542d8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87571cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f88fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
