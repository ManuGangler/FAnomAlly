{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302f8385",
   "metadata": {},
   "source": [
    "# 1) Upload data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68831f6",
   "metadata": {},
   "source": [
    "Initially, we acquired the data from FINK using the link provided: https://fink-portal.org/download.\n",
    "\n",
    "#### Now, let's import the data into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6810444",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_parquet('../../ftransfer_ztf_2024-02-01_689626')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0005021",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb204e6",
   "metadata": {},
   "source": [
    "#### Here we calculate the first and last days on which an alert was recorded across all the data. \n",
    "we're identifying the earliest and latest dates observed across all the alerts in the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_series = pdf.candidate.apply(pd.Series)['jd']\n",
    "\n",
    "last_day = jd_series.max()\n",
    "# this is not the perfect way to verify the min but we suppose that 'jd' is sorted\n",
    "first_day = last_day\n",
    "for k in range(len(pdf)):\n",
    "    if first_day > pdf.prv_candidates[k][0]['jd']:\n",
    "        first_day = pdf.prv_candidates[k][0]['jd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d1881",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228083e5",
   "metadata": {},
   "source": [
    "# 2) Select alert and bluid the data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207add8",
   "metadata": {},
   "source": [
    "### We select alerts (data) based on their shared ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = pdf['objectId'][4771]\n",
    "\n",
    "id_most_repeated = pdf['objectId'].value_counts().idxmax()\n",
    "\n",
    "Id = \"ZTF18acoyqvk\" # max by j (for all Q) here we got = 119 on idx = 13 (all Q matched)\n",
    "# Id = \"ZTF18abosdhe\" #min by j ,  ( idx = 5 , with one Q )\n",
    "\n",
    "#Id = \"ZTF18adarfuu\" # max by Q idx = 6\n",
    "Id = \"ZTF18aaxyrcb\" # min by Q idx = 7\n",
    "Id = \"ZTF19abizgyw\" # <10 data \n",
    "\n",
    "Id = \"ZTF18acckcza\" # Anomaly data analysis \n",
    "Id = \"ZTF18acevrat\" # probUpperlim\n",
    "\n",
    "pdf_filter_by_shared_Id = pdf.loc[pdf['objectId'] == Id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c0c24",
   "metadata": {},
   "source": [
    "### Choose the last alert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pdf_filter_by_shared_Id['candidate'].apply(pd.Series)\n",
    "\n",
    "candidate_df = candidate_df.sort_values(by= 'jd')\n",
    "index_max_jd = candidate_df.index[-1]\n",
    "\n",
    "# select this candidate\n",
    "pdf_last_alert = pdf_filter_by_shared_Id.loc[index_max_jd]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c878ac",
   "metadata": {},
   "source": [
    "### Transform the data of all candidates (including `prv_candidates` and the last one) into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_selec_cands = pdf_last_alert['prv_candidates'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd041afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add 'candidate' the actual value \n",
    "keys = pdf_selec_cands[0].keys()\n",
    "latest_cand = {key: pdf_last_alert['candidate'][key] for key in keys if key in pdf_last_alert['candidate']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2516f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dicts = list(pdf_selec_cands)\n",
    "liste_dicts.append(latest_cand)\n",
    "df = pd.DataFrame(liste_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb6079",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4c784",
   "metadata": {},
   "source": [
    "# 3) plot Difference Magnitude in Modified Julian Date [UTC]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd102bb",
   "metadata": {},
   "source": [
    "_Circles (●) with error bars show valid alerts that pass the Fink quality cuts.\n",
    "In addition, the Difference magnitude view shows:\n",
    "\n",
    "_upper triangles with errors (▲), representing alert measurements that do not satisfy Fink quality cuts, but are nevetheless contained in the history of valid alerts and used by classifiers.\n",
    "\n",
    "_lower triangles (▽), representing 5-sigma magnitude limit in difference image based on PSF-fit photometry contained in the history of valid alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "# valid values \n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "# Upper limit values\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "#bad quality values \n",
    "maskBadquality = ~maskValid & ~maskUpper\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt]['magpsf'],\n",
    "        df[maskValid & maskFilt]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} band'.format(filtdic[filt])\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        df[maskUpper & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskUpper & maskFilt]['diffmaglim'],\n",
    "        ls='', marker='v', color=colordic[filt], markerfacecolor='none'\n",
    "    )\n",
    "    \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskBadquality & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskBadquality & maskFilt]['magpsf'],\n",
    "        df[maskBadquality & maskFilt]['sigmapsf'],\n",
    "        ls='', marker='^', color=colordic[filt]\n",
    "    )\n",
    "\n",
    "#plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35bf46",
   "metadata": {},
   "source": [
    "# Plot the magnitude difference for valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34ecf0",
   "metadata": {},
   "source": [
    "Distinguishing between positive differences represented by circles and negative differences represented by triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "    \n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "\n",
    "    \n",
    "#t or 1 => candidate is from positive (sci minus ref) subtraction;\n",
    "#f or 0 => candidate is from negative (ref minus sci) subtraction\"\n",
    "maskpos = (df['isdiffpos'] == 't') | (df['isdiffpos'] == '1')\n",
    "maskneg = (df['isdiffpos'] == 'f') | (df['isdiffpos'] == '0')\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    # candidates from negative \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt & maskneg ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt & maskneg ]['magpsf'],\n",
    "        df[maskValid & maskFilt & maskneg ]['sigmapsf'],\n",
    "        ls = '', marker='^', color=colordic[filt], label='{} (-)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "    # candidates from positive \n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt &  maskpos ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt &  maskpos ]['magpsf'],\n",
    "        df[maskValid & maskFilt &  maskpos ]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} (+)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "\n",
    "#plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf6121",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7320a",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9302975",
   "metadata": {},
   "source": [
    "# 5) Calculate and plot Apparent DC flux  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c69e3",
   "metadata": {},
   "source": [
    "We utilize a function(`apparent_flux`) located within the `fink_utils` package to compute the apparent flux for the valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f99ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def apparent_flux_New(\n",
    "    magpsf: float,\n",
    "    sigmapsf: float,\n",
    "    magnr: float,\n",
    "    sigmagnr: float,\n",
    "    isdiffpos: int,    \n",
    "    is_Source: bool = True,\n",
    "    jansky: bool = True\n",
    "\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Compute apparent flux from difference magnitude supplied by ZTF\n",
    "    Implemented according to p.107 of the ZTF Science Data System Explanatory Supplement\n",
    "    https://irsa.ipac.caltech.edu/data/ZTF/docs/ztf_explanatory_supplement.pdf\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    magpsf,sigmapsf; floats\n",
    "        magnitude from PSF-fit photometry, and 1-sigma error\n",
    "    magnr,sigmagnr: floats\n",
    "        magnitude of nearest source in reference image PSF-catalog\n",
    "        within 30 arcsec and 1-sigma error\n",
    "    isdiffpos: str\n",
    "        t or 1 => candidate is from positive (sci minus ref) subtraction;\n",
    "        f or 0 => candidate is from negative (ref minus sci) subtraction\n",
    "    jansky: bool\n",
    "        If True, normalise units to Jansky. Default is True.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dc_flux: float\n",
    "        Apparent flux\n",
    "    dc_sigflux: float\n",
    "        Error on apparent flux\n",
    "    \"\"\"\n",
    "    if magpsf is None or magnr < 0:\n",
    "        return float(\"Nan\"), float(\"Nan\")\n",
    "    \n",
    "    \n",
    "    elif is_Source: \n",
    "\n",
    "        difference_flux = 10 ** (-0.4 * magpsf)\n",
    "        difference_sigflux = (sigmapsf / 1.0857) * difference_flux\n",
    "\n",
    "        ref_flux = 10 ** (-0.4 * magnr)\n",
    "        ref_sigflux = (sigmagnr / 1.0857) * ref_flux\n",
    "\n",
    "        # add or subract difference flux based on isdiffpos\n",
    "        if (isdiffpos == 't') or (isdiffpos == '1'):\n",
    "            dc_flux = ref_flux + difference_flux\n",
    "        else:\n",
    "            dc_flux = ref_flux - difference_flux\n",
    "\n",
    "        # assumes errors are independent. Maybe too conservative.\n",
    "        dc_sigflux = np.sqrt(difference_sigflux**2 + ref_sigflux**2)\n",
    "\n",
    "        if jansky:\n",
    "            dc_flux *= 3631\n",
    "            dc_sigflux *= 3631\n",
    "\n",
    "        return dc_flux, dc_sigflux\n",
    "    \n",
    "    \n",
    "    \n",
    "    dc_flux = 10**(-0.4* magpsf) \n",
    "    dc_sigflux = sigmapsf * dc_flux / 1.0857\n",
    "\n",
    "    if jansky:\n",
    "        dc_flux *= 3631\n",
    "        dc_sigflux *= 3631\n",
    "\n",
    "    return dc_flux, dc_sigflux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10153c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7591672",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def apparent_flux_New(\n",
    "    magpsf: float,\n",
    "    sigmapsf: float,\n",
    "    magnr: float,\n",
    "    sigmagnr: float,\n",
    "    isdiffpos: int,    \n",
    "    is_Source: bool = True,\n",
    "    jansky: bool = True\n",
    "\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Compute apparent flux from difference magnitude supplied by ZTF\n",
    "    Implemented according to p.107 of the ZTF Science Data System Explanatory Supplement\n",
    "    https://irsa.ipac.caltech.edu/data/ZTF/docs/ztf_explanatory_supplement.pdf\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    magpsf,sigmapsf; floats\n",
    "        magnitude from PSF-fit photometry, and 1-sigma error\n",
    "    magnr,sigmagnr: floats\n",
    "        magnitude of nearest source in reference image PSF-catalog\n",
    "        within 30 arcsec and 1-sigma error\n",
    "    isdiffpos: str\n",
    "        t or 1 => candidate is from positive (sci minus ref) subtraction;\n",
    "        f or 0 => candidate is from negative (ref minus sci) subtraction\n",
    "    jansky: bool\n",
    "        If True, normalise units to Jansky. Default is True.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dc_flux: float\n",
    "        Apparent flux\n",
    "    dc_sigflux: float\n",
    "        Error on apparent flux\n",
    "    \"\"\"\n",
    "    if magpsf is None or magnr < 0:\n",
    "        return float(\"Nan\"), float(\"Nan\")\n",
    "    \n",
    "    \n",
    "\n",
    "    difference_flux = 10 ** (-0.4 * magpsf)\n",
    "    difference_sigflux = (sigmapsf / 1.0857) * difference_flux\n",
    "\n",
    "    if is_Source: \n",
    "\n",
    "        ref_flux = 10 ** (-0.4 * magnr)\n",
    "        ref_sigflux = (sigmagnr / 1.0857) * ref_flux\n",
    "\n",
    "        # add or subract difference flux based on isdiffpos\n",
    "        if (isdiffpos == 't') or (isdiffpos == '1'):\n",
    "            dc_flux = ref_flux + difference_flux\n",
    "        else:\n",
    "            dc_flux = ref_flux - difference_flux\n",
    "\n",
    "        # assumes errors are independent. Maybe too conservative.\n",
    "        dc_sigflux = np.sqrt(difference_sigflux**2 + ref_sigflux**2)\n",
    "        \n",
    "    else:\n",
    "        dc_flux= difference_flux\n",
    "        dc_sigflux = difference_sigflux\n",
    "        \n",
    "        \n",
    "    if jansky:\n",
    "        dc_flux *= 3631\n",
    "        dc_sigflux *= 3631\n",
    "\n",
    "    return dc_flux, dc_sigflux\n",
    "    \n",
    "    \n",
    "    \n",
    "#     dc_flux = 10**(-0.4* magpsf) \n",
    "#     dc_sigflux = sigmapsf * dc_flux / 1.0857\n",
    "\n",
    "#     if jansky:\n",
    "#         dc_flux *= 3631\n",
    "#         dc_sigflux *= 3631\n",
    "\n",
    "#     return dc_flux, dc_sigflux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 5))\n",
    "from fink_utils.photometry.utils import is_source_behind\n",
    "\n",
    "# from fink_utils.photometry.conversion import apparent_flux\n",
    "\n",
    "\n",
    "# Take only valid measurements\n",
    "maskValid = (df['rb'] >= 0.55) & (df['nbad'] == 0)\n",
    "df_valid = df[maskValid].sort_values('jd')\n",
    "df_valid['is_Source'] = is_source_behind(df_valid['distnr'])\n",
    "\n",
    "# dc_flux, dc_sigflux = np.transpose(\n",
    "#         [\n",
    "#             apparent_flux(*args, jansky=True) for args in zip(\n",
    "#                 df_valid['magpsf'].astype(float).values,\n",
    "#                 df_valid['sigmapsf'].astype(float).values,\n",
    "#                 df_valid['magnr'].astype(float).values,\n",
    "#                 df_valid['sigmagnr'].astype(float).values,\n",
    "#                 df_valid['isdiffpos'].values\n",
    "#             )\n",
    "#         ]\n",
    "# )\n",
    "\n",
    "# df_valid['dc_flux_origin'] = dc_flux\n",
    "\n",
    "# df_valid['dc_sigflux_origin'] = dc_sigflux\n",
    "\n",
    "dc_flux, dc_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux_New(*args, jansky=True) for args in zip(\n",
    "                df_valid['magpsf'].astype(float).values,\n",
    "                df_valid['sigmapsf'].astype(float).values,\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values,\n",
    "                df_valid['isdiffpos'].values,\n",
    "                df_valid['is_Source'].astype(bool).values\n",
    "\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['dc_flux'] = dc_flux\n",
    "df_valid['dc_sigflux'] = dc_sigflux\n",
    "\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3,\n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        label=filt\n",
    "    )\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(14, 5))\n",
    " \n",
    "# for filt in np.unique(df['fid']):\n",
    "#     mask = df_valid['fid'] == filt\n",
    "#     sub = df_valid[mask]\n",
    "#     plt.errorbar(\n",
    "#         sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "#         sub['dc_flux_origin'] * 1e3,\n",
    "#         sub['dc_sigflux_origin'] * 1e3,\n",
    "#         ls='',\n",
    "#         marker='o',\n",
    "#         label=filt\n",
    "#     )\n",
    "# plt.legend()\n",
    "\n",
    "# plt.xlabel('Modified Julian Date [UTC]')\n",
    "# plt.ylabel('Apparent DC flux (millijanksy)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befe5d71",
   "metadata": {},
   "source": [
    "## Apparent flux for the nearest source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45ab7e",
   "metadata": {},
   "source": [
    "We create a function `flux_nr` to determine the apparent flux for the nearest source in the reference image.\n",
    "\n",
    "Please don't overlook downloading the FAnomAly package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAnomAly.flux import flux_nr\n",
    "\n",
    "nr_flux, nr_sigflux = np.transpose(\n",
    "        [\n",
    "            flux_nr(*args, jansky=True) for args in zip(\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['nr_flux'] = nr_flux\n",
    "df_valid['nr_sigflux'] = nr_sigflux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce599bb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd36ec",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028d844",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146da65d",
   "metadata": {},
   "source": [
    "# 4) Verify whether there is a source behind the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7f388",
   "metadata": {},
   "source": [
    "If so, we compute the magnitude DC using the new `dc_mag` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17e03a",
   "metadata": {},
   "source": [
    " And we extract a subset of validated data into a dataframe for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from FAnomAly.dc_mag import dc_mag\n",
    "# from fink_utils.photometry.conversion import dc_mag\n",
    "\n",
    "\n",
    "\n",
    "# mag_dc, err_dc = np.transpose(\n",
    "#     [\n",
    "#         dc_mag(*args) for args in zip(\n",
    "#             df_valid['magpsf'].astype(float).values,\n",
    "#             df_valid['sigmapsf'].astype(float).values,\n",
    "#             df_valid['magnr'].astype(float).values,\n",
    "#             df_valid['sigmagnr'].astype(float).values,\n",
    "#             df_valid['isdiffpos'].values,\n",
    "#             df_valid['is_Source'].astype(bool).values\n",
    "\n",
    "#         )\n",
    "#     ]\n",
    "#  )\n",
    "\n",
    "# df_valid['mag_dc'] = mag_dc\n",
    "# df_valid['err_dc'] = err_dc\n",
    "\n",
    "# # apparent mag and its error from fluxes\n",
    "mag_dc = -2.5 * np.log10(df_valid['dc_flux'] / 3631) \n",
    "err_dc = df_valid['dc_sigflux'] / df_valid['dc_flux'] * 1.0857\n",
    "\n",
    "\n",
    "df_valid['mag_dc'] = mag_dc\n",
    "df_valid['err_dc'] = err_dc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb64c6",
   "metadata": {},
   "source": [
    "### Next, we plot the comparison between PSF-fit magnitudes and DC magnitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f96483",
   "metadata": {},
   "source": [
    "We calculate the reference value as the average magnitude of the nearest source in the reference image PSF catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "for filt in np.unique(df_valid['fid']):\n",
    "    maskFilt = df_valid['fid'] == filt\n",
    "\n",
    "#     plt.errorbar(\n",
    "#         df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "#         df_valid[maskFilt]['magpsf'],\n",
    "#         df_valid[maskFilt]['sigmapsf'],\n",
    "#         ls = '', marker='s', \n",
    "#         color=colordic[filt], \n",
    "#         label='{} band (PSF-fit)'.format(filtdic[filt]),\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['mag_dc'],\n",
    "        df_valid[maskFilt]['err_dc'],\n",
    "        ls = '', marker='o', \n",
    "        color=colordic[filt], \n",
    "        label='{} band (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    #To show if there is a variance in the reference( magnitude of the nearest source in the reference image PSF)\n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['magnr'],\n",
    "        ls = '--', \n",
    "        color=colordic[filt], \n",
    "        label='{} ref (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    \n",
    "\n",
    "ref_value_r = np.sqrt((df_valid[df_valid['fid'] == 2]['magnr'] ** 2).mean())# Quadratic Mean\n",
    "ref_value_g = np.sqrt((df_valid[df_valid['fid'] == 1]['magnr'] ** 2).mean())\n",
    "\n",
    "\n",
    "#  Average Values (Used in Fink)\n",
    "#plt.axhline(y=ref_value_r, color=colordic[2], linestyle='--')\n",
    "#plt.axhline(y=ref_value_g, color=colordic[1], linestyle='--')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Comparison of PSF-fit and DC magnitudes')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Magnitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b07b1b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76716d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372399a2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765880f1",
   "metadata": {},
   "source": [
    "# 6) Data missing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0759eda",
   "metadata": {},
   "source": [
    "Our objective here is to retrieve the missing data values, particularly for cases where they represent upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only Upper limits data\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "df_Upper = df[maskUpper].sort_values('jd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a5ed4",
   "metadata": {},
   "source": [
    "Compute the average of the sigma magnitude values for the nearest sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926d3fb",
   "metadata": {},
   "source": [
    "We define a function named `apparent_flux_Upper` to calculate the apparent flux, along with its associated sigma (error), for both the DC flux and NR flux, specifically for data representing upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e475b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['source'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c50a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day, last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6927f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_Source_by_fid = df_valid.groupby(['fid', 'is_Source']).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# # Determine which count is highest\n",
    "is_Source_by_fid['Highest_bool'] = is_Source_by_fid.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15261f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_Source_by_fid['Highest_bool'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_valid[df_valid['fid'] == 1]) ==0 : \n",
    "    # if we don't have data for green alerts we drop the green upperlim \n",
    "    # Not the best solution but Missing data is better than false data \n",
    "    df_Upper.drop(df_Upper[df_Upper['fid'] == 1].index, inplace=True)\n",
    "    \n",
    "    # We append two data points with zero values. This aids our algorithm without introducing any risk.\n",
    "    new_rows = pd.DataFrame({'fid': [1, 1],\n",
    "                             'jd': [first_day, last_day],#[df_valid['jd'].min(), df_valid['jd'].max()],\n",
    "                             'dc_flux': [0, 0],\n",
    "                             'dc_sigflux': [0, 0],\n",
    "                             'nr_flux' : [0,0],\n",
    "                             'nr_sigflux':[0,0], \n",
    "                             'source': [0,0],\n",
    "                             'is_Source': [is_Source_by_fid['Highest_bool'].iloc[0],is_Source_by_fid['Highest_bool'].iloc[0]]\n",
    "                            })\n",
    "\n",
    "    df_valid = pd.concat([df_valid, new_rows], ignore_index=True)\n",
    "\n",
    "elif len(df_valid[df_valid['fid'] == 2]) ==0 : \n",
    "    df_Upper.drop(df_Upper[df_Upper['fid'] == 2].index, inplace=True)\n",
    "    \n",
    "        \n",
    "    new_rows = pd.DataFrame({'fid': [2, 2],\n",
    "                             'jd': [first_day, last_day],\n",
    "                             'dc_flux': [0, 0],\n",
    "                             'dc_sigflux': [0, 0],\n",
    "                             'nr_flux' : [0,0],\n",
    "                             'nr_sigflux':[0,0],\n",
    "                             'source': [0,0],\n",
    "                             'is_Source': [is_Source_by_fid['Highest_bool'].iloc[0],is_Source_by_fid['Highest_bool'].iloc[0]]\n",
    "                             \n",
    "                           })\n",
    "\n",
    "    df_valid = pd.concat([df_valid, new_rows], ignore_index=True)\n",
    "\n",
    "\n",
    "there_upper = (len(df_Upper)>0)\n",
    "if there_upper:\n",
    "    \n",
    "    is_Source_by_fid = df_valid.groupby(['fid', 'is_Source']).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "    # # Determine which count is highest\n",
    "    is_Source_by_fid['Highest_bool'] = is_Source_by_fid.idxmax(axis=1)\n",
    "    ### if there is no valid data we drop upper limit data (so why do we still modify its mean !)\n",
    "\n",
    "    \n",
    "    \n",
    "    if is_Source_by_fid['Highest_bool'].iloc[0]: \n",
    "        mean_sigmnr_g = np.sqrt((df_valid[df_valid['fid'] == 1]['sigmagnr'] ** 2).mean())\n",
    "    else:\n",
    "        ref_value_g = np.inf\n",
    "        mean_sigmnr_g = 0\n",
    "\n",
    "        \n",
    "    if is_Source_by_fid['Highest_bool'].iloc[1]: \n",
    "        mean_sigmnr_r = np.sqrt((df_valid[df_valid['fid'] == 2]['sigmagnr'] ** 2).mean())\n",
    "    else:\n",
    "        ref_value_r = np.inf\n",
    "        mean_sigmnr_r = 0\n",
    "                \n",
    "        \n",
    "    \n",
    "    from FAnomAly.flux import apparent_flux_Upper\n",
    "\n",
    "    dc_flux, dc_sigflux,nr_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux_Upper(*args, ref_value_r, ref_value_g, mean_sigmnr_r, mean_sigmnr_g, jansky=True) for args in zip(\n",
    "                df_Upper['diffmaglim'].astype(float).values,\n",
    "                df_Upper['fid'].astype(int).values,\n",
    "\n",
    "            )  \n",
    "        ]\n",
    "     )\n",
    "\n",
    "    df_Upper['dc_flux'] = dc_flux\n",
    "    df_Upper['dc_sigflux'] = dc_sigflux\n",
    "    df_Upper['nr_sigflux'] = nr_sigflux\n",
    "    df_Upper['nr_flux'] = dc_flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c525a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_Source_by_fid['Highest_bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a918d",
   "metadata": {},
   "source": [
    "### Plot the apparent DC flux (in millijansky) for both valid and upper limits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db693860",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} valid\"\n",
    "    )\n",
    "    \n",
    "    if there_upper:\n",
    "        mask2 = df_Upper['fid'] == filt\n",
    "        plt.errorbar(\n",
    "        df_Upper[mask2]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_Upper[mask2]['dc_flux']*1e3,\n",
    "        df_Upper[mask2]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Upperlim\"\n",
    "        )\n",
    "#     break\n",
    "        \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7453ea6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf0776",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae0fe5",
   "metadata": {},
   "source": [
    "# 7) Combine Upper with valid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616249f2",
   "metadata": {},
   "source": [
    "We merge the data from the upper limit and valid datasets based on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83977c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['jd', 'fid','dc_flux', 'dc_sigflux', 'nr_flux', 'nr_sigflux','source']\n",
    "if there_upper: \n",
    "    df_Upper['source'] = 1\n",
    "    combined_df = pd.concat([df_Upper[columns_to_keep], df_valid[columns_to_keep]], axis=0)\n",
    "else:\n",
    "    combined_df = df_valid[columns_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf479ce",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dbd07c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b941e8",
   "metadata": {},
   "source": [
    "# 8) Data by days "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade442e",
   "metadata": {},
   "source": [
    "Here, we group the data by modified Julian date on a daily basis and by filter ID (1 for g, 2 for R, 3 for i), computing the average values of flux and sigma flux(for both DC and NR) using the `Weighted_Mean` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54621832",
   "metadata": {},
   "source": [
    "#### Convert 'mjd' to integer to remove fractional part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc[:, 'mjd'] = (combined_df['jd'] - 2400000.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560339d1",
   "metadata": {},
   "source": [
    "#### group the data by mjd and by filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70711f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = combined_df.groupby(['mjd','fid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94fb10",
   "metadata": {},
   "source": [
    "#### calculate the average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from FAnomAly.Weighted_Mean import Weighted_Mean_general\n",
    "\n",
    "df_by_days = pd.DataFrame()\n",
    "df_by_days = df_group.apply(Weighted_Mean_general, flux_col='dc_flux', sigflux_col='dc_sigflux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf35e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_days[['nr_flux', 'nr_sigflux']] = df_group.apply(Weighted_Mean_general, flux_col='nr_flux',sigflux_col='nr_sigflux')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31273442",
   "metadata": {},
   "source": [
    "We extract the initial value from the 'source' column within each group. It's noteworthy that on any given day (represented by 'r/g'), there might be either missing data or available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52214c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_days['source'] = df_group.apply(lambda group: group['source'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74da68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only once !...\n",
    "df_by_days.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b932d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_days.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428ad40",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6faa8",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40124d6",
   "metadata": {},
   "source": [
    "# 9) Fill the missing days ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53876f8",
   "metadata": {},
   "source": [
    "If there are missing days without alerts in the data, we can fill these gaps by inserting average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33983e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAnomAly.Weighted_Mean import Weighted_Mean_all\n",
    "\n",
    "min_mjd = int(first_day - 2400000.5) #df_by_days['mjd'].min()\n",
    "max_mjd = int(last_day  - 2400000.5) #df_by_days['mjd'].max()\n",
    "# Create a DataFrame all_days containing a range of MJD values from the minimum to the maximum MJD found in df_by_days.\n",
    "all_days = pd.DataFrame({'mjd': range(min_mjd, max_mjd + 1)}) # + 1 i need to check this one ! \n",
    "\n",
    "df_extended = df_by_days\n",
    "# df_extended['source'] = 1 # I need to check for this one\n",
    "\n",
    "\n",
    "there_missing_data = (df_by_days.shape[0] < (max_mjd -min_mjd +1)*2)\n",
    "if there_missing_data:        \n",
    "     for filt in np.unique(df_extended['fid']):\n",
    "        print(filt)\n",
    "        mask = df_extended['fid'] == filt\n",
    "        sub = df_extended[mask]\n",
    "        data_days = df_extended[mask]['mjd']\n",
    "\n",
    "        missing_days = all_days[~all_days['mjd'].isin(data_days)]\n",
    "    \n",
    "    \n",
    "        df_predic = pd.DataFrame(index=missing_days['mjd'])\n",
    "    \n",
    "        dc_flux ,nr_flux = Weighted_Mean_all(sub)\n",
    "        \n",
    "        dc_sigflux = sub['dc_flux'].std()\n",
    "        nr_sigflux = sub['nr_flux'].std()\n",
    "        \n",
    "        #print(dc_flux*1e3, dc_sigflux*1e3 ,nr_flux*1e3 ,nr_sigflux*1e3)\n",
    "\n",
    "        \n",
    "        df_predic[['fid','dc_flux', 'dc_sigflux' ,'nr_flux' ,'nr_sigflux']] = [filt,dc_flux, dc_sigflux ,nr_flux ,nr_sigflux]\n",
    "        df_predic['source'] = 0\n",
    "\n",
    "        # Add a new column 'source' to df_extended\n",
    "\n",
    "        df_extended = pd.concat([df_extended, df_predic.reset_index()], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c40a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.sort_values(by=['mjd','fid'],   inplace=True)\n",
    "df_extended.reset_index(drop= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4d55b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_extended.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4a387",
   "metadata": {},
   "source": [
    "### plot apparent  DC and nr flux in millijanksy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "\n",
    "for filt in np.unique(df_extended['fid']):\n",
    "    mask = df_extended['fid'] == filt\n",
    "    mask_missing =  df_extended['source'] == 0\n",
    "    mask_original = df_extended['source'] == 1\n",
    "    sub2 = df_extended[mask & mask_missing]\n",
    "    sub = df_extended[mask & mask_original]\n",
    "    \n",
    "    plt.errorbar(\n",
    "        sub['mjd'],\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} original flux dc\"\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        sub2['mjd'],\n",
    "        sub2['dc_flux']*1e3, \n",
    "#         sub2['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='x',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Missing flux dc\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"plt.errorbar(\n",
    "        df[mask]['mjd'],\n",
    "        df[mask]['nr_flux']*1e3,\n",
    "        df[mask]['nr_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all nr\"\n",
    "    )\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent  DC and nr flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02336833",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_extended['dc_flux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6175091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = df_extended['dc_flux'][::2].values/df_extended['dc_flux'][1::2].values\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c034a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe88c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df_by_days['fid']):\n",
    "    mask = df_by_days['fid'] == filt\n",
    "    sub = df_by_days\n",
    "    plt.errorbar(\n",
    "        sub[mask]['mjd'],\n",
    "        sub[mask]['dc_flux']*1e3, \n",
    "        sub[mask]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all flux dc\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    \"\"\"plt.errorbar(\n",
    "        df[mask]['mjd'],\n",
    "        df[mask]['nr_flux']*1e3,\n",
    "        df[mask]['nr_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all nr\"\n",
    "    )\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent  DC and nr flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdaf6f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff4db1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503bea0",
   "metadata": {},
   "source": [
    "# 10) Create a final dataframe to consolidate the values of this alert into a single row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7954a",
   "metadata": {},
   "source": [
    "In this dataframe, include another dataframe as a dictionary containing the values of mjd,flux, sigma, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly = pd.DataFrame()\n",
    "df_anomaly['objectId'] = [pdf_last_alert.objectId]\n",
    "df_anomaly['candid'] = [pdf_last_alert.candid]\n",
    "df_anomaly['jd'] = [pdf_last_alert.candidate['jd']]\n",
    "df_anomaly['df'] = [df_extended.to_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ddc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's an example of how we can utilize the dataframe of the first row:\n",
    "df_test = pd.DataFrame.from_dict(df_anomaly['df'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23333851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adb25b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cf81c9",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff90f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063b05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b23f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8b55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e3555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52579d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ec3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c242f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7774c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a907964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252a6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed387185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61e052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f41e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
