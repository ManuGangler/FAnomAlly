{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "from PIL import Image as im\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1f1197",
   "metadata": {},
   "source": [
    "# Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6810444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = pd.read_parquet('../../ftransfer_ztf_2024-02-01_689626')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0005021",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228083e5",
   "metadata": {},
   "source": [
    "# Select alerts with shared Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = pdf['objectId'][4771]\n",
    "\n",
    "id_plus_repete = pdf['objectId'].value_counts().idxmax()\n",
    "\n",
    "# We select data based on their shared ID, (here opting for the most frequently occurring alert).\n",
    "pdf_selectionne = pdf.loc[pdf['objectId'] == id_plus_repete]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546384aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_selectionne.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c0c24",
   "metadata": {},
   "source": [
    "# Choose the last alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48d946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pdf_selectionne['candidate'].apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = pdf_selectionne['candidate'].apply(pd.Series)\n",
    "\n",
    "# index of the candidate with the biggest 'jd'\n",
    "index_max_jd = candidate_df['jd'].idxmax()\n",
    "\n",
    "# select this candidate\n",
    "pdf_selectionne = pdf_selectionne.loc[index_max_jd]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c878ac",
   "metadata": {},
   "source": [
    "# Transform all candidates (including 'prv_candidates' and the last one) into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821f99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_selectionne_cand = pdf_selectionne['prv_candidates'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd041afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add 'candidate' the actual value \n",
    "keys = pdf_selectionne_cand[0].keys()\n",
    "actual_cand = {key: pdf_selectionne['candidate'][key] for key in keys if key in pdf_selectionne['candidate']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2516f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dicts = list(pdf_selectionne_cand)\n",
    "liste_dicts.append(actual_cand)\n",
    "df = pd.DataFrame(liste_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4c784",
   "metadata": {},
   "source": [
    "# plot Difference Magnitude in Modified Julian Date [UTC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mjd = df['jd'].apply(lambda x: x - 2400000.5)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "# valid values \n",
    "maskValid = (df['rb'] > 0.55) & (df['nbad'] == 0)\n",
    "# Upper limit values\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "#bad quality values \n",
    "maskBadquality = ~maskValid & ~maskUpper\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt]['magpsf'],\n",
    "        df[maskValid & maskFilt]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} band'.format(filtdic[filt])\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        df[maskUpper & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskUpper & maskFilt]['diffmaglim'],\n",
    "        ls='', marker='v', color=colordic[filt], markerfacecolor='none'\n",
    "    )\n",
    "    \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskBadquality & maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskBadquality & maskFilt]['magpsf'],\n",
    "        df[maskBadquality & maskFilt]['sigmapsf'],\n",
    "        ls='', marker='^', color=colordic[filt]\n",
    "    )\n",
    "\n",
    "plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57e689",
   "metadata": {},
   "source": [
    "# Plot the magnitude difference for valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f5fa1",
   "metadata": {},
   "source": [
    "Distinguishing between positive differences represented by circles and negative differences represented by triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "    \n",
    "maskValid = (df['rb'] > 0.55) & (df['nbad'] == 0)\n",
    "\n",
    "    \n",
    "#t or 1 => candidate is from positive (sci minus ref) subtraction;\n",
    "#f or 0 => candidate is from negative (ref minus sci) subtraction\"\n",
    "maskpos = (df['isdiffpos'] == 't') | (df['isdiffpos'] == 1)\n",
    "maskneg = (df['isdiffpos'] == 'f') | (df['isdiffpos'] == 0)\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    maskFilt = df['fid'] == filt\n",
    "\n",
    "    # candidates from negative \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt & maskneg ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt & maskneg ]['magpsf'],\n",
    "        df[maskValid & maskFilt & maskneg ]['sigmapsf'],\n",
    "        ls = '', marker='^', color=colordic[filt], label='{} (-)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "    # candidates from positive \n",
    "    plt.errorbar(\n",
    "        df[maskValid & maskFilt &  maskpos ]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df[maskValid & maskFilt &  maskpos ]['magpsf'],\n",
    "        df[maskValid & maskFilt &  maskpos ]['sigmapsf'],\n",
    "        ls = '', marker='o', color=colordic[filt], label='{} (+)'.format(filtdic[filt])\n",
    "    )\n",
    "    \n",
    "\n",
    "#plt.ylim(12, 22)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Difference image PSF-fit magnitude')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Difference Magnitude');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd65647",
   "metadata": {},
   "source": [
    "# Verify whether there is a source behind the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7fa86",
   "metadata": {},
   "source": [
    "If so, we compute the magnitude DC using the `dc_mag` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0410bb9",
   "metadata": {},
   "source": [
    " And we have extracted a subset of validated data into a dataframe for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fink_science.conversion import dc_mag\n",
    "from fink_utils.photometry.conversion import dc_mag\n",
    "from fink_utils.photometry.utils import is_source_behind\n",
    "\n",
    "# Take only valid measurements\n",
    "maskValid = (df['rb'] > 0.55) & (df['nbad'] == 0)\n",
    "df_valid = df[maskValid].sort_values('jd')\n",
    "\n",
    "isSource = is_source_behind(\n",
    "    df_valid['distnr'].values[0]\n",
    ")\n",
    "\n",
    "if isSource:\n",
    "    print('It looks like there is a source behind. Lets compute the DC magnitude instead.')\n",
    "    \n",
    "    # Use DC magnitude instead of difference mag\n",
    "    mag_dc, err_dc = np.transpose(\n",
    "        [\n",
    "            dc_mag(*args) for args in zip(\n",
    "                df_valid['magpsf'].astype(float).values,\n",
    "                df_valid['sigmapsf'].astype(float).values,\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values,\n",
    "                df_valid['isdiffpos'].values\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df_valid['mag_dc'] = mag_dc\n",
    "    df_valid['err_dc'] = err_dc\n",
    "else:\n",
    "    print('No source found -- keeping PSF fit magnitude')\n",
    "    df_valid['mag_dc'] = df_valid['magpsf']\n",
    "    df_valid['err_dc'] = df_valid['sigmapsf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa23cc4",
   "metadata": {},
   "source": [
    "Next, we plot the comparison between PSF-fit magnitudes and DC magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "colordic = {1: 'C0', 2: 'C1'}\n",
    "filtdic = {1: 'g', 2: 'r'}\n",
    "\n",
    "for filt in np.unique(df_valid['fid']):\n",
    "    maskFilt = df_valid['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['magpsf'],\n",
    "        df_valid[maskFilt]['sigmapsf'],\n",
    "        ls = '', marker='x', \n",
    "        color=colordic[filt], \n",
    "        label='{} band (PSF-fit)'.format(filtdic[filt]),\n",
    "    )\n",
    "    \n",
    "    \n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['mag_dc'],\n",
    "        df_valid[maskFilt]['err_dc'],\n",
    "        ls = '', marker='o', \n",
    "        color=colordic[filt], \n",
    "        label='{} band (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    #To show if there is a variance in the reference( magnitude of the nearest source in the reference image PSF)\n",
    "    plt.errorbar(\n",
    "        df_valid[maskFilt]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_valid[maskFilt]['magnr'],\n",
    "        ls = '--', \n",
    "        color=colordic[filt], \n",
    "        label='{} ref (DC)'.format(filtdic[filt]),\n",
    "    )\n",
    "    \n",
    "\n",
    "# We calculate the reference value as the average magnitude of the nearest source in the reference image PSF catalog.\n",
    "ref_r = df_valid[df_valid['fid']==2]['magnr'].mean()\n",
    "\n",
    "ref_g = df_valid[df_valid['fid']==1]['magnr'].mean()\n",
    "\n",
    "\n",
    "\n",
    "print(ref_r, ref_g)\n",
    "#  Average Values (Used in Fink)\n",
    "#plt.axhline(y=ref_r, color=colordic[2], linestyle='--')\n",
    "#plt.axhline(y=ref_g, color=colordic[1], linestyle='--')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.title('Comparison of PSF-fit and DC magnitudes')\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Magnitude');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9302975",
   "metadata": {},
   "source": [
    "# Calculate and plot Apparent DC flux  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32e2e0",
   "metadata": {},
   "source": [
    "We utilize a function(`apparent_flux`) located within the `fink_utils` folder to compute the apparent flux for the valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "from fink_utils.photometry.conversion import apparent_flux\n",
    "\n",
    "\n",
    "dc_flux, dc_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux(*args, jansky=True) for args in zip(\n",
    "                df_valid['magpsf'].astype(float).values,\n",
    "                df_valid['sigmapsf'].astype(float).values,\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values,\n",
    "                df_valid['isdiffpos'].values\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['dc_flux'] = dc_flux\n",
    "df_valid['dc_sigflux'] = dc_sigflux\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3,\n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        label=filt\n",
    "    )\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e2d2d",
   "metadata": {},
   "source": [
    "# Apparent flux for the nearest source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b5420",
   "metadata": {},
   "source": [
    "We create a function `apparent_flux` to determine the apparent flux for the nearest source in the reference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def flux_nr(\n",
    "    magnr: float,\n",
    "    sigmagnr: float,\n",
    "    jansky: bool = True\n",
    "\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dc_flux: float\n",
    "        Apparent flux\n",
    "    dc_sigflux: float\n",
    "        Error on apparent flux\n",
    "    \"\"\"\n",
    "\n",
    "    nr_flux = 10 ** (-0.4 * magnr)\n",
    "    \n",
    "    nr_sigflux = np.log(10) * 0.4 * nr_flux *sigmagnr # dc_flux ! \n",
    "    \n",
    "    if jansky:\n",
    "        nr_flux *= 3631\n",
    "        nr_sigflux *= 3631\n",
    "\n",
    "    return nr_flux, nr_sigflux\n",
    "\n",
    "nr_flux, nr_sigflux = np.transpose(\n",
    "        [\n",
    "            flux_nr(*args, jansky=True) for args in zip(\n",
    "                df_valid['magnr'].astype(float).values,\n",
    "                df_valid['sigmagnr'].astype(float).values\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_valid['nr_flux'] = nr_flux\n",
    "df_valid['nr_sigflux'] = nr_sigflux\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765880f1",
   "metadata": {},
   "source": [
    "# Data missing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57884d09",
   "metadata": {},
   "source": [
    "Our objective here is to retrieve the missing data values, particularly for cases where they represent upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only Upper limits data\n",
    "maskUpper = pd.isna(df['magpsf'])\n",
    "\n",
    "df_Upper = df[maskUpper].sort_values('jd')#, ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d66282",
   "metadata": {},
   "source": [
    "Compute the average of the sigma magnitude values for the nearest sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmnr_r = df_valid[df_valid['fid']==2]['sigmagnr'].mean()\n",
    "sigmnr_g = df_valid[df_valid['fid']==1]['sigmagnr'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196ae2e",
   "metadata": {},
   "source": [
    "We define a function named `apparent_flux_Upper` to calculate the apparent flux, along with its associated sigma (error), for both the DC flux and NR flux, specifically for data representing upper limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def apparent_flux_Upper(\n",
    "    diffmaglim: float,\n",
    "    fid: int,\n",
    "    ref_r: float,\n",
    "    ref_g: float,\n",
    "    sigmnr_r: float,\n",
    "    sigmnr_g: float,\n",
    "    jansky: bool = True\n",
    "\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dc_flux: float\n",
    "        Apparent flux\n",
    "    dc_sigflux: float\n",
    "        Error on apparent flux\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    if (fid == 1):\n",
    "        mnr = ref_g\n",
    "        sigmnr = sigmnr_g\n",
    "    if (fid == 2):\n",
    "        mnr = ref_r\n",
    "        sigmnr = sigmnr_r\n",
    "\n",
    "    dc_flux = 10 ** (-0.4 * mnr)\n",
    "    \n",
    "    sig_c = (10 ** (-0.4 * diffmaglim))/np.sqrt(3) * 4.65 # (normalisation* ! )\n",
    "    sig_flux_nr = np.log(10) * 0.4 * (10 ** (-0.4 * mnr)) *sigmnr # dc_flux ! \n",
    "    \n",
    "    dc_sigflux = np.sqrt(sig_c**2 + sig_flux_nr**2)\n",
    "\n",
    "    if jansky:\n",
    "        dc_flux *= 3631\n",
    "        dc_sigflux *= 3631\n",
    "        sig_flux_nr *= 3631\n",
    "\n",
    "    return dc_flux, dc_sigflux, sig_flux_nr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dc_flux, dc_sigflux,nr_sigflux = np.transpose(\n",
    "        [\n",
    "            apparent_flux_Upper(*args, ref_r, ref_g, sigmnr_r, sigmnr_g, jansky=True) for args in zip(\n",
    "                df_Upper['diffmaglim'].astype(float).values,\n",
    "                df_Upper['fid'].astype(int).values,\n",
    "\n",
    "            )\n",
    "        ]\n",
    ")\n",
    "\n",
    "df_Upper['dc_flux'] = dc_flux\n",
    "df_Upper['dc_sigflux'] = dc_sigflux\n",
    "df_Upper['nr_sigflux'] = nr_sigflux\n",
    "df_Upper['nr_flux'] = dc_flux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a05fd",
   "metadata": {},
   "source": [
    "# Plot the apparent DC flux (in millijansky) for both valid and upper limits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db693860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} valid\"\n",
    "    )\n",
    "    \n",
    "    mask2 = df_Upper['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df_Upper[mask2]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_Upper[mask2]['dc_flux']*1e3,\n",
    "        df_Upper[mask2]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Upperlim\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae0fe5",
   "metadata": {},
   "source": [
    "# Combine Upper with valid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c116cf",
   "metadata": {},
   "source": [
    "We merge the data from the upper limit and valid datasets based on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83977c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['jd', 'fid','dc_flux', 'dc_sigflux', 'nr_flux', 'nr_sigflux']\n",
    "combined_df = pd.concat([df_Upper[columns_to_keep], df_valid[columns_to_keep]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5b941e8",
   "metadata": {},
   "source": [
    "# Data by days "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baed553",
   "metadata": {},
   "source": [
    "Here, we group the data by modified Julian date on a daily basis and by filter ID (1 for g, 2 for R, 3 for i), computing the average values of flux and sigma flux(for both DC and NR) using the `Weighted_Mean` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['mjd'] = combined_df['jd'].apply(lambda x: x - 2400000.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc85e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'mjd' to integer to remove fractional part\n",
    "combined_df['mjd'] = combined_df['mjd'].astype(int)\n",
    "df2 = combined_df.groupby(['mjd','fid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b876555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I should generelaize this one ! \n",
    "def Weighted_Mean_dc(group):\n",
    "    N= len(group)\n",
    "    if N ==1 :\n",
    "        return pd.Series({'dc_flux': group['dc_flux'].iloc[0], 'dc_sigflux': group['dc_sigflux'].iloc[0]}) \n",
    "    \n",
    "    wi = 1/group['dc_sigflux']**2\n",
    "\n",
    "    x_bar = (group['dc_flux']*wi).sum() / wi.sum()\n",
    "    \n",
    "    x_2 = ((group['dc_flux'] - x_bar)**2 *wi).sum()\n",
    "    \n",
    "    sigma_x = np.sqrt(1/ wi.sum())\n",
    "    \n",
    "    fact = np.sqrt(x_2/ (N-1))\n",
    "    \n",
    "    if (fact >= 1) : \n",
    "        sigma_x *= fact\n",
    "    return pd.Series({'dc_flux': x_bar, 'dc_sigflux': sigma_x})\n",
    "    #return pd.Series(x_bar , index=[group.index[0]]),pd.Series(sigma_x , index=[group.index[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_mod = pd.DataFrame()\n",
    "df_mod = df2.apply(Weighted_Mean_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde26199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Mean_nr(group):\n",
    "    N= len(group)\n",
    "    if N ==1 :\n",
    "        return pd.Series({'nr_flux': group['nr_flux'].iloc[0], 'nr_sigflux': group['nr_sigflux'].iloc[0]}) \n",
    "    \n",
    "    wi = 1/group['nr_sigflux']**2\n",
    "\n",
    "    x_bar = (group['nr_flux']*wi).sum() / wi.sum()\n",
    "    \n",
    "    x_2 = ((group['nr_flux'] - x_bar)**2 *wi).sum()\n",
    "    \n",
    "    sigma_x = np.sqrt(1/ wi.sum())\n",
    "    \n",
    "    fact = np.sqrt(x_2/ (N-1))\n",
    "    \n",
    "    if (fact >= 1) : \n",
    "        sigma_x *= fact\n",
    "    return pd.Series({'nr_flux': x_bar, 'nr_sigflux': sigma_x})\n",
    "    #return pd.Series(x_bar , index=[group.index[0]]),pd.Series(sigma_x , index=[group.index[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf35e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod[['nr_flux', 'nr_sigflux']] = df2.apply(Weighted_Mean_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74da68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only once ! i need to solve this prob...\n",
    "df_mod.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b932d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df4c89",
   "metadata": {},
   "source": [
    "# Fill the missing days ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a17705",
   "metadata": {},
   "source": [
    "If there are missing days without alerts in the data, we can fill these gaps by inserting average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5fae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod[['mjd','fid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e65b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec192b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2d9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78fe3f01",
   "metadata": {},
   "source": [
    "# Create a final dataframe to consolidate the values of this alert into a single row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424eea69",
   "metadata": {},
   "source": [
    "In this dataframe, include another dataframe as a dictionary containing the values of flux, sigma, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly = pd.DataFrame()\n",
    "df_anomaly['objectId'] = [pdf_selectionne.objectId]\n",
    "df_anomaly['candid'] = [pdf_selectionne.candid]\n",
    "df_anomaly['jd'] = [pdf_selectionne.candidate['jd']]\n",
    "df_anomaly['df'] = [df_mod.to_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ddc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's an example of how we can utilize the dataframe of the first row:\n",
    "df = pd.DataFrame.from_dict(df_anomaly['df'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23333851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e327841b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15439811",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4baff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5da8ae",
   "metadata": {},
   "source": [
    "# Trash "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid[(df_valid['mjd']).astype(int) == 59089 ][['fid', 'dc_flux','dc_sigflux']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Upper[(df_Upper['mjd']).astype(int) == 59089 ][['fid','dc_flux','dc_sigflux']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=np.array((0.000015,0.000109))\n",
    "f1=np.array((0.000669,0.000828))\n",
    "f1bar=np.sum(f1/s1**2)/np.sum(1/s1**2)\n",
    "print(f1bar)\n",
    "print('chi2',(f1-f1bar)**2/s1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53772e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df['fid'] == filt\n",
    "    sub = df\n",
    "    plt.errorbar(\n",
    "        sub[mask]['mjd'],\n",
    "        sub[mask]['dc_flux']*1e3, \n",
    "        sub[mask]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all flux dc\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    plt.errorbar(\n",
    "        df[mask]['mjd'],\n",
    "        df[mask]['nr_flux']*1e3,\n",
    "        df[mask]['nr_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} all nr\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent  DC and nr flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbbfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "\n",
    "for filt in np.unique(df['fid']):\n",
    "    mask = df_valid['fid'] == filt\n",
    "    sub = df_valid[mask]\n",
    "    plt.errorbar(\n",
    "        sub['jd'].apply(lambda x: x - 2400000.5),\n",
    "        sub['dc_flux']*1e3, \n",
    "        sub['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='o',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} valid\"\n",
    "    )\n",
    "    \n",
    "    mask2 = df_Upper['fid'] == filt\n",
    "\n",
    "    plt.errorbar(\n",
    "        df_Upper[mask2]['jd'].apply(lambda x: x - 2400000.5),\n",
    "        df_Upper[mask2]['dc_flux']*1e3,\n",
    "        df_Upper[mask2]['dc_sigflux']*1e3,\n",
    "        ls='', \n",
    "        marker='.',\n",
    "        color=colordic[filt], \n",
    "\n",
    "        label=f\"{filt} Upperlim\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Modified Julian Date [UTC]')\n",
    "plt.ylabel('Apparent DC flux (millijanksy)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2884ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8425c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b9d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def sig_Mean_error(group):\n",
    "    N= len(group)\n",
    "    if N ==1 :\n",
    "        return group['dc_sigflux']\n",
    "\n",
    "    wi = 1/group['dc_sigflux']**2\n",
    "    \n",
    "    x_bar = (group['dc_flux']*wi).sum() / wi.sum()\n",
    "    \n",
    "    x_2 = ((group['dc_flux'] - x_bar)**2 *wi).sum()\n",
    "\n",
    "    sigma_x = np.sqrt(1/ wi.sum())\n",
    "    \n",
    "    fact = np.sqrt(x_2/ (N-1))\n",
    "    \n",
    "    if (fact >= 1) : \n",
    "        sigma_x *= fact\n",
    "   \n",
    "    return pd.Series(sigma_x, index=[group.index[0]])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
